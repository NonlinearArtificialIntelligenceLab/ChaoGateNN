{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "import equinox as eqx\n",
    "import optax\n",
    "from tqdm import trange\n",
    "from jaxtyping import Array, Bool, Float\n",
    "\n",
    "from chaogatenn.chaogate import ChaoGate\n",
    "from chaogatenn.maps import LogisticMap\n",
    "from chaogatenn.utils import grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for different logic gates\n",
    "X = jnp.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=bool)  # Input combinations\n",
    "AND_Y = jnp.array([0, 0, 0, 1], dtype=bool)  # AND gate output\n",
    "OR_Y = jnp.array([0, 1, 1, 1], dtype=bool)  # OR gate output\n",
    "XOR_Y = jnp.array([0, 1, 1, 0], dtype=bool)  # XOR gate output\n",
    "NAND_Y = jnp.array([1, 1, 1, 0], dtype=bool)  # NAND gate output\n",
    "NOR_Y = jnp.array([1, 0, 0, 0], dtype=bool)  # NOR gate output\n",
    "XNOR_Y = jnp.array([1, 0, 0, 1], dtype=bool)  # XNOR gate output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of logic gates and their corresponding outputs\n",
    "logic_gates = {\n",
    "    \"AND\": AND_Y,\n",
    "    \"OR\": OR_Y,\n",
    "    \"XOR\": XOR_Y,\n",
    "    \"NAND\": NAND_Y,\n",
    "    \"NOR\": NOR_Y,\n",
    "    \"XNOR\": XNOR_Y,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_loss(\n",
    "    chao_gate: ChaoGate, x: Bool[Array, \"batch 2\"], y: Bool[Array, \"batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    pred = jax.vmap(chao_gate)(x)\n",
    "    # binary cross entropy\n",
    "    return -jnp.mean(y * jnp.log(pred + 1e-15) + (1 - y) * jnp.log(1 - pred + 1e-15))\n",
    "\n",
    "\n",
    "# Function to perform a single optimization step\n",
    "@eqx.filter_jit\n",
    "def make_step(\n",
    "    model: ChaoGate,\n",
    "    x: Bool[Array, \"dim 2\"],\n",
    "    y: Bool[Array, \"dim\"],\n",
    "    optim: optax.GradientTransformation,\n",
    "    opt_state: optax.OptState,\n",
    ") -> tuple[Float[Array, \"dim\"], ChaoGate, optax.OptState]:\n",
    "    loss, grads = compute_loss(model, x, y)\n",
    "    updates, opt_state = optim.update(grads, opt_state)\n",
    "    model = eqx.apply_updates(model, updates)\n",
    "    return loss, model, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"../output/logistic_sweep/\"\n",
    "metrics_dict = {}\n",
    "results_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gate_name, Y in logic_gates.items():\n",
    "    metrics_dict[gate_name] = []\n",
    "    results_dict[gate_name] = []\n",
    "    for a in jnp.linspace(0.0, 4.0, num=40):  # 50 steps from 0 to 4\n",
    "        Map = LogisticMap(a=a)\n",
    "        chao_gate = ChaoGate(DELTA=1.0, X0=1.0, X_THRESHOLD=1.0, Map=Map)\n",
    "        optim = optax.adabelief(3e-4)\n",
    "        opt_state = optim.init(eqx.filter(chao_gate, eqx.is_inexact_array))\n",
    "\n",
    "        epochs = 1000\n",
    "        for epoch in trange(epochs, desc=f\"Training {gate_name} gate with a={a:.2f}\"):\n",
    "            loss, chao_gate, opt_state = make_step(chao_gate, X, Y, optim, opt_state)\n",
    "            _, grads = compute_loss(chao_gate, X, Y)\n",
    "            grad_norm_value = grad_norm(grads)\n",
    "\n",
    "        pred_ys = jax.vmap(chao_gate)(X)\n",
    "        num_correct = jnp.sum((pred_ys > 0.5) == Y)\n",
    "        final_accuracy = (num_correct / len(X)).item()\n",
    "        metrics_dict[gate_name].append(\n",
    "            (a, loss.item(), final_accuracy, grad_norm_value)\n",
    "        )\n",
    "        results_dict[gate_name].append(\n",
    "            (a, chao_gate.DELTA, chao_gate.X0, chao_gate.X_THRESHOLD)\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print results\n",
    "for gate_name, metrics in metrics_dict.items():\n",
    "    print(f\"\\nResults for {gate_name} gate:\")\n",
    "    for a, loss, accuracy, grad_norm_value in metrics:\n",
    "        print(\n",
    "            f\"a={a:.2f}, Loss={loss:.6f}, Accuracy={accuracy:.2f}, Grad Norm={grad_norm_value:.6f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform into arrays and save using numpy savetxt\n",
    "for gate_name, metrics in metrics_dict.items():\n",
    "    metrics = jnp.array(metrics)\n",
    "    np.savetxt(f\"{output_dir}{gate_name}_metrics.txt\", metrics, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for gate_name, results in results_dict.items():\n",
    "    results = jnp.array(results)\n",
    "    np.savetxt(f\"{output_dir}{gate_name}_results.txt\", results, delimiter=\",\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
