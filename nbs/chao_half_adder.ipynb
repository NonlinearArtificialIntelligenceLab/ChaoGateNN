{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAX_PLATFORM_NAME=cpu\n",
      "The jaxtyping extension is already loaded. To reload it, use:\n",
      "  %reload_ext jaxtyping\n"
     ]
    }
   ],
   "source": [
    "%env JAX_PLATFORM_NAME=cpu\n",
    "\n",
    "import jaxtyping  # noqa: F401\n",
    "\n",
    "%load_ext jaxtyping\n",
    "%jaxtyping.typechecker beartype.beartype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx\n",
    "import optax\n",
    "\n",
    "from tqdm.notebook import trange\n",
    "\n",
    "from jaxtyping import Array, Bool, Float\n",
    "\n",
    "from chaogatenn.chaogate import ChaoGate\n",
    "from chaogatenn.maps import DuffingMap\n",
    "from chaogatenn.utils import grad_norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map = LogisticMap(a=4.0)\n",
    "# Map = LorenzMap(sigma=10.0, rho=28.0, beta=8/3, dt=0.01, steps=1000)\n",
    "Map = DuffingMap(\n",
    "    alpha=1.0, beta=5.0, delta=0.02, gamma=8.0, omega=0.5, dt=0.01, steps=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data for the Half Adder\n",
    "X = jnp.array([[0, 0], [0, 1], [1, 0], [1, 1]], dtype=bool)  # Input combinations\n",
    "y_sum = jnp.array([0, 1, 1, 0], dtype=bool)  # XOR gate output for Sum\n",
    "y_carry = jnp.array([0, 0, 0, 1], dtype=bool)  # AND gate output for Carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_sum_loss(\n",
    "    xor_gate: ChaoGate, x: Bool[Array, \"batch 2\"], y_sum: Bool[Array, \"batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    pred_sum = jax.vmap(xor_gate)(x)\n",
    "\n",
    "    # Binary cross-entropy loss for XOR (Sum)\n",
    "    loss_sum = -jnp.mean(\n",
    "        y_sum * jnp.log(pred_sum + 1e-15) + (1 - y_sum) * jnp.log(1 - pred_sum + 1e-15)\n",
    "    )\n",
    "\n",
    "    return loss_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_value_and_grad()\n",
    "def compute_carry_loss(\n",
    "    and_gate: ChaoGate, x: Bool[Array, \"batch 2\"], y_carry: Bool[Array, \"batch\"]\n",
    ") -> Float[Array, \"\"]:\n",
    "    pred_carry = jax.vmap(and_gate)(x)\n",
    "    # Binary cross-entropy loss for AND (Carry)\n",
    "    loss_carry = -jnp.mean(\n",
    "        y_carry * jnp.log(pred_carry + 1e-15)\n",
    "        + (1 - y_carry) * jnp.log(1 - pred_carry + 1e-15)\n",
    "    )\n",
    "\n",
    "    # Total loss is the sum of both losses\n",
    "    return loss_carry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@eqx.filter_jit\n",
    "def make_step(\n",
    "    xor_gate: ChaoGate,\n",
    "    and_gate: ChaoGate,\n",
    "    X: Bool[Array, \"batch 2\"],\n",
    "    y_sum: Bool[Array, \"batch\"],\n",
    "    y_carry: Bool[Array, \"batch \"],\n",
    "    optim: optax.GradientTransformation,\n",
    "    opt_state: optax.OptState,\n",
    ") -> (Float[Array, \"dim\"], ChaoGate, optax.OptState):  # type: ignore\n",
    "    loss_sum, grads_sum = compute_sum_loss(xor_gate, X, y_sum)\n",
    "\n",
    "    loss_carry, grads_carry = compute_carry_loss(and_gate, X, y_carry)\n",
    "\n",
    "    loss = loss_sum + loss_carry\n",
    "    updates, opt_state = optim.update([grads_sum, grads_carry], opt_state)\n",
    "\n",
    "    xor_gate = eqx.apply_updates(xor_gate, updates[0])  # type: ignore\n",
    "    and_gate = eqx.apply_updates(and_gate, updates[1])  # type: ignore\n",
    "    return loss, xor_gate, and_gate, opt_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the XOR and AND gates with random values\n",
    "xor_gate = ChaoGate(DELTA=0.5, X0=1.0, X_THRESHOLD=0.4, Map=Map)\n",
    "and_gate = ChaoGate(DELTA=0.5, X0=1.0, X_THRESHOLD=0.4, Map=Map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = optax.adabelief(learning_rate=3e-4)\n",
    "opt_state = optim.init(eqx.filter([xor_gate, and_gate], eqx.is_inexact_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6322abc3f7974682832e012cdc798640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, loss: 1.3239755630493164, grad norm: 34.50337600708008\n",
      "Epoch 1, loss: 1.300273060798645, grad norm: 33.1033821105957\n",
      "Epoch 2, loss: 1.276551604270935, grad norm: 31.577356338500977\n",
      "Epoch 3, loss: 1.2530434131622314, grad norm: 29.936603546142578\n",
      "Epoch 4, loss: 1.229955792427063, grad norm: 28.199138641357422\n",
      "Epoch 5, loss: 1.2075345516204834, grad norm: 26.383403778076172\n",
      "Epoch 6, loss: 1.1859779357910156, grad norm: 24.514856338500977\n",
      "Epoch 7, loss: 1.1655094623565674, grad norm: 22.62105369567871\n",
      "Epoch 8, loss: 1.1463145017623901, grad norm: 20.727556228637695\n",
      "Epoch 9, loss: 1.1285209655761719, grad norm: 18.86127471923828\n",
      "Epoch 10, loss: 1.1122305393218994, grad norm: 17.050796508789062\n",
      "Epoch 11, loss: 1.0975120067596436, grad norm: 15.314709663391113\n",
      "Epoch 12, loss: 1.0843632221221924, grad norm: 13.672774314880371\n",
      "Epoch 13, loss: 1.072744607925415, grad norm: 12.135438919067383\n",
      "Epoch 14, loss: 1.0625773668289185, grad norm: 10.713972091674805\n",
      "Epoch 15, loss: 1.0537739992141724, grad norm: 9.408059120178223\n",
      "Epoch 16, loss: 1.0461976528167725, grad norm: 8.219266891479492\n",
      "Epoch 17, loss: 1.0397303104400635, grad norm: 7.144393444061279\n",
      "Epoch 18, loss: 1.0342450141906738, grad norm: 6.1772637367248535\n",
      "Epoch 19, loss: 1.0296146869659424, grad norm: 5.311155796051025\n",
      "Epoch 20, loss: 1.025721788406372, grad norm: 4.5369648933410645\n",
      "Epoch 21, loss: 1.0224559307098389, grad norm: 3.8477468490600586\n",
      "Epoch 22, loss: 1.0197288990020752, grad norm: 3.2350471019744873\n",
      "Epoch 23, loss: 1.0174520015716553, grad norm: 2.691063404083252\n",
      "Epoch 24, loss: 1.0155493021011353, grad norm: 2.2094171047210693\n",
      "Epoch 25, loss: 1.013965368270874, grad norm: 1.7833465337753296\n",
      "Epoch 26, loss: 1.012641429901123, grad norm: 1.4078346490859985\n",
      "Epoch 27, loss: 1.0115313529968262, grad norm: 1.0784273147583008\n",
      "Epoch 28, loss: 1.0105957984924316, grad norm: 0.7930796146392822\n",
      "Epoch 29, loss: 1.009803056716919, grad norm: 0.5541070699691772\n",
      "Epoch 30, loss: 1.009122371673584, grad norm: 0.3741958737373352\n",
      "Epoch 31, loss: 1.0085320472717285, grad norm: 0.2908230423927307\n",
      "Epoch 32, loss: 1.0080127716064453, grad norm: 0.3276378810405731\n",
      "Epoch 33, loss: 1.0075440406799316, grad norm: 0.4278092086315155\n",
      "Epoch 34, loss: 1.0071139335632324, grad norm: 0.5403731465339661\n",
      "Epoch 35, loss: 1.0067110061645508, grad norm: 0.6477031707763672\n",
      "Epoch 36, loss: 1.0063209533691406, grad norm: 0.7450901865959167\n",
      "Epoch 37, loss: 1.005948543548584, grad norm: 0.8307716846466064\n",
      "Epoch 38, loss: 1.0055748224258423, grad norm: 0.9046643972396851\n",
      "Epoch 39, loss: 1.0051968097686768, grad norm: 0.9682278633117676\n",
      "Epoch 40, loss: 1.0048128366470337, grad norm: 1.0205425024032593\n",
      "Epoch 41, loss: 1.004417061805725, grad norm: 1.064016580581665\n",
      "Epoch 42, loss: 1.00400972366333, grad norm: 1.0979138612747192\n",
      "Epoch 43, loss: 1.0035902261734009, grad norm: 1.1238970756530762\n",
      "Epoch 44, loss: 1.0031548738479614, grad norm: 1.1421431303024292\n",
      "Epoch 45, loss: 1.0027029514312744, grad norm: 1.1531814336776733\n",
      "Epoch 46, loss: 1.0022331476211548, grad norm: 1.1578233242034912\n",
      "Epoch 47, loss: 1.0017507076263428, grad norm: 1.1563642024993896\n",
      "Epoch 48, loss: 1.0012513399124146, grad norm: 1.1493135690689087\n",
      "Epoch 49, loss: 1.000734806060791, grad norm: 1.137518048286438\n",
      "Epoch 50, loss: 1.0002083778381348, grad norm: 1.1214096546173096\n",
      "Epoch 51, loss: 0.9996666312217712, grad norm: 1.1001039743423462\n",
      "Epoch 52, loss: 0.9991111755371094, grad norm: 1.076080083847046\n",
      "Epoch 53, loss: 0.9985486268997192, grad norm: 1.0486124753952026\n",
      "Epoch 54, loss: 0.9979733824729919, grad norm: 1.0177770853042603\n",
      "Epoch 55, loss: 0.9973922967910767, grad norm: 0.9843828678131104\n",
      "Epoch 56, loss: 0.9967993497848511, grad norm: 0.9485490918159485\n",
      "Epoch 57, loss: 0.9962035417556763, grad norm: 0.9111149311065674\n",
      "Epoch 58, loss: 0.9955999255180359, grad norm: 0.8715468049049377\n",
      "Epoch 59, loss: 0.9949931502342224, grad norm: 0.830785870552063\n",
      "Epoch 60, loss: 0.9943821430206299, grad norm: 0.78924161195755\n",
      "Epoch 61, loss: 0.9937682151794434, grad norm: 0.7465914487838745\n",
      "Epoch 62, loss: 0.9931514263153076, grad norm: 0.7035518884658813\n",
      "Epoch 63, loss: 0.99253249168396, grad norm: 0.6607624292373657\n",
      "Epoch 64, loss: 0.9919154047966003, grad norm: 0.6177199482917786\n",
      "Epoch 65, loss: 0.9912901520729065, grad norm: 0.5749866962432861\n",
      "Epoch 66, loss: 0.9906711578369141, grad norm: 0.5335698127746582\n",
      "Epoch 67, loss: 0.9900482892990112, grad norm: 0.49293094873428345\n",
      "Epoch 68, loss: 0.9894257187843323, grad norm: 0.45374566316604614\n",
      "Epoch 69, loss: 0.9888064861297607, grad norm: 0.41652512550354004\n",
      "Epoch 70, loss: 0.9881854057312012, grad norm: 0.3813774585723877\n",
      "Epoch 71, loss: 0.9875656366348267, grad norm: 0.34887924790382385\n",
      "Epoch 72, loss: 0.986943781375885, grad norm: 0.3195989727973938\n",
      "Epoch 73, loss: 0.986323356628418, grad norm: 0.2935754954814911\n",
      "Epoch 74, loss: 0.9857048988342285, grad norm: 0.27198734879493713\n",
      "Epoch 75, loss: 0.9850819706916809, grad norm: 0.25507664680480957\n",
      "Epoch 76, loss: 0.9844622611999512, grad norm: 0.24282269179821014\n",
      "Epoch 77, loss: 0.9838413000106812, grad norm: 0.23557433485984802\n",
      "Epoch 78, loss: 0.9832180142402649, grad norm: 0.23279042541980743\n",
      "Epoch 79, loss: 0.9825956225395203, grad norm: 0.23396161198616028\n",
      "Epoch 80, loss: 0.9819691777229309, grad norm: 0.23857231438159943\n",
      "Epoch 81, loss: 0.98134845495224, grad norm: 0.24555495381355286\n",
      "Epoch 82, loss: 0.9807230234146118, grad norm: 0.2541879713535309\n",
      "Epoch 83, loss: 0.9800958037376404, grad norm: 0.2635062038898468\n",
      "Epoch 84, loss: 0.9794646501541138, grad norm: 0.2737349569797516\n",
      "Epoch 85, loss: 0.9788345098495483, grad norm: 0.28349247574806213\n",
      "Epoch 86, loss: 0.9782049059867859, grad norm: 0.2931463122367859\n",
      "Epoch 87, loss: 0.9775717258453369, grad norm: 0.3022707998752594\n",
      "Epoch 88, loss: 0.9769364595413208, grad norm: 0.31050536036491394\n",
      "Epoch 89, loss: 0.9763010144233704, grad norm: 0.3182179629802704\n",
      "Epoch 90, loss: 0.9756609797477722, grad norm: 0.3245736360549927\n",
      "Epoch 91, loss: 0.9750207662582397, grad norm: 0.33000314235687256\n",
      "Epoch 92, loss: 0.9743773341178894, grad norm: 0.33453112840652466\n",
      "Epoch 93, loss: 0.9737342000007629, grad norm: 0.3377496302127838\n",
      "Epoch 94, loss: 0.9730885624885559, grad norm: 0.3401605486869812\n",
      "Epoch 95, loss: 0.9724379777908325, grad norm: 0.3418135643005371\n",
      "Epoch 96, loss: 0.9717861413955688, grad norm: 0.34218108654022217\n",
      "Epoch 97, loss: 0.9711365699768066, grad norm: 0.3421594798564911\n",
      "Epoch 98, loss: 0.9704817533493042, grad norm: 0.34132760763168335\n",
      "Epoch 99, loss: 0.9698249697685242, grad norm: 0.33945852518081665\n",
      "Epoch 100, loss: 0.9691699147224426, grad norm: 0.3371865451335907\n",
      "Epoch 101, loss: 0.9685109257698059, grad norm: 0.3346266448497772\n",
      "Epoch 102, loss: 0.9678515195846558, grad norm: 0.3309294283390045\n",
      "Epoch 103, loss: 0.9671889543533325, grad norm: 0.3269692659378052\n",
      "Epoch 104, loss: 0.9665283560752869, grad norm: 0.3227035403251648\n",
      "Epoch 105, loss: 0.9658611416816711, grad norm: 0.3180167078971863\n",
      "Epoch 106, loss: 0.96519535779953, grad norm: 0.3132888376712799\n",
      "Epoch 107, loss: 0.96452796459198, grad norm: 0.30831629037857056\n",
      "Epoch 108, loss: 0.9638600945472717, grad norm: 0.3030160367488861\n",
      "Epoch 109, loss: 0.9631895422935486, grad norm: 0.2975648045539856\n",
      "Epoch 110, loss: 0.9625201225280762, grad norm: 0.2923184633255005\n",
      "Epoch 111, loss: 0.9618473649024963, grad norm: 0.2868058681488037\n",
      "Epoch 112, loss: 0.9611764550209045, grad norm: 0.28160637617111206\n",
      "Epoch 113, loss: 0.9604998826980591, grad norm: 0.27593666315078735\n",
      "Epoch 114, loss: 0.9598259925842285, grad norm: 0.2708139717578888\n",
      "Epoch 115, loss: 0.9591506719589233, grad norm: 0.2655573785305023\n",
      "Epoch 116, loss: 0.9584732055664062, grad norm: 0.26062360405921936\n",
      "Epoch 117, loss: 0.957797646522522, grad norm: 0.2557012438774109\n",
      "Epoch 118, loss: 0.9571172595024109, grad norm: 0.2510029077529907\n",
      "Epoch 119, loss: 0.9564347267150879, grad norm: 0.2462260127067566\n",
      "Epoch 120, loss: 0.955756664276123, grad norm: 0.2419130504131317\n",
      "Epoch 121, loss: 0.9550761580467224, grad norm: 0.23773232102394104\n",
      "Epoch 122, loss: 0.954391360282898, grad norm: 0.23366664350032806\n",
      "Epoch 123, loss: 0.953709602355957, grad norm: 0.2298436164855957\n",
      "Epoch 124, loss: 0.9530287384986877, grad norm: 0.22619135677814484\n",
      "Epoch 125, loss: 0.9523440599441528, grad norm: 0.22265736758708954\n",
      "Epoch 126, loss: 0.9516589641571045, grad norm: 0.2191738486289978\n",
      "Epoch 127, loss: 0.9509733319282532, grad norm: 0.21630072593688965\n",
      "Epoch 128, loss: 0.9502888321876526, grad norm: 0.21342115104198456\n",
      "Epoch 129, loss: 0.9495993256568909, grad norm: 0.21062396466732025\n",
      "Epoch 130, loss: 0.9489142298698425, grad norm: 0.20795659720897675\n",
      "Epoch 131, loss: 0.9482252597808838, grad norm: 0.20540736615657806\n",
      "Epoch 132, loss: 0.9475384950637817, grad norm: 0.20311206579208374\n",
      "Epoch 133, loss: 0.9468504190444946, grad norm: 0.20090964436531067\n",
      "Epoch 134, loss: 0.9461591839790344, grad norm: 0.19874264299869537\n",
      "Epoch 135, loss: 0.9454711675643921, grad norm: 0.19701433181762695\n",
      "Epoch 136, loss: 0.9447839260101318, grad norm: 0.1950448453426361\n",
      "Epoch 137, loss: 0.9440908432006836, grad norm: 0.19352631270885468\n",
      "Epoch 138, loss: 0.9433995485305786, grad norm: 0.19187109172344208\n",
      "Epoch 139, loss: 0.9427081942558289, grad norm: 0.19016307592391968\n",
      "Epoch 140, loss: 0.9420193433761597, grad norm: 0.18874216079711914\n",
      "Epoch 141, loss: 0.9413274526596069, grad norm: 0.18746477365493774\n",
      "Epoch 142, loss: 0.9406352639198303, grad norm: 0.18623217940330505\n",
      "Epoch 143, loss: 0.9399433135986328, grad norm: 0.18483002483844757\n",
      "Epoch 144, loss: 0.9392514824867249, grad norm: 0.18348653614521027\n",
      "Epoch 145, loss: 0.9385582208633423, grad norm: 0.18253278732299805\n",
      "Epoch 146, loss: 0.9378663897514343, grad norm: 0.18113349378108978\n",
      "Epoch 147, loss: 0.9371729493141174, grad norm: 0.18026921153068542\n",
      "Epoch 148, loss: 0.936481237411499, grad norm: 0.17909596860408783\n",
      "Epoch 149, loss: 0.9357883334159851, grad norm: 0.1782459318637848\n",
      "Epoch 150, loss: 0.9350958466529846, grad norm: 0.17720021307468414\n",
      "Epoch 151, loss: 0.9344030618667603, grad norm: 0.17631025612354279\n",
      "Epoch 152, loss: 0.9337112903594971, grad norm: 0.1754400134086609\n",
      "Epoch 153, loss: 0.9330160021781921, grad norm: 0.17453846335411072\n",
      "Epoch 154, loss: 0.9323217868804932, grad norm: 0.1735008805990219\n",
      "Epoch 155, loss: 0.9316306114196777, grad norm: 0.17264801263809204\n",
      "Epoch 156, loss: 0.9309377670288086, grad norm: 0.17146950960159302\n",
      "Epoch 157, loss: 0.930243730545044, grad norm: 0.17069914937019348\n",
      "Epoch 158, loss: 0.9295527935028076, grad norm: 0.16971682012081146\n",
      "Epoch 159, loss: 0.9288629293441772, grad norm: 0.16884849965572357\n",
      "Epoch 160, loss: 0.9281678795814514, grad norm: 0.16788464784622192\n",
      "Epoch 161, loss: 0.9274768829345703, grad norm: 0.16666696965694427\n",
      "Epoch 162, loss: 0.9267849922180176, grad norm: 0.1657640039920807\n",
      "Epoch 163, loss: 0.9260944724082947, grad norm: 0.1648736298084259\n",
      "Epoch 164, loss: 0.9254017472267151, grad norm: 0.1638244092464447\n",
      "Epoch 165, loss: 0.9247119426727295, grad norm: 0.1626460701227188\n",
      "Epoch 166, loss: 0.9240179061889648, grad norm: 0.1616382747888565\n",
      "Epoch 167, loss: 0.9233294129371643, grad norm: 0.1605207324028015\n",
      "Epoch 168, loss: 0.9226380586624146, grad norm: 0.1597144454717636\n",
      "Epoch 169, loss: 0.921947717666626, grad norm: 0.15868769586086273\n",
      "Epoch 170, loss: 0.9212585091590881, grad norm: 0.1574202924966812\n",
      "Epoch 171, loss: 0.9205700159072876, grad norm: 0.15638086199760437\n",
      "Epoch 172, loss: 0.9198806285858154, grad norm: 0.15522894263267517\n",
      "Epoch 173, loss: 0.9191927909851074, grad norm: 0.1540389209985733\n",
      "Epoch 174, loss: 0.9185043573379517, grad norm: 0.1526409089565277\n",
      "Epoch 175, loss: 0.9178149700164795, grad norm: 0.15161839127540588\n",
      "Epoch 176, loss: 0.917129635810852, grad norm: 0.15061521530151367\n",
      "Epoch 177, loss: 0.9164413213729858, grad norm: 0.14937545359134674\n",
      "Epoch 178, loss: 0.9157569408416748, grad norm: 0.14839161932468414\n",
      "Epoch 179, loss: 0.9150711297988892, grad norm: 0.14703288674354553\n",
      "Epoch 180, loss: 0.9143856167793274, grad norm: 0.14587271213531494\n",
      "Epoch 181, loss: 0.9137001037597656, grad norm: 0.14481206238269806\n",
      "Epoch 182, loss: 0.913015604019165, grad norm: 0.14378583431243896\n",
      "Epoch 183, loss: 0.9123321175575256, grad norm: 0.14281101524829865\n",
      "Epoch 184, loss: 0.9116485118865967, grad norm: 0.14156031608581543\n",
      "Epoch 185, loss: 0.9109647274017334, grad norm: 0.14053046703338623\n",
      "Epoch 186, loss: 0.9102827906608582, grad norm: 0.1397230476140976\n",
      "Epoch 187, loss: 0.9096019864082336, grad norm: 0.1383751630783081\n",
      "Epoch 188, loss: 0.9089204668998718, grad norm: 0.13747850060462952\n",
      "Epoch 189, loss: 0.9082397222518921, grad norm: 0.13641414046287537\n",
      "Epoch 190, loss: 0.9075628519058228, grad norm: 0.1353270560503006\n",
      "Epoch 191, loss: 0.9068810939788818, grad norm: 0.13444896042346954\n",
      "Epoch 192, loss: 0.9062055349349976, grad norm: 0.13341112434864044\n",
      "Epoch 193, loss: 0.9055275321006775, grad norm: 0.13249363005161285\n",
      "Epoch 194, loss: 0.9048510789871216, grad norm: 0.13145238161087036\n",
      "Epoch 195, loss: 0.904175877571106, grad norm: 0.13070425391197205\n",
      "Epoch 196, loss: 0.9034988880157471, grad norm: 0.12962724268436432\n",
      "Epoch 197, loss: 0.9028242230415344, grad norm: 0.12886962294578552\n",
      "Epoch 198, loss: 0.9021511077880859, grad norm: 0.12809230387210846\n",
      "Epoch 199, loss: 0.9014784097671509, grad norm: 0.12727981805801392\n",
      "Epoch 200, loss: 0.9008055925369263, grad norm: 0.12639203667640686\n",
      "Epoch 201, loss: 0.9001341462135315, grad norm: 0.12563015520572662\n",
      "Epoch 202, loss: 0.8994625806808472, grad norm: 0.12506461143493652\n",
      "Epoch 203, loss: 0.8987938165664673, grad norm: 0.12424340099096298\n",
      "Epoch 204, loss: 0.8981245756149292, grad norm: 0.12362703680992126\n",
      "Epoch 205, loss: 0.8974564671516418, grad norm: 0.12290209531784058\n",
      "Epoch 206, loss: 0.8967874646186829, grad norm: 0.12227001041173935\n",
      "Epoch 207, loss: 0.8961233496665955, grad norm: 0.12177282571792603\n",
      "Epoch 208, loss: 0.89545738697052, grad norm: 0.12117379158735275\n",
      "Epoch 209, loss: 0.8947896361351013, grad norm: 0.12068405747413635\n",
      "Epoch 210, loss: 0.8941280841827393, grad norm: 0.12002885341644287\n",
      "Epoch 211, loss: 0.8934649229049683, grad norm: 0.11966618150472641\n",
      "Epoch 212, loss: 0.89280104637146, grad norm: 0.11932796984910965\n",
      "Epoch 213, loss: 0.8921382427215576, grad norm: 0.1187901645898819\n",
      "Epoch 214, loss: 0.8914811611175537, grad norm: 0.11832644045352936\n",
      "Epoch 215, loss: 0.8908205032348633, grad norm: 0.11784171313047409\n",
      "Epoch 216, loss: 0.8901622295379639, grad norm: 0.1176229864358902\n",
      "Epoch 217, loss: 0.8895050287246704, grad norm: 0.11715815961360931\n",
      "Epoch 218, loss: 0.8888481855392456, grad norm: 0.11692621558904648\n",
      "Epoch 219, loss: 0.8881925344467163, grad norm: 0.1165647953748703\n",
      "Epoch 220, loss: 0.887535810470581, grad norm: 0.11628443002700806\n",
      "Epoch 221, loss: 0.8868851065635681, grad norm: 0.11593414843082428\n",
      "Epoch 222, loss: 0.8862296342849731, grad norm: 0.11573519557714462\n",
      "Epoch 223, loss: 0.8855786919593811, grad norm: 0.11551027745008469\n",
      "Epoch 224, loss: 0.8849290013313293, grad norm: 0.11536911129951477\n",
      "Epoch 225, loss: 0.8842807412147522, grad norm: 0.11506098508834839\n",
      "Epoch 226, loss: 0.8836315870285034, grad norm: 0.11484352499246597\n",
      "Epoch 227, loss: 0.8829846382141113, grad norm: 0.1149006336927414\n",
      "Epoch 228, loss: 0.8823371529579163, grad norm: 0.11468793451786041\n",
      "Epoch 229, loss: 0.8816913366317749, grad norm: 0.1146281361579895\n",
      "Epoch 230, loss: 0.8810491561889648, grad norm: 0.11462906748056412\n",
      "Epoch 231, loss: 0.8804024457931519, grad norm: 0.11442185193300247\n",
      "Epoch 232, loss: 0.8797613382339478, grad norm: 0.11460943520069122\n",
      "Epoch 233, loss: 0.8791215419769287, grad norm: 0.11438705027103424\n",
      "Epoch 234, loss: 0.8784801959991455, grad norm: 0.11454682797193527\n",
      "Epoch 235, loss: 0.877839982509613, grad norm: 0.1145673468708992\n",
      "Epoch 236, loss: 0.8772025108337402, grad norm: 0.11457279324531555\n",
      "Epoch 237, loss: 0.8765656352043152, grad norm: 0.11470472812652588\n",
      "Epoch 238, loss: 0.8759296536445618, grad norm: 0.11487443000078201\n",
      "Epoch 239, loss: 0.8752964735031128, grad norm: 0.11472050100564957\n",
      "Epoch 240, loss: 0.8746614456176758, grad norm: 0.11499209702014923\n",
      "Epoch 241, loss: 0.8740300536155701, grad norm: 0.11500264704227448\n",
      "Epoch 242, loss: 0.8733986020088196, grad norm: 0.11520934849977493\n",
      "Epoch 243, loss: 0.8727678060531616, grad norm: 0.11538226902484894\n",
      "Epoch 244, loss: 0.8721393346786499, grad norm: 0.11566879600286484\n",
      "Epoch 245, loss: 0.8715130090713501, grad norm: 0.11590149253606796\n",
      "Epoch 246, loss: 0.8708842992782593, grad norm: 0.11609510332345963\n",
      "Epoch 247, loss: 0.87026047706604, grad norm: 0.11649051308631897\n",
      "Epoch 248, loss: 0.869636058807373, grad norm: 0.1165396198630333\n",
      "Epoch 249, loss: 0.8690130710601807, grad norm: 0.1169842779636383\n",
      "Epoch 250, loss: 0.8683922290802002, grad norm: 0.1172449067234993\n",
      "Epoch 251, loss: 0.8677701354026794, grad norm: 0.11771491914987564\n",
      "Epoch 252, loss: 0.8671505451202393, grad norm: 0.11800627410411835\n",
      "Epoch 253, loss: 0.8665330410003662, grad norm: 0.11837486922740936\n",
      "Epoch 254, loss: 0.8659153580665588, grad norm: 0.11872387677431107\n",
      "Epoch 255, loss: 0.8652995228767395, grad norm: 0.1190948337316513\n",
      "Epoch 256, loss: 0.8646842837333679, grad norm: 0.11944530159235\n",
      "Epoch 257, loss: 0.8640701770782471, grad norm: 0.12000614404678345\n",
      "Epoch 258, loss: 0.8634589910507202, grad norm: 0.12037321925163269\n",
      "Epoch 259, loss: 0.8628473877906799, grad norm: 0.12092317640781403\n",
      "Epoch 260, loss: 0.8622368574142456, grad norm: 0.12136591970920563\n",
      "Epoch 261, loss: 0.861627459526062, grad norm: 0.12184592336416245\n",
      "Epoch 262, loss: 0.8610193133354187, grad norm: 0.12226961553096771\n",
      "Epoch 263, loss: 0.8604142665863037, grad norm: 0.12275667488574982\n",
      "Epoch 264, loss: 0.8598113059997559, grad norm: 0.12327636033296585\n",
      "Epoch 265, loss: 0.859205424785614, grad norm: 0.12385942786931992\n",
      "Epoch 266, loss: 0.8586035966873169, grad norm: 0.12437533587217331\n",
      "Epoch 267, loss: 0.8580011129379272, grad norm: 0.12492203712463379\n",
      "Epoch 268, loss: 0.8574017286300659, grad norm: 0.12551671266555786\n",
      "Epoch 269, loss: 0.8568028211593628, grad norm: 0.12610331177711487\n",
      "Epoch 270, loss: 0.8562076687812805, grad norm: 0.12669940292835236\n",
      "Epoch 271, loss: 0.8556109666824341, grad norm: 0.12724505364894867\n",
      "Epoch 272, loss: 0.8550163507461548, grad norm: 0.127890944480896\n",
      "Epoch 273, loss: 0.8544203639030457, grad norm: 0.12845978140830994\n",
      "Epoch 274, loss: 0.8538300395011902, grad norm: 0.12912267446517944\n",
      "Epoch 275, loss: 0.8532364964485168, grad norm: 0.12974554300308228\n",
      "Epoch 276, loss: 0.8526484966278076, grad norm: 0.13043442368507385\n",
      "Epoch 277, loss: 0.852057695388794, grad norm: 0.1310444176197052\n",
      "Epoch 278, loss: 0.8514719009399414, grad norm: 0.13170640170574188\n",
      "Epoch 279, loss: 0.8508862853050232, grad norm: 0.13233759999275208\n",
      "Epoch 280, loss: 0.8503006100654602, grad norm: 0.13303887844085693\n",
      "Epoch 281, loss: 0.8497189283370972, grad norm: 0.1337403506040573\n",
      "Epoch 282, loss: 0.8491368293762207, grad norm: 0.13435858488082886\n",
      "Epoch 283, loss: 0.8485550880432129, grad norm: 0.1350591629743576\n",
      "Epoch 284, loss: 0.8479758501052856, grad norm: 0.13577166199684143\n",
      "Epoch 285, loss: 0.8473983407020569, grad norm: 0.13650815188884735\n",
      "Epoch 286, loss: 0.8468197584152222, grad norm: 0.13717298209667206\n",
      "Epoch 287, loss: 0.846244215965271, grad norm: 0.13789445161819458\n",
      "Epoch 288, loss: 0.8456709384918213, grad norm: 0.1386326402425766\n",
      "Epoch 289, loss: 0.8450994491577148, grad norm: 0.13936667144298553\n",
      "Epoch 290, loss: 0.844523549079895, grad norm: 0.140077143907547\n",
      "Epoch 291, loss: 0.8439557552337646, grad norm: 0.140802800655365\n",
      "Epoch 292, loss: 0.8433846235275269, grad norm: 0.1415242701768875\n",
      "Epoch 293, loss: 0.842819094657898, grad norm: 0.14227765798568726\n",
      "Epoch 294, loss: 0.8422507047653198, grad norm: 0.1430167406797409\n",
      "Epoch 295, loss: 0.8416861891746521, grad norm: 0.1437629759311676\n",
      "Epoch 296, loss: 0.8411219120025635, grad norm: 0.1445063352584839\n",
      "Epoch 297, loss: 0.840562105178833, grad norm: 0.14524006843566895\n",
      "Epoch 298, loss: 0.8400003910064697, grad norm: 0.14600278437137604\n",
      "Epoch 299, loss: 0.8394411206245422, grad norm: 0.1467437744140625\n",
      "Epoch 300, loss: 0.83888179063797, grad norm: 0.1475251019001007\n",
      "Epoch 301, loss: 0.838323175907135, grad norm: 0.14829234778881073\n",
      "Epoch 302, loss: 0.837766170501709, grad norm: 0.149074986577034\n",
      "Epoch 303, loss: 0.8372129201889038, grad norm: 0.1498221755027771\n",
      "Epoch 304, loss: 0.8366585969924927, grad norm: 0.15062062442302704\n",
      "Epoch 305, loss: 0.8361069560050964, grad norm: 0.15139256417751312\n",
      "Epoch 306, loss: 0.8355560898780823, grad norm: 0.15214936435222626\n",
      "Epoch 307, loss: 0.8350070714950562, grad norm: 0.15295366942882538\n",
      "Epoch 308, loss: 0.8344584107398987, grad norm: 0.1536719799041748\n",
      "Epoch 309, loss: 0.8339159488677979, grad norm: 0.15447184443473816\n",
      "Epoch 310, loss: 0.8333688378334045, grad norm: 0.15524327754974365\n",
      "Epoch 311, loss: 0.8328233957290649, grad norm: 0.15602220594882965\n",
      "Epoch 312, loss: 0.8322814106941223, grad norm: 0.15681125223636627\n",
      "Epoch 313, loss: 0.8317396640777588, grad norm: 0.15759527683258057\n",
      "Epoch 314, loss: 0.8311992883682251, grad norm: 0.15838509798049927\n",
      "Epoch 315, loss: 0.8306593894958496, grad norm: 0.15914858877658844\n",
      "Epoch 316, loss: 0.8301229476928711, grad norm: 0.1599300652742386\n",
      "Epoch 317, loss: 0.829586386680603, grad norm: 0.16071632504463196\n",
      "Epoch 318, loss: 0.829052209854126, grad norm: 0.1615026444196701\n",
      "Epoch 319, loss: 0.8285195827484131, grad norm: 0.16226640343666077\n",
      "Epoch 320, loss: 0.8279860019683838, grad norm: 0.16305199265480042\n",
      "Epoch 321, loss: 0.8274557590484619, grad norm: 0.16383016109466553\n",
      "Epoch 322, loss: 0.8269264698028564, grad norm: 0.16461195051670074\n",
      "Epoch 323, loss: 0.8263978362083435, grad norm: 0.16540254652500153\n",
      "Epoch 324, loss: 0.825872540473938, grad norm: 0.16617365181446075\n",
      "Epoch 325, loss: 0.825345516204834, grad norm: 0.16694676876068115\n",
      "Epoch 326, loss: 0.8248213529586792, grad norm: 0.16770070791244507\n",
      "Epoch 327, loss: 0.8243004083633423, grad norm: 0.1684795469045639\n",
      "Epoch 328, loss: 0.823777437210083, grad norm: 0.16928604245185852\n",
      "Epoch 329, loss: 0.8232565522193909, grad norm: 0.1700436919927597\n",
      "Epoch 330, loss: 0.8227375745773315, grad norm: 0.17083662748336792\n",
      "Epoch 331, loss: 0.8222193121910095, grad norm: 0.1715632826089859\n",
      "Epoch 332, loss: 0.821705162525177, grad norm: 0.17234298586845398\n",
      "Epoch 333, loss: 0.8211902379989624, grad norm: 0.1731099784374237\n",
      "Epoch 334, loss: 0.820675253868103, grad norm: 0.17384721338748932\n",
      "Epoch 335, loss: 0.820166289806366, grad norm: 0.17464172840118408\n",
      "Epoch 336, loss: 0.8196527361869812, grad norm: 0.17538972198963165\n",
      "Epoch 337, loss: 0.8191438913345337, grad norm: 0.17615193128585815\n",
      "Epoch 338, loss: 0.8186353445053101, grad norm: 0.1769145280122757\n",
      "Epoch 339, loss: 0.8181271553039551, grad norm: 0.1776767522096634\n",
      "Epoch 340, loss: 0.8176225423812866, grad norm: 0.17838899791240692\n",
      "Epoch 341, loss: 0.8171210289001465, grad norm: 0.17915040254592896\n",
      "Epoch 342, loss: 0.8166162371635437, grad norm: 0.17991575598716736\n",
      "Epoch 343, loss: 0.8161146640777588, grad norm: 0.18069659173488617\n",
      "Epoch 344, loss: 0.8156125545501709, grad norm: 0.18139095604419708\n",
      "Epoch 345, loss: 0.8151153922080994, grad norm: 0.18215367197990417\n",
      "Epoch 346, loss: 0.8146172761917114, grad norm: 0.18292976915836334\n",
      "Epoch 347, loss: 0.8141188025474548, grad norm: 0.18363523483276367\n",
      "Epoch 348, loss: 0.8136250972747803, grad norm: 0.18437114357948303\n",
      "Epoch 349, loss: 0.8131301403045654, grad norm: 0.18509343266487122\n",
      "Epoch 350, loss: 0.812638521194458, grad norm: 0.1858590990304947\n",
      "Epoch 351, loss: 0.8121451735496521, grad norm: 0.18654003739356995\n",
      "Epoch 352, loss: 0.8116568922996521, grad norm: 0.18727819621562958\n",
      "Epoch 353, loss: 0.8111674785614014, grad norm: 0.1880093514919281\n",
      "Epoch 354, loss: 0.8106814026832581, grad norm: 0.18869735300540924\n",
      "Epoch 355, loss: 0.8101952075958252, grad norm: 0.18943257629871368\n",
      "Epoch 356, loss: 0.8097108602523804, grad norm: 0.1901290863752365\n",
      "Epoch 357, loss: 0.8092280626296997, grad norm: 0.1908135861158371\n",
      "Epoch 358, loss: 0.8087461590766907, grad norm: 0.19155055284500122\n",
      "Epoch 359, loss: 0.8082642555236816, grad norm: 0.19231203198432922\n",
      "Epoch 360, loss: 0.807783305644989, grad norm: 0.19298318028450012\n",
      "Epoch 361, loss: 0.807304859161377, grad norm: 0.1936883181333542\n",
      "Epoch 362, loss: 0.806828498840332, grad norm: 0.1943572759628296\n",
      "Epoch 363, loss: 0.8063536286354065, grad norm: 0.1950988620519638\n",
      "Epoch 364, loss: 0.8058772683143616, grad norm: 0.19573713839054108\n",
      "Epoch 365, loss: 0.8054059743881226, grad norm: 0.19647258520126343\n",
      "Epoch 366, loss: 0.8049310445785522, grad norm: 0.19715183973312378\n",
      "Epoch 367, loss: 0.8044618964195251, grad norm: 0.19778096675872803\n",
      "Epoch 368, loss: 0.803993821144104, grad norm: 0.19852495193481445\n",
      "Epoch 369, loss: 0.8035250306129456, grad norm: 0.19918182492256165\n",
      "Epoch 370, loss: 0.8030592203140259, grad norm: 0.199872225522995\n",
      "Epoch 371, loss: 0.8025916218757629, grad norm: 0.20048639178276062\n",
      "Epoch 372, loss: 0.8021289110183716, grad norm: 0.20117144286632538\n",
      "Epoch 373, loss: 0.801666259765625, grad norm: 0.20187000930309296\n",
      "Epoch 374, loss: 0.8012028336524963, grad norm: 0.20249396562576294\n",
      "Epoch 375, loss: 0.800742506980896, grad norm: 0.20318108797073364\n",
      "Epoch 376, loss: 0.8002835512161255, grad norm: 0.2037697583436966\n",
      "Epoch 377, loss: 0.7998251914978027, grad norm: 0.2044234275817871\n",
      "Epoch 378, loss: 0.7993687987327576, grad norm: 0.20506921410560608\n",
      "Epoch 379, loss: 0.7989132404327393, grad norm: 0.20570717751979828\n",
      "Epoch 380, loss: 0.7984604239463806, grad norm: 0.20635877549648285\n",
      "Epoch 381, loss: 0.7980083227157593, grad norm: 0.2070121169090271\n",
      "Epoch 382, loss: 0.797552764415741, grad norm: 0.2076263576745987\n",
      "Epoch 383, loss: 0.7971037030220032, grad norm: 0.20823082327842712\n",
      "Epoch 384, loss: 0.7966547012329102, grad norm: 0.2088768184185028\n",
      "Epoch 385, loss: 0.7962062358856201, grad norm: 0.20944824814796448\n",
      "Epoch 386, loss: 0.7957618236541748, grad norm: 0.21013346314430237\n",
      "Epoch 387, loss: 0.7953134775161743, grad norm: 0.21073390543460846\n",
      "Epoch 388, loss: 0.7948697805404663, grad norm: 0.21129286289215088\n",
      "Epoch 389, loss: 0.7944265604019165, grad norm: 0.21196305751800537\n",
      "Epoch 390, loss: 0.7939848303794861, grad norm: 0.21250998973846436\n",
      "Epoch 391, loss: 0.7935446500778198, grad norm: 0.21318405866622925\n",
      "Epoch 392, loss: 0.7931050658226013, grad norm: 0.21373848617076874\n",
      "Epoch 393, loss: 0.7926672697067261, grad norm: 0.21438048779964447\n",
      "Epoch 394, loss: 0.7922284603118896, grad norm: 0.21493178606033325\n",
      "Epoch 395, loss: 0.7917933464050293, grad norm: 0.2154908925294876\n",
      "Epoch 396, loss: 0.791361391544342, grad norm: 0.21610747277736664\n",
      "Epoch 397, loss: 0.7909269332885742, grad norm: 0.2166370302438736\n",
      "Epoch 398, loss: 0.7904950380325317, grad norm: 0.21724963188171387\n",
      "Epoch 399, loss: 0.7900631427764893, grad norm: 0.21783095598220825\n",
      "Epoch 400, loss: 0.7896338701248169, grad norm: 0.21832510828971863\n",
      "Epoch 401, loss: 0.7892050743103027, grad norm: 0.21890532970428467\n",
      "Epoch 402, loss: 0.7887776494026184, grad norm: 0.21946854889392853\n",
      "Epoch 403, loss: 0.7883515357971191, grad norm: 0.22005988657474518\n",
      "Epoch 404, loss: 0.7879250049591064, grad norm: 0.22059711813926697\n",
      "Epoch 405, loss: 0.7875034213066101, grad norm: 0.22122053802013397\n",
      "Epoch 406, loss: 0.787079930305481, grad norm: 0.2217046171426773\n",
      "Epoch 407, loss: 0.7866593599319458, grad norm: 0.22224122285842896\n",
      "Epoch 408, loss: 0.7862390279769897, grad norm: 0.2228839248418808\n",
      "Epoch 409, loss: 0.7858192920684814, grad norm: 0.22335411608219147\n",
      "Epoch 410, loss: 0.7854008674621582, grad norm: 0.22392737865447998\n",
      "Epoch 411, loss: 0.7849856019020081, grad norm: 0.2245083600282669\n",
      "Epoch 412, loss: 0.7845690846443176, grad norm: 0.2249726951122284\n",
      "Epoch 413, loss: 0.7841559648513794, grad norm: 0.22547535598278046\n",
      "Epoch 414, loss: 0.7837423086166382, grad norm: 0.22604595124721527\n",
      "Epoch 415, loss: 0.7833305597305298, grad norm: 0.2264697551727295\n",
      "Epoch 416, loss: 0.7829192876815796, grad norm: 0.22705279290676117\n",
      "Epoch 417, loss: 0.7825099229812622, grad norm: 0.2274910807609558\n",
      "Epoch 418, loss: 0.7821024656295776, grad norm: 0.22803321480751038\n",
      "Epoch 419, loss: 0.7816938161849976, grad norm: 0.22847501933574677\n",
      "Epoch 420, loss: 0.7812877893447876, grad norm: 0.22902651131153107\n",
      "Epoch 421, loss: 0.7808816432952881, grad norm: 0.2295287847518921\n",
      "Epoch 422, loss: 0.7804783582687378, grad norm: 0.22993104159832\n",
      "Epoch 423, loss: 0.7800765037536621, grad norm: 0.2304488718509674\n",
      "Epoch 424, loss: 0.779674768447876, grad norm: 0.23088692128658295\n",
      "Epoch 425, loss: 0.7792750597000122, grad norm: 0.231409952044487\n",
      "Epoch 426, loss: 0.7788741588592529, grad norm: 0.2319016009569168\n",
      "Epoch 427, loss: 0.7784743309020996, grad norm: 0.23240025341510773\n",
      "Epoch 428, loss: 0.7780787944793701, grad norm: 0.23288896679878235\n",
      "Epoch 429, loss: 0.7776827812194824, grad norm: 0.2332373857498169\n",
      "Epoch 430, loss: 0.7772882580757141, grad norm: 0.23381860554218292\n",
      "Epoch 431, loss: 0.776892900466919, grad norm: 0.23416689038276672\n",
      "Epoch 432, loss: 0.7765032052993774, grad norm: 0.23468726873397827\n",
      "Epoch 433, loss: 0.7761106491088867, grad norm: 0.23517224192619324\n",
      "Epoch 434, loss: 0.7757196426391602, grad norm: 0.2356308400630951\n",
      "Epoch 435, loss: 0.7753292322158813, grad norm: 0.23601894080638885\n",
      "Epoch 436, loss: 0.7749446630477905, grad norm: 0.23644106090068817\n",
      "Epoch 437, loss: 0.7745556831359863, grad norm: 0.23690861463546753\n",
      "Epoch 438, loss: 0.7741701602935791, grad norm: 0.23735970258712769\n",
      "Epoch 439, loss: 0.7737855911254883, grad norm: 0.23784595727920532\n",
      "Epoch 440, loss: 0.7733996510505676, grad norm: 0.23834554851055145\n",
      "Epoch 441, loss: 0.7730158567428589, grad norm: 0.2386336475610733\n",
      "Epoch 442, loss: 0.7726361751556396, grad norm: 0.23910318315029144\n",
      "Epoch 443, loss: 0.7722572088241577, grad norm: 0.23958426713943481\n",
      "Epoch 444, loss: 0.771877110004425, grad norm: 0.23993487656116486\n",
      "Epoch 445, loss: 0.7714956998825073, grad norm: 0.24030183255672455\n",
      "Epoch 446, loss: 0.7711212635040283, grad norm: 0.240727499127388\n",
      "Epoch 447, loss: 0.7707453966140747, grad norm: 0.24116107821464539\n",
      "Epoch 448, loss: 0.7703689336776733, grad norm: 0.24161404371261597\n",
      "Epoch 449, loss: 0.7699939608573914, grad norm: 0.24191924929618835\n",
      "Epoch 450, loss: 0.7696229219436646, grad norm: 0.24242332577705383\n",
      "Epoch 451, loss: 0.7692492604255676, grad norm: 0.24279658496379852\n",
      "Epoch 452, loss: 0.7688788771629333, grad norm: 0.24314182996749878\n",
      "Epoch 453, loss: 0.7685074806213379, grad norm: 0.24360233545303345\n",
      "Epoch 454, loss: 0.7681384086608887, grad norm: 0.2439727783203125\n",
      "Epoch 455, loss: 0.7677700519561768, grad norm: 0.24430325627326965\n",
      "Epoch 456, loss: 0.7674049139022827, grad norm: 0.24468106031417847\n",
      "Epoch 457, loss: 0.7670392990112305, grad norm: 0.24502508342266083\n",
      "Epoch 458, loss: 0.766674280166626, grad norm: 0.24546056985855103\n",
      "Epoch 459, loss: 0.7663109302520752, grad norm: 0.24583765864372253\n",
      "Epoch 460, loss: 0.7659482955932617, grad norm: 0.24621112644672394\n",
      "Epoch 461, loss: 0.7655848264694214, grad norm: 0.24653179943561554\n",
      "Epoch 462, loss: 0.7652245759963989, grad norm: 0.2468372881412506\n",
      "Epoch 463, loss: 0.7648658156394958, grad norm: 0.2472466677427292\n",
      "Epoch 464, loss: 0.7645057439804077, grad norm: 0.2476002275943756\n",
      "Epoch 465, loss: 0.7641485929489136, grad norm: 0.24800905585289001\n",
      "Epoch 466, loss: 0.7637917995452881, grad norm: 0.24823708832263947\n",
      "Epoch 467, loss: 0.7634367942810059, grad norm: 0.24866873025894165\n",
      "Epoch 468, loss: 0.7630816102027893, grad norm: 0.24902063608169556\n",
      "Epoch 469, loss: 0.7627259492874146, grad norm: 0.24932801723480225\n",
      "Epoch 470, loss: 0.7623742818832397, grad norm: 0.24961920082569122\n",
      "Epoch 471, loss: 0.7620232105255127, grad norm: 0.2500365376472473\n",
      "Epoch 472, loss: 0.7616726160049438, grad norm: 0.2502920627593994\n",
      "Epoch 473, loss: 0.761322021484375, grad norm: 0.2505829930305481\n",
      "Epoch 474, loss: 0.7609747648239136, grad norm: 0.2509468197822571\n",
      "Epoch 475, loss: 0.7606244087219238, grad norm: 0.2512286901473999\n",
      "Epoch 476, loss: 0.7602807283401489, grad norm: 0.2516230642795563\n",
      "Epoch 477, loss: 0.7599342465400696, grad norm: 0.2519341707229614\n",
      "Epoch 478, loss: 0.7595870494842529, grad norm: 0.2521815896034241\n",
      "Epoch 479, loss: 0.7592453956604004, grad norm: 0.2525072395801544\n",
      "Epoch 480, loss: 0.7589011788368225, grad norm: 0.2528691589832306\n",
      "Epoch 481, loss: 0.7585574984550476, grad norm: 0.25320643186569214\n",
      "Epoch 482, loss: 0.7582190036773682, grad norm: 0.2534233331680298\n",
      "Epoch 483, loss: 0.7578780055046082, grad norm: 0.2537578344345093\n",
      "Epoch 484, loss: 0.7575376629829407, grad norm: 0.2540453374385834\n",
      "Epoch 485, loss: 0.7571997046470642, grad norm: 0.2543114721775055\n",
      "Epoch 486, loss: 0.7568629384040833, grad norm: 0.25457963347435\n",
      "Epoch 487, loss: 0.7565268278121948, grad norm: 0.2550100088119507\n",
      "Epoch 488, loss: 0.7561913132667542, grad norm: 0.2553007900714874\n",
      "Epoch 489, loss: 0.7558561563491821, grad norm: 0.25549986958503723\n",
      "Epoch 490, loss: 0.755523681640625, grad norm: 0.2558338940143585\n",
      "Epoch 491, loss: 0.7551891207695007, grad norm: 0.25608572363853455\n",
      "Epoch 492, loss: 0.7548583149909973, grad norm: 0.2563418447971344\n",
      "Epoch 493, loss: 0.7545286417007446, grad norm: 0.2566598951816559\n",
      "Epoch 494, loss: 0.7541980147361755, grad norm: 0.256881445646286\n",
      "Epoch 495, loss: 0.7538682222366333, grad norm: 0.257245808839798\n",
      "Epoch 496, loss: 0.7535405158996582, grad norm: 0.25748559832572937\n",
      "Epoch 497, loss: 0.7532137632369995, grad norm: 0.25773105025291443\n",
      "Epoch 498, loss: 0.7528867721557617, grad norm: 0.2580679655075073\n",
      "Epoch 499, loss: 0.7525602579116821, grad norm: 0.25826549530029297\n",
      "Epoch 500, loss: 0.7522359490394592, grad norm: 0.2585048973560333\n",
      "Epoch 501, loss: 0.7519130110740662, grad norm: 0.2588295340538025\n",
      "Epoch 502, loss: 0.7515889406204224, grad norm: 0.2590843439102173\n",
      "Epoch 503, loss: 0.7512679100036621, grad norm: 0.2592383921146393\n",
      "Epoch 504, loss: 0.750946581363678, grad norm: 0.2595549523830414\n",
      "Epoch 505, loss: 0.7506244778633118, grad norm: 0.2597411870956421\n",
      "Epoch 506, loss: 0.750307023525238, grad norm: 0.259992778301239\n",
      "Epoch 507, loss: 0.7499876022338867, grad norm: 0.2602091431617737\n",
      "Epoch 508, loss: 0.7496695518493652, grad norm: 0.26053038239479065\n",
      "Epoch 509, loss: 0.7493528127670288, grad norm: 0.2607116997241974\n",
      "Epoch 510, loss: 0.7490344047546387, grad norm: 0.26096484065055847\n",
      "Epoch 511, loss: 0.7487198710441589, grad norm: 0.2611980140209198\n",
      "Epoch 512, loss: 0.7484056949615479, grad norm: 0.2613506019115448\n",
      "Epoch 513, loss: 0.7480931282043457, grad norm: 0.2616547644138336\n",
      "Epoch 514, loss: 0.7477810382843018, grad norm: 0.2617276906967163\n",
      "Epoch 515, loss: 0.7474699020385742, grad norm: 0.26208773255348206\n",
      "Epoch 516, loss: 0.7471568584442139, grad norm: 0.26229748129844666\n",
      "Epoch 517, loss: 0.7468457221984863, grad norm: 0.2625185549259186\n",
      "Epoch 518, loss: 0.7465368509292603, grad norm: 0.26273778080940247\n",
      "Epoch 519, loss: 0.7462276816368103, grad norm: 0.26282837986946106\n",
      "Epoch 520, loss: 0.7459208965301514, grad norm: 0.2631399631500244\n",
      "Epoch 521, loss: 0.745612382888794, grad norm: 0.2633552551269531\n",
      "Epoch 522, loss: 0.745307207107544, grad norm: 0.26361963152885437\n",
      "Epoch 523, loss: 0.7450007200241089, grad norm: 0.2637646198272705\n",
      "Epoch 524, loss: 0.7446961402893066, grad norm: 0.2639447748661041\n",
      "Epoch 525, loss: 0.7443926334381104, grad norm: 0.26420921087265015\n",
      "Epoch 526, loss: 0.7440888285636902, grad norm: 0.264401912689209\n",
      "Epoch 527, loss: 0.7437877058982849, grad norm: 0.2646198272705078\n",
      "Epoch 528, loss: 0.7434858083724976, grad norm: 0.26478931307792664\n",
      "Epoch 529, loss: 0.7431857585906982, grad norm: 0.26498866081237793\n",
      "Epoch 530, loss: 0.7428827285766602, grad norm: 0.2652007043361664\n",
      "Epoch 531, loss: 0.7425844669342041, grad norm: 0.2655746340751648\n",
      "Epoch 532, loss: 0.7422842383384705, grad norm: 0.26564693450927734\n",
      "Epoch 533, loss: 0.7419872283935547, grad norm: 0.26585856080055237\n",
      "Epoch 534, loss: 0.7416893243789673, grad norm: 0.26597627997398376\n",
      "Epoch 535, loss: 0.7413942813873291, grad norm: 0.2661639153957367\n",
      "Epoch 536, loss: 0.7410995960235596, grad norm: 0.26640990376472473\n",
      "Epoch 537, loss: 0.740801990032196, grad norm: 0.2666056156158447\n",
      "Epoch 538, loss: 0.7405076026916504, grad norm: 0.26674190163612366\n",
      "Epoch 539, loss: 0.7402147054672241, grad norm: 0.26690515875816345\n",
      "Epoch 540, loss: 0.7399216294288635, grad norm: 0.2671234607696533\n",
      "Epoch 541, loss: 0.7396304607391357, grad norm: 0.26723527908325195\n",
      "Epoch 542, loss: 0.7393385171890259, grad norm: 0.26749542355537415\n",
      "Epoch 543, loss: 0.7390478849411011, grad norm: 0.2675597071647644\n",
      "Epoch 544, loss: 0.7387588024139404, grad norm: 0.2678264081478119\n",
      "Epoch 545, loss: 0.7384675741195679, grad norm: 0.2678670585155487\n",
      "Epoch 546, loss: 0.7381801605224609, grad norm: 0.26813676953315735\n",
      "Epoch 547, loss: 0.7378926873207092, grad norm: 0.2682996690273285\n",
      "Epoch 548, loss: 0.7376056909561157, grad norm: 0.2683703899383545\n",
      "Epoch 549, loss: 0.7373197674751282, grad norm: 0.2686399817466736\n",
      "Epoch 550, loss: 0.7370295524597168, grad norm: 0.26875001192092896\n",
      "Epoch 551, loss: 0.7367473244667053, grad norm: 0.2688426375389099\n",
      "Epoch 552, loss: 0.7364620566368103, grad norm: 0.26900389790534973\n",
      "Epoch 553, loss: 0.7361793518066406, grad norm: 0.26923736929893494\n",
      "Epoch 554, loss: 0.7358951568603516, grad norm: 0.2693920433521271\n",
      "Epoch 555, loss: 0.7356134653091431, grad norm: 0.2695377469062805\n",
      "Epoch 556, loss: 0.7353304624557495, grad norm: 0.26970502734184265\n",
      "Epoch 557, loss: 0.7350485324859619, grad norm: 0.26987212896347046\n",
      "Epoch 558, loss: 0.7347695827484131, grad norm: 0.2699737846851349\n",
      "Epoch 559, loss: 0.7344895601272583, grad norm: 0.2702210545539856\n",
      "Epoch 560, loss: 0.7342082262039185, grad norm: 0.27035218477249146\n",
      "Epoch 561, loss: 0.733929455280304, grad norm: 0.27047160267829895\n",
      "Epoch 562, loss: 0.7336512804031372, grad norm: 0.2706455886363983\n",
      "Epoch 563, loss: 0.7333745360374451, grad norm: 0.2708686590194702\n",
      "Epoch 564, loss: 0.733096718788147, grad norm: 0.2710225284099579\n",
      "Epoch 565, loss: 0.7328177094459534, grad norm: 0.27101171016693115\n",
      "Epoch 566, loss: 0.7325441241264343, grad norm: 0.2711600363254547\n",
      "Epoch 567, loss: 0.7322686314582825, grad norm: 0.2714008092880249\n",
      "Epoch 568, loss: 0.7319934964179993, grad norm: 0.271556556224823\n",
      "Epoch 569, loss: 0.731717586517334, grad norm: 0.2716417908668518\n",
      "Epoch 570, loss: 0.7314457297325134, grad norm: 0.27175799012184143\n",
      "Epoch 571, loss: 0.731173038482666, grad norm: 0.2719120979309082\n",
      "Epoch 572, loss: 0.7308993339538574, grad norm: 0.2720527946949005\n",
      "Epoch 573, loss: 0.7306281328201294, grad norm: 0.27209097146987915\n",
      "Epoch 574, loss: 0.7303584814071655, grad norm: 0.2722856104373932\n",
      "Epoch 575, loss: 0.7300863862037659, grad norm: 0.272468626499176\n",
      "Epoch 576, loss: 0.7298156023025513, grad norm: 0.2724791467189789\n",
      "Epoch 577, loss: 0.729546844959259, grad norm: 0.27276602387428284\n",
      "Epoch 578, loss: 0.7292754054069519, grad norm: 0.2728583514690399\n",
      "Epoch 579, loss: 0.7290077209472656, grad norm: 0.27297648787498474\n",
      "Epoch 580, loss: 0.7287402153015137, grad norm: 0.27313175797462463\n",
      "Epoch 581, loss: 0.7284727692604065, grad norm: 0.27321958541870117\n",
      "Epoch 582, loss: 0.7282053232192993, grad norm: 0.27337646484375\n",
      "Epoch 583, loss: 0.7279386520385742, grad norm: 0.2735098600387573\n",
      "Epoch 584, loss: 0.7276712656021118, grad norm: 0.2736867666244507\n",
      "Epoch 585, loss: 0.7274062037467957, grad norm: 0.27371862530708313\n",
      "Epoch 586, loss: 0.7271422147750854, grad norm: 0.2738279700279236\n",
      "Epoch 587, loss: 0.7268761396408081, grad norm: 0.2739869952201843\n",
      "Epoch 588, loss: 0.726611852645874, grad norm: 0.2742129862308502\n",
      "Epoch 589, loss: 0.7263474464416504, grad norm: 0.27429988980293274\n",
      "Epoch 590, loss: 0.7260844707489014, grad norm: 0.2743692398071289\n",
      "Epoch 591, loss: 0.7258220314979553, grad norm: 0.2745087742805481\n",
      "Epoch 592, loss: 0.7255589962005615, grad norm: 0.2746405303478241\n",
      "Epoch 593, loss: 0.7252972722053528, grad norm: 0.2748570740222931\n",
      "Epoch 594, loss: 0.7250353097915649, grad norm: 0.2748643755912781\n",
      "Epoch 595, loss: 0.724774181842804, grad norm: 0.27504923939704895\n",
      "Epoch 596, loss: 0.7245137095451355, grad norm: 0.2751747667789459\n",
      "Epoch 597, loss: 0.7242534160614014, grad norm: 0.2753066122531891\n",
      "Epoch 598, loss: 0.7239944338798523, grad norm: 0.2753586769104004\n",
      "Epoch 599, loss: 0.7237344980239868, grad norm: 0.2754565477371216\n",
      "Epoch 600, loss: 0.7234742641448975, grad norm: 0.2755659222602844\n",
      "Epoch 601, loss: 0.7232170104980469, grad norm: 0.27565842866897583\n",
      "Epoch 602, loss: 0.7229580879211426, grad norm: 0.27581310272216797\n",
      "Epoch 603, loss: 0.722700834274292, grad norm: 0.2758996784687042\n",
      "Epoch 604, loss: 0.7224438190460205, grad norm: 0.27615833282470703\n",
      "Epoch 605, loss: 0.722183108329773, grad norm: 0.2761932611465454\n",
      "Epoch 606, loss: 0.7219275236129761, grad norm: 0.27629080414772034\n",
      "Epoch 607, loss: 0.7216720581054688, grad norm: 0.27639302611351013\n",
      "Epoch 608, loss: 0.721415102481842, grad norm: 0.27657005190849304\n",
      "Epoch 609, loss: 0.7211593389511108, grad norm: 0.27659446001052856\n",
      "Epoch 610, loss: 0.7209047079086304, grad norm: 0.27670538425445557\n",
      "Epoch 611, loss: 0.720650315284729, grad norm: 0.27679213881492615\n",
      "Epoch 612, loss: 0.7203956842422485, grad norm: 0.27692174911499023\n",
      "Epoch 613, loss: 0.720140814781189, grad norm: 0.2770058214664459\n",
      "Epoch 614, loss: 0.719886064529419, grad norm: 0.27722054719924927\n",
      "Epoch 615, loss: 0.7196331024169922, grad norm: 0.2772270739078522\n",
      "Epoch 616, loss: 0.7193794846534729, grad norm: 0.2774217426776886\n",
      "Epoch 617, loss: 0.7191259860992432, grad norm: 0.2775188386440277\n",
      "Epoch 618, loss: 0.7188715934753418, grad norm: 0.2777130901813507\n",
      "Epoch 619, loss: 0.7186198234558105, grad norm: 0.2777942419052124\n",
      "Epoch 620, loss: 0.718367338180542, grad norm: 0.2779150903224945\n",
      "Epoch 621, loss: 0.7181147336959839, grad norm: 0.2780539393424988\n",
      "Epoch 622, loss: 0.7178623676300049, grad norm: 0.27811336517333984\n",
      "Epoch 623, loss: 0.7176120281219482, grad norm: 0.27824947237968445\n",
      "Epoch 624, loss: 0.7173588871955872, grad norm: 0.2783590257167816\n",
      "Epoch 625, loss: 0.7171097993850708, grad norm: 0.2783640921115875\n",
      "Epoch 626, loss: 0.7168591022491455, grad norm: 0.2785753607749939\n",
      "Epoch 627, loss: 0.7166075706481934, grad norm: 0.2787625193595886\n",
      "Epoch 628, loss: 0.7163568735122681, grad norm: 0.2788762152194977\n",
      "Epoch 629, loss: 0.7161045670509338, grad norm: 0.2789562940597534\n",
      "Epoch 630, loss: 0.7158559560775757, grad norm: 0.2790563404560089\n",
      "Epoch 631, loss: 0.7156075239181519, grad norm: 0.27921631932258606\n",
      "Epoch 632, loss: 0.7153564095497131, grad norm: 0.27931079268455505\n",
      "Epoch 633, loss: 0.7151080369949341, grad norm: 0.2795346975326538\n",
      "Epoch 634, loss: 0.7148575782775879, grad norm: 0.2795508801937103\n",
      "Epoch 635, loss: 0.7146105766296387, grad norm: 0.2795853614807129\n",
      "Epoch 636, loss: 0.7143613696098328, grad norm: 0.2797262966632843\n",
      "Epoch 637, loss: 0.7141103148460388, grad norm: 0.27985680103302\n",
      "Epoch 638, loss: 0.7138621807098389, grad norm: 0.2799606919288635\n",
      "Epoch 639, loss: 0.7136133909225464, grad norm: 0.2801128625869751\n",
      "Epoch 640, loss: 0.7133663892745972, grad norm: 0.28016555309295654\n",
      "Epoch 641, loss: 0.7131171226501465, grad norm: 0.28029170632362366\n",
      "Epoch 642, loss: 0.7128705978393555, grad norm: 0.2804211378097534\n",
      "Epoch 643, loss: 0.712622880935669, grad norm: 0.28053054213523865\n",
      "Epoch 644, loss: 0.7123734951019287, grad norm: 0.2806644141674042\n",
      "Epoch 645, loss: 0.712125301361084, grad norm: 0.28077831864356995\n",
      "Epoch 646, loss: 0.7118792533874512, grad norm: 0.280955970287323\n",
      "Epoch 647, loss: 0.7116296291351318, grad norm: 0.2810070514678955\n",
      "Epoch 648, loss: 0.7113840579986572, grad norm: 0.28120744228363037\n",
      "Epoch 649, loss: 0.7111362218856812, grad norm: 0.28137412667274475\n",
      "Epoch 650, loss: 0.7108867168426514, grad norm: 0.2814481854438782\n",
      "Epoch 651, loss: 0.7106388807296753, grad norm: 0.2816169261932373\n",
      "Epoch 652, loss: 0.710392415523529, grad norm: 0.2816321849822998\n",
      "Epoch 653, loss: 0.7101446390151978, grad norm: 0.2817919850349426\n",
      "Epoch 654, loss: 0.7098967432975769, grad norm: 0.2818808853626251\n",
      "Epoch 655, loss: 0.709650993347168, grad norm: 0.2819712162017822\n",
      "Epoch 656, loss: 0.7094025611877441, grad norm: 0.2821243703365326\n",
      "Epoch 657, loss: 0.7091536521911621, grad norm: 0.2822516858577728\n",
      "Epoch 658, loss: 0.708907961845398, grad norm: 0.2823861539363861\n",
      "Epoch 659, loss: 0.7086607217788696, grad norm: 0.28250911831855774\n",
      "Epoch 660, loss: 0.7084126472473145, grad norm: 0.28252869844436646\n",
      "Epoch 661, loss: 0.7081656455993652, grad norm: 0.2828032076358795\n",
      "Epoch 662, loss: 0.7079176902770996, grad norm: 0.2829316258430481\n",
      "Epoch 663, loss: 0.7076680660247803, grad norm: 0.28309640288352966\n",
      "Epoch 664, loss: 0.7074254751205444, grad norm: 0.2830638289451599\n",
      "Epoch 665, loss: 0.7071750164031982, grad norm: 0.28334328532218933\n",
      "Epoch 666, loss: 0.7069267630577087, grad norm: 0.28341254591941833\n",
      "Epoch 667, loss: 0.7066802382469177, grad norm: 0.2836766839027405\n",
      "Epoch 668, loss: 0.7064303159713745, grad norm: 0.28369414806365967\n",
      "Epoch 669, loss: 0.7061838507652283, grad norm: 0.2837764620780945\n",
      "Epoch 670, loss: 0.7059363722801208, grad norm: 0.284029483795166\n",
      "Epoch 671, loss: 0.7056872248649597, grad norm: 0.28413042426109314\n",
      "Epoch 672, loss: 0.7054388523101807, grad norm: 0.2843080461025238\n",
      "Epoch 673, loss: 0.7051907777786255, grad norm: 0.28447747230529785\n",
      "Epoch 674, loss: 0.7049423456192017, grad norm: 0.2845286726951599\n",
      "Epoch 675, loss: 0.7046957612037659, grad norm: 0.2847486734390259\n",
      "Epoch 676, loss: 0.7044452428817749, grad norm: 0.2848261594772339\n",
      "Epoch 677, loss: 0.7041963338851929, grad norm: 0.2850474417209625\n",
      "Epoch 678, loss: 0.7039470076560974, grad norm: 0.2850746512413025\n",
      "Epoch 679, loss: 0.70369952917099, grad norm: 0.2852122485637665\n",
      "Epoch 680, loss: 0.703447699546814, grad norm: 0.285377562046051\n",
      "Epoch 681, loss: 0.7031998634338379, grad norm: 0.28559616208076477\n",
      "Epoch 682, loss: 0.7029491662979126, grad norm: 0.2857420742511749\n",
      "Epoch 683, loss: 0.7026981115341187, grad norm: 0.2858518958091736\n",
      "Epoch 684, loss: 0.702450692653656, grad norm: 0.28591737151145935\n",
      "Epoch 685, loss: 0.70219886302948, grad norm: 0.2862195372581482\n",
      "Epoch 686, loss: 0.7019467353820801, grad norm: 0.28635331988334656\n",
      "Epoch 687, loss: 0.7016953825950623, grad norm: 0.28654372692108154\n",
      "Epoch 688, loss: 0.701445996761322, grad norm: 0.286658376455307\n",
      "Epoch 689, loss: 0.7011939883232117, grad norm: 0.2869022786617279\n",
      "Epoch 690, loss: 0.700942873954773, grad norm: 0.2870136499404907\n",
      "Epoch 691, loss: 0.700690746307373, grad norm: 0.2871154546737671\n",
      "Epoch 692, loss: 0.700438380241394, grad norm: 0.2873711585998535\n",
      "Epoch 693, loss: 0.7001866698265076, grad norm: 0.28750893473625183\n",
      "Epoch 694, loss: 0.6999329328536987, grad norm: 0.28766658902168274\n",
      "Epoch 695, loss: 0.6996831893920898, grad norm: 0.28780120611190796\n",
      "Epoch 696, loss: 0.6994286775588989, grad norm: 0.28816667199134827\n",
      "Epoch 697, loss: 0.6991723775863647, grad norm: 0.28808268904685974\n",
      "Epoch 698, loss: 0.698921799659729, grad norm: 0.28825411200523376\n",
      "Epoch 699, loss: 0.6986665725708008, grad norm: 0.2884547710418701\n",
      "Epoch 700, loss: 0.6984136700630188, grad norm: 0.28865209221839905\n",
      "Epoch 701, loss: 0.698157548904419, grad norm: 0.2888399064540863\n",
      "Epoch 702, loss: 0.6979031562805176, grad norm: 0.2891010642051697\n",
      "Epoch 703, loss: 0.6976475715637207, grad norm: 0.2892380952835083\n",
      "Epoch 704, loss: 0.6973906755447388, grad norm: 0.2893041670322418\n",
      "Epoch 705, loss: 0.6971372961997986, grad norm: 0.2894893288612366\n",
      "Epoch 706, loss: 0.6968804597854614, grad norm: 0.2897384464740753\n",
      "Epoch 707, loss: 0.6966235637664795, grad norm: 0.289844810962677\n",
      "Epoch 708, loss: 0.696366548538208, grad norm: 0.290058434009552\n",
      "Epoch 709, loss: 0.6961092948913574, grad norm: 0.29014602303504944\n",
      "Epoch 710, loss: 0.6958516836166382, grad norm: 0.29046252369880676\n",
      "Epoch 711, loss: 0.6955939531326294, grad norm: 0.2907355725765228\n",
      "Epoch 712, loss: 0.695335328578949, grad norm: 0.29089662432670593\n",
      "Epoch 713, loss: 0.6950769424438477, grad norm: 0.29107028245925903\n",
      "Epoch 714, loss: 0.6948186159133911, grad norm: 0.29128143191337585\n",
      "Epoch 715, loss: 0.6945569515228271, grad norm: 0.2914239466190338\n",
      "Epoch 716, loss: 0.6942991614341736, grad norm: 0.29173779487609863\n",
      "Epoch 717, loss: 0.6940374970436096, grad norm: 0.2919231951236725\n",
      "Epoch 718, loss: 0.6937777996063232, grad norm: 0.2920601963996887\n",
      "Epoch 719, loss: 0.6935169696807861, grad norm: 0.2921731173992157\n",
      "Epoch 720, loss: 0.6932569742202759, grad norm: 0.29252558946609497\n",
      "Epoch 721, loss: 0.6929966807365417, grad norm: 0.2926501929759979\n",
      "Epoch 722, loss: 0.6927345395088196, grad norm: 0.2929092049598694\n",
      "Epoch 723, loss: 0.6924707293510437, grad norm: 0.29306158423423767\n",
      "Epoch 724, loss: 0.6922094821929932, grad norm: 0.29332953691482544\n",
      "Epoch 725, loss: 0.6919455528259277, grad norm: 0.2935776114463806\n",
      "Epoch 726, loss: 0.6916813850402832, grad norm: 0.2938401401042938\n",
      "Epoch 727, loss: 0.6914161443710327, grad norm: 0.2939679026603699\n",
      "Epoch 728, loss: 0.6911556720733643, grad norm: 0.2942405939102173\n",
      "Epoch 729, loss: 0.6908899545669556, grad norm: 0.2945224642753601\n",
      "Epoch 730, loss: 0.6906250715255737, grad norm: 0.2946755588054657\n",
      "Epoch 731, loss: 0.6903601884841919, grad norm: 0.29502782225608826\n",
      "Epoch 732, loss: 0.6900930404663086, grad norm: 0.29512402415275574\n",
      "Epoch 733, loss: 0.6898279190063477, grad norm: 0.29539868235588074\n",
      "Epoch 734, loss: 0.6895621418952942, grad norm: 0.29561299085617065\n",
      "Epoch 735, loss: 0.689296305179596, grad norm: 0.29586654901504517\n",
      "Epoch 736, loss: 0.6890294551849365, grad norm: 0.2962040603160858\n",
      "Epoch 737, loss: 0.688761830329895, grad norm: 0.2963659167289734\n",
      "Epoch 738, loss: 0.6884937286376953, grad norm: 0.29661551117897034\n",
      "Epoch 739, loss: 0.6882259249687195, grad norm: 0.2968828082084656\n",
      "Epoch 740, loss: 0.6879584193229675, grad norm: 0.297121524810791\n",
      "Epoch 741, loss: 0.6876909732818604, grad norm: 0.2973845601081848\n",
      "Epoch 742, loss: 0.6874203681945801, grad norm: 0.2976137399673462\n",
      "Epoch 743, loss: 0.6871510744094849, grad norm: 0.2979075312614441\n",
      "Epoch 744, loss: 0.6868835687637329, grad norm: 0.2980588972568512\n",
      "Epoch 745, loss: 0.6866136193275452, grad norm: 0.29850515723228455\n",
      "Epoch 746, loss: 0.6863430738449097, grad norm: 0.2987024486064911\n",
      "Epoch 747, loss: 0.686072587966919, grad norm: 0.2989475727081299\n",
      "Epoch 748, loss: 0.6858014464378357, grad norm: 0.2992798984050751\n",
      "Epoch 749, loss: 0.685531735420227, grad norm: 0.2995051145553589\n",
      "Epoch 750, loss: 0.685259222984314, grad norm: 0.2997804284095764\n",
      "Epoch 751, loss: 0.6849899291992188, grad norm: 0.30010566115379333\n",
      "Epoch 752, loss: 0.6847181916236877, grad norm: 0.3003998100757599\n",
      "Epoch 753, loss: 0.6844455599784851, grad norm: 0.3005567789077759\n",
      "Epoch 754, loss: 0.6841760873794556, grad norm: 0.30090728402137756\n",
      "Epoch 755, loss: 0.6839014291763306, grad norm: 0.3011705279350281\n",
      "Epoch 756, loss: 0.6836283802986145, grad norm: 0.30141669511795044\n",
      "Epoch 757, loss: 0.683357298374176, grad norm: 0.3017578125\n",
      "Epoch 758, loss: 0.6830849647521973, grad norm: 0.30200815200805664\n",
      "Epoch 759, loss: 0.6828125715255737, grad norm: 0.30236050486564636\n",
      "Epoch 760, loss: 0.6825405359268188, grad norm: 0.3026696443557739\n",
      "Epoch 761, loss: 0.6822672486305237, grad norm: 0.3030039966106415\n",
      "Epoch 762, loss: 0.6819934844970703, grad norm: 0.3033028542995453\n",
      "Epoch 763, loss: 0.6817203760147095, grad norm: 0.30371323227882385\n",
      "Epoch 764, loss: 0.6814454197883606, grad norm: 0.30401816964149475\n",
      "Epoch 765, loss: 0.6811755895614624, grad norm: 0.30432939529418945\n",
      "Epoch 766, loss: 0.680901288986206, grad norm: 0.30459919571876526\n",
      "Epoch 767, loss: 0.680627703666687, grad norm: 0.30493730306625366\n",
      "Epoch 768, loss: 0.6803557872772217, grad norm: 0.30513012409210205\n",
      "Epoch 769, loss: 0.6800829172134399, grad norm: 0.30564743280410767\n",
      "Epoch 770, loss: 0.6798082590103149, grad norm: 0.30600807070732117\n",
      "Epoch 771, loss: 0.6795352697372437, grad norm: 0.30626004934310913\n",
      "Epoch 772, loss: 0.6792646646499634, grad norm: 0.3065215051174164\n",
      "Epoch 773, loss: 0.6789895296096802, grad norm: 0.3068826198577881\n",
      "Epoch 774, loss: 0.6787182092666626, grad norm: 0.30724719166755676\n",
      "Epoch 775, loss: 0.6784439086914062, grad norm: 0.3075319528579712\n",
      "Epoch 776, loss: 0.6781716346740723, grad norm: 0.3079747259616852\n",
      "Epoch 777, loss: 0.6778997778892517, grad norm: 0.3083062767982483\n",
      "Epoch 778, loss: 0.6776262521743774, grad norm: 0.3086670935153961\n",
      "Epoch 779, loss: 0.6773543357849121, grad norm: 0.3089520335197449\n",
      "Epoch 780, loss: 0.6770827770233154, grad norm: 0.309383362531662\n",
      "Epoch 781, loss: 0.676813006401062, grad norm: 0.3097984790802002\n",
      "Epoch 782, loss: 0.6765396595001221, grad norm: 0.31003639101982117\n",
      "Epoch 783, loss: 0.6762703657150269, grad norm: 0.3103694021701813\n",
      "Epoch 784, loss: 0.6759997010231018, grad norm: 0.31079357862472534\n",
      "Epoch 785, loss: 0.6757296323776245, grad norm: 0.3112083673477173\n",
      "Epoch 786, loss: 0.6754578351974487, grad norm: 0.31165945529937744\n",
      "Epoch 787, loss: 0.6751890182495117, grad norm: 0.31196486949920654\n",
      "Epoch 788, loss: 0.6749193668365479, grad norm: 0.3125677704811096\n",
      "Epoch 789, loss: 0.6746495366096497, grad norm: 0.3129552900791168\n",
      "Epoch 790, loss: 0.6743817329406738, grad norm: 0.313206285238266\n",
      "Epoch 791, loss: 0.6741145849227905, grad norm: 0.3136172592639923\n",
      "Epoch 792, loss: 0.6738466024398804, grad norm: 0.3141583204269409\n",
      "Epoch 793, loss: 0.6735792756080627, grad norm: 0.314542680978775\n",
      "Epoch 794, loss: 0.6733148097991943, grad norm: 0.3149801790714264\n",
      "Epoch 795, loss: 0.673046886920929, grad norm: 0.3153323531150818\n",
      "Epoch 796, loss: 0.6727825999259949, grad norm: 0.31580692529678345\n",
      "Epoch 797, loss: 0.6725188493728638, grad norm: 0.31612491607666016\n",
      "Epoch 798, loss: 0.6722537875175476, grad norm: 0.3166947066783905\n",
      "Epoch 799, loss: 0.6719909310340881, grad norm: 0.31699642539024353\n",
      "Epoch 800, loss: 0.6717280149459839, grad norm: 0.31754037737846375\n",
      "Epoch 801, loss: 0.6714658141136169, grad norm: 0.3179536461830139\n",
      "Epoch 802, loss: 0.6712028980255127, grad norm: 0.31828445196151733\n",
      "Epoch 803, loss: 0.6709432601928711, grad norm: 0.31882208585739136\n",
      "Epoch 804, loss: 0.6706819534301758, grad norm: 0.3191896677017212\n",
      "Epoch 805, loss: 0.6704237461090088, grad norm: 0.31964701414108276\n",
      "Epoch 806, loss: 0.6701645851135254, grad norm: 0.32002246379852295\n",
      "Epoch 807, loss: 0.6699082255363464, grad norm: 0.32056725025177\n",
      "Epoch 808, loss: 0.6696501970291138, grad norm: 0.32109934091567993\n",
      "Epoch 809, loss: 0.6693946123123169, grad norm: 0.3216465413570404\n",
      "Epoch 810, loss: 0.6691387891769409, grad norm: 0.3220903277397156\n",
      "Epoch 811, loss: 0.6688840389251709, grad norm: 0.32252582907676697\n",
      "Epoch 812, loss: 0.668628990650177, grad norm: 0.3230490982532501\n",
      "Epoch 813, loss: 0.6683769822120667, grad norm: 0.32353341579437256\n",
      "Epoch 814, loss: 0.6681259870529175, grad norm: 0.32394081354141235\n",
      "Epoch 815, loss: 0.667876124382019, grad norm: 0.3244863450527191\n",
      "Epoch 816, loss: 0.6676255464553833, grad norm: 0.324878454208374\n",
      "Epoch 817, loss: 0.6673787832260132, grad norm: 0.32546985149383545\n",
      "Epoch 818, loss: 0.6671269536018372, grad norm: 0.32599151134490967\n",
      "Epoch 819, loss: 0.6668828725814819, grad norm: 0.32654163241386414\n",
      "Epoch 820, loss: 0.6666357517242432, grad norm: 0.32705003023147583\n",
      "Epoch 821, loss: 0.6663918495178223, grad norm: 0.3275144100189209\n",
      "Epoch 822, loss: 0.6661490201950073, grad norm: 0.3280012309551239\n",
      "Epoch 823, loss: 0.6659071445465088, grad norm: 0.32855677604675293\n",
      "Epoch 824, loss: 0.665664792060852, grad norm: 0.32910165190696716\n",
      "Epoch 825, loss: 0.6654241681098938, grad norm: 0.3295828104019165\n",
      "Epoch 826, loss: 0.6651871204376221, grad norm: 0.3302265405654907\n",
      "Epoch 827, loss: 0.6649463176727295, grad norm: 0.3306606113910675\n",
      "Epoch 828, loss: 0.6647114157676697, grad norm: 0.3313775062561035\n",
      "Epoch 829, loss: 0.6644752025604248, grad norm: 0.3319048285484314\n",
      "Epoch 830, loss: 0.6642396450042725, grad norm: 0.33241817355155945\n",
      "Epoch 831, loss: 0.6640077829360962, grad norm: 0.3330717384815216\n",
      "Epoch 832, loss: 0.6637746095657349, grad norm: 0.33356618881225586\n",
      "Epoch 833, loss: 0.663543701171875, grad norm: 0.3341512084007263\n",
      "Epoch 834, loss: 0.6633114218711853, grad norm: 0.3347012996673584\n",
      "Epoch 835, loss: 0.6630846261978149, grad norm: 0.3354451656341553\n",
      "Epoch 836, loss: 0.6628547310829163, grad norm: 0.33595919609069824\n",
      "Epoch 837, loss: 0.6626315116882324, grad norm: 0.3365355432033539\n",
      "Epoch 838, loss: 0.6624065041542053, grad norm: 0.33720844984054565\n",
      "Epoch 839, loss: 0.66218101978302, grad norm: 0.3377046287059784\n",
      "Epoch 840, loss: 0.661961555480957, grad norm: 0.3383794128894806\n",
      "Epoch 841, loss: 0.6617400646209717, grad norm: 0.33899223804473877\n",
      "Epoch 842, loss: 0.661517858505249, grad norm: 0.33957207202911377\n",
      "Epoch 843, loss: 0.6613019704818726, grad norm: 0.3402283489704132\n",
      "Epoch 844, loss: 0.6610826253890991, grad norm: 0.34094274044036865\n",
      "Epoch 845, loss: 0.660865068435669, grad norm: 0.341499924659729\n",
      "Epoch 846, loss: 0.6606512069702148, grad norm: 0.34216049313545227\n",
      "Epoch 847, loss: 0.660437822341919, grad norm: 0.34284842014312744\n",
      "Epoch 848, loss: 0.6602275967597961, grad norm: 0.343410849571228\n",
      "Epoch 849, loss: 0.6600162982940674, grad norm: 0.34414687752723694\n",
      "Epoch 850, loss: 0.6598062515258789, grad norm: 0.3447801470756531\n",
      "Epoch 851, loss: 0.6595996618270874, grad norm: 0.34542444348335266\n",
      "Epoch 852, loss: 0.6593918204307556, grad norm: 0.34607014060020447\n",
      "Epoch 853, loss: 0.6591861248016357, grad norm: 0.346767783164978\n",
      "Epoch 854, loss: 0.6589822173118591, grad norm: 0.3474949598312378\n",
      "Epoch 855, loss: 0.6587793827056885, grad norm: 0.3481215238571167\n",
      "Epoch 856, loss: 0.6585752964019775, grad norm: 0.3488827049732208\n",
      "Epoch 857, loss: 0.6583766341209412, grad norm: 0.3495748043060303\n",
      "Epoch 858, loss: 0.6581772565841675, grad norm: 0.3503129184246063\n",
      "Epoch 859, loss: 0.6579796075820923, grad norm: 0.3509694039821625\n",
      "Epoch 860, loss: 0.6577845811843872, grad norm: 0.3517908751964569\n",
      "Epoch 861, loss: 0.6575870513916016, grad norm: 0.35254257917404175\n",
      "Epoch 862, loss: 0.6573935151100159, grad norm: 0.35317063331604004\n",
      "Epoch 863, loss: 0.6571990251541138, grad norm: 0.35390493273735046\n",
      "Epoch 864, loss: 0.6570088267326355, grad norm: 0.3547370731830597\n",
      "Epoch 865, loss: 0.6568185687065125, grad norm: 0.35543516278266907\n",
      "Epoch 866, loss: 0.6566311120986938, grad norm: 0.3561401665210724\n",
      "Epoch 867, loss: 0.6564439535140991, grad norm: 0.3569084107875824\n",
      "Epoch 868, loss: 0.6562559008598328, grad norm: 0.3576940596103668\n",
      "Epoch 869, loss: 0.6560724377632141, grad norm: 0.35838547348976135\n",
      "Epoch 870, loss: 0.6558881998062134, grad norm: 0.35929858684539795\n",
      "Epoch 871, loss: 0.6557040810585022, grad norm: 0.36001208424568176\n",
      "Epoch 872, loss: 0.6555245518684387, grad norm: 0.36079296469688416\n",
      "Epoch 873, loss: 0.6553456783294678, grad norm: 0.36159318685531616\n",
      "Epoch 874, loss: 0.6551668047904968, grad norm: 0.3623359501361847\n",
      "Epoch 875, loss: 0.6549887657165527, grad norm: 0.36313170194625854\n",
      "Epoch 876, loss: 0.654812753200531, grad norm: 0.36395761370658875\n",
      "Epoch 877, loss: 0.6546378135681152, grad norm: 0.3647640347480774\n",
      "Epoch 878, loss: 0.6544638872146606, grad norm: 0.3656046688556671\n",
      "Epoch 879, loss: 0.654289186000824, grad norm: 0.36656662821769714\n",
      "Epoch 880, loss: 0.6541182994842529, grad norm: 0.3672373592853546\n",
      "Epoch 881, loss: 0.6539484262466431, grad norm: 0.3680604100227356\n",
      "Epoch 882, loss: 0.6537795066833496, grad norm: 0.36892879009246826\n",
      "Epoch 883, loss: 0.6536097526550293, grad norm: 0.3698596656322479\n",
      "Epoch 884, loss: 0.6534441709518433, grad norm: 0.37065714597702026\n",
      "Epoch 885, loss: 0.6532790660858154, grad norm: 0.3714607059955597\n",
      "Epoch 886, loss: 0.6531137228012085, grad norm: 0.3723644018173218\n",
      "Epoch 887, loss: 0.652950644493103, grad norm: 0.37331119179725647\n",
      "Epoch 888, loss: 0.6527881622314453, grad norm: 0.37424325942993164\n",
      "Epoch 889, loss: 0.6526260375976562, grad norm: 0.37511739134788513\n",
      "Epoch 890, loss: 0.6524652242660522, grad norm: 0.37602701783180237\n",
      "Epoch 891, loss: 0.6523080468177795, grad norm: 0.37698447704315186\n",
      "Epoch 892, loss: 0.6521490812301636, grad norm: 0.3779621422290802\n",
      "Epoch 893, loss: 0.651993989944458, grad norm: 0.3788027763366699\n",
      "Epoch 894, loss: 0.6518365740776062, grad norm: 0.37968289852142334\n",
      "Epoch 895, loss: 0.6516827344894409, grad norm: 0.3806591331958771\n",
      "Epoch 896, loss: 0.6515263915061951, grad norm: 0.38157522678375244\n",
      "Epoch 897, loss: 0.6513746380805969, grad norm: 0.382561057806015\n",
      "Epoch 898, loss: 0.6512223482131958, grad norm: 0.38353651762008667\n",
      "Epoch 899, loss: 0.6510721445083618, grad norm: 0.3844245672225952\n",
      "Epoch 900, loss: 0.6509212255477905, grad norm: 0.38538557291030884\n",
      "Epoch 901, loss: 0.6507718563079834, grad norm: 0.38638561964035034\n",
      "Epoch 902, loss: 0.6506255865097046, grad norm: 0.3873557150363922\n",
      "Epoch 903, loss: 0.6504765748977661, grad norm: 0.3883921205997467\n",
      "Epoch 904, loss: 0.6503305435180664, grad norm: 0.38937926292419434\n",
      "Epoch 905, loss: 0.6501858234405518, grad norm: 0.3902738094329834\n",
      "Epoch 906, loss: 0.6500424742698669, grad norm: 0.39140307903289795\n",
      "Epoch 907, loss: 0.6498987674713135, grad norm: 0.39236772060394287\n",
      "Epoch 908, loss: 0.6497557163238525, grad norm: 0.39342689514160156\n",
      "Epoch 909, loss: 0.6496132612228394, grad norm: 0.39439135789871216\n",
      "Epoch 910, loss: 0.6494709253311157, grad norm: 0.3954148292541504\n",
      "Epoch 911, loss: 0.6493327617645264, grad norm: 0.39658376574516296\n",
      "Epoch 912, loss: 0.6491937637329102, grad norm: 0.3975633382797241\n",
      "Epoch 913, loss: 0.6490535140037537, grad norm: 0.39859965443611145\n",
      "Epoch 914, loss: 0.6489174962043762, grad norm: 0.3996172547340393\n",
      "Epoch 915, loss: 0.6487798094749451, grad norm: 0.40075141191482544\n",
      "Epoch 916, loss: 0.6486426591873169, grad norm: 0.4018886983394623\n",
      "Epoch 917, loss: 0.6485062837600708, grad norm: 0.4028925895690918\n",
      "Epoch 918, loss: 0.6483719944953918, grad norm: 0.4040006995201111\n",
      "Epoch 919, loss: 0.6482378244400024, grad norm: 0.4050205945968628\n",
      "Epoch 920, loss: 0.6481053829193115, grad norm: 0.40617820620536804\n",
      "Epoch 921, loss: 0.647972822189331, grad norm: 0.407272607088089\n",
      "Epoch 922, loss: 0.6478399038314819, grad norm: 0.4084584414958954\n",
      "Epoch 923, loss: 0.6477079391479492, grad norm: 0.40958574414253235\n",
      "Epoch 924, loss: 0.6475768089294434, grad norm: 0.4106992781162262\n",
      "Epoch 925, loss: 0.6474483609199524, grad norm: 0.41181978583335876\n",
      "Epoch 926, loss: 0.6473190784454346, grad norm: 0.4129321575164795\n",
      "Epoch 927, loss: 0.6471900343894958, grad norm: 0.4141514003276825\n",
      "Epoch 928, loss: 0.6470624208450317, grad norm: 0.4152870774269104\n",
      "Epoch 929, loss: 0.6469354629516602, grad norm: 0.4165157973766327\n",
      "Epoch 930, loss: 0.6468062400817871, grad norm: 0.41769757866859436\n",
      "Epoch 931, loss: 0.6466798782348633, grad norm: 0.4188127815723419\n",
      "Epoch 932, loss: 0.6465531587600708, grad norm: 0.42005982995033264\n",
      "Epoch 933, loss: 0.6464277505874634, grad norm: 0.4212612807750702\n",
      "Epoch 934, loss: 0.6463052034378052, grad norm: 0.4224727153778076\n",
      "Epoch 935, loss: 0.6461796760559082, grad norm: 0.4236467480659485\n",
      "Epoch 936, loss: 0.6460562348365784, grad norm: 0.4248032569885254\n",
      "Epoch 937, loss: 0.6459330320358276, grad norm: 0.426087349653244\n",
      "Epoch 938, loss: 0.6458113193511963, grad norm: 0.42725130915641785\n",
      "Epoch 939, loss: 0.6456879377365112, grad norm: 0.4284983277320862\n",
      "Epoch 940, loss: 0.6455657482147217, grad norm: 0.4297639727592468\n",
      "Epoch 941, loss: 0.6454441547393799, grad norm: 0.4309746026992798\n",
      "Epoch 942, loss: 0.6453242897987366, grad norm: 0.4323444664478302\n",
      "Epoch 943, loss: 0.6452023386955261, grad norm: 0.43356236815452576\n",
      "Epoch 944, loss: 0.6450815200805664, grad norm: 0.4348447918891907\n",
      "Epoch 945, loss: 0.6449629068374634, grad norm: 0.4361698627471924\n",
      "Epoch 946, loss: 0.6448415517807007, grad norm: 0.43737879395484924\n",
      "Epoch 947, loss: 0.6447235941886902, grad norm: 0.43873393535614014\n",
      "Epoch 948, loss: 0.6446051001548767, grad norm: 0.4401032328605652\n",
      "Epoch 949, loss: 0.6444855332374573, grad norm: 0.44132405519485474\n",
      "Epoch 950, loss: 0.644368052482605, grad norm: 0.44277986884117126\n",
      "Epoch 951, loss: 0.6442517638206482, grad norm: 0.44402915239334106\n",
      "Epoch 952, loss: 0.6441351175308228, grad norm: 0.44541415572166443\n",
      "Epoch 953, loss: 0.6440168023109436, grad norm: 0.4467496871948242\n",
      "Epoch 954, loss: 0.6439009308815002, grad norm: 0.44806182384490967\n",
      "Epoch 955, loss: 0.6437828540802002, grad norm: 0.44946178793907166\n",
      "Epoch 956, loss: 0.6436647176742554, grad norm: 0.4508505165576935\n",
      "Epoch 957, loss: 0.6435490250587463, grad norm: 0.4521711468696594\n",
      "Epoch 958, loss: 0.6434321999549866, grad norm: 0.4535788595676422\n",
      "Epoch 959, loss: 0.6433181166648865, grad norm: 0.45502328872680664\n",
      "Epoch 960, loss: 0.6432020664215088, grad norm: 0.45629173517227173\n",
      "Epoch 961, loss: 0.6430896520614624, grad norm: 0.45772621035575867\n",
      "Epoch 962, loss: 0.6429706811904907, grad norm: 0.4591677784919739\n",
      "Epoch 963, loss: 0.6428555250167847, grad norm: 0.4605226516723633\n",
      "Epoch 964, loss: 0.6427416205406189, grad norm: 0.46199285984039307\n",
      "Epoch 965, loss: 0.642627477645874, grad norm: 0.46331652998924255\n",
      "Epoch 966, loss: 0.6425133943557739, grad norm: 0.464844286441803\n",
      "Epoch 967, loss: 0.6423971652984619, grad norm: 0.4663269817829132\n",
      "Epoch 968, loss: 0.6422826051712036, grad norm: 0.46770742535591125\n",
      "Epoch 969, loss: 0.6421701908111572, grad norm: 0.46911898255348206\n",
      "Epoch 970, loss: 0.6420568227767944, grad norm: 0.47055545449256897\n",
      "Epoch 971, loss: 0.6419405341148376, grad norm: 0.4720236361026764\n",
      "Epoch 972, loss: 0.6418287754058838, grad norm: 0.47352614998817444\n",
      "Epoch 973, loss: 0.6417151093482971, grad norm: 0.4749578833580017\n",
      "Epoch 974, loss: 0.6415978670120239, grad norm: 0.47645801305770874\n",
      "Epoch 975, loss: 0.6414861679077148, grad norm: 0.4779050052165985\n",
      "Epoch 976, loss: 0.6413724422454834, grad norm: 0.4792841970920563\n",
      "Epoch 977, loss: 0.641257643699646, grad norm: 0.48075273633003235\n",
      "Epoch 978, loss: 0.6411454081535339, grad norm: 0.48236483335494995\n",
      "Epoch 979, loss: 0.6410315036773682, grad norm: 0.4838513731956482\n",
      "Epoch 980, loss: 0.6409188508987427, grad norm: 0.4854111671447754\n",
      "Epoch 981, loss: 0.6408048868179321, grad norm: 0.4868757128715515\n",
      "Epoch 982, loss: 0.6406916379928589, grad norm: 0.4883767366409302\n",
      "Epoch 983, loss: 0.6405764222145081, grad norm: 0.4899228513240814\n",
      "Epoch 984, loss: 0.6404634118080139, grad norm: 0.4913899898529053\n",
      "Epoch 985, loss: 0.6403493881225586, grad norm: 0.4929552972316742\n",
      "Epoch 986, loss: 0.6402365565299988, grad norm: 0.49442926049232483\n",
      "Epoch 987, loss: 0.6401219367980957, grad norm: 0.496008962392807\n",
      "Epoch 988, loss: 0.6400073170661926, grad norm: 0.49756965041160583\n",
      "Epoch 989, loss: 0.6398943662643433, grad norm: 0.49913713335990906\n",
      "Epoch 990, loss: 0.6397786736488342, grad norm: 0.500704288482666\n",
      "Epoch 991, loss: 0.6396651268005371, grad norm: 0.502388060092926\n",
      "Epoch 992, loss: 0.6395508646965027, grad norm: 0.5038725137710571\n",
      "Epoch 993, loss: 0.6394341588020325, grad norm: 0.5054921507835388\n",
      "Epoch 994, loss: 0.6393204927444458, grad norm: 0.5070090889930725\n",
      "Epoch 995, loss: 0.63920658826828, grad norm: 0.508587658405304\n",
      "Epoch 996, loss: 0.639090359210968, grad norm: 0.5101881623268127\n",
      "Epoch 997, loss: 0.6389763951301575, grad norm: 0.5118251442909241\n",
      "Epoch 998, loss: 0.6388602256774902, grad norm: 0.5133864879608154\n",
      "Epoch 999, loss: 0.6387432813644409, grad norm: 0.5149356722831726\n",
      "Epoch 1000, loss: 0.6386293768882751, grad norm: 0.5164591670036316\n",
      "Epoch 1001, loss: 0.6385124325752258, grad norm: 0.5180903077125549\n",
      "Epoch 1002, loss: 0.6383976936340332, grad norm: 0.5197938680648804\n",
      "Epoch 1003, loss: 0.6382807493209839, grad norm: 0.5212234258651733\n",
      "Epoch 1004, loss: 0.6381624937057495, grad norm: 0.5229098796844482\n",
      "Epoch 1005, loss: 0.6380465030670166, grad norm: 0.524496853351593\n",
      "Epoch 1006, loss: 0.6379292607307434, grad norm: 0.526043713092804\n",
      "Epoch 1007, loss: 0.6378132104873657, grad norm: 0.5275601744651794\n",
      "Epoch 1008, loss: 0.6376956701278687, grad norm: 0.5292763113975525\n",
      "Epoch 1009, loss: 0.6375788450241089, grad norm: 0.5307677984237671\n",
      "Epoch 1010, loss: 0.6374613046646118, grad norm: 0.5324808359146118\n",
      "Epoch 1011, loss: 0.6373423933982849, grad norm: 0.5340631008148193\n",
      "Epoch 1012, loss: 0.6372241377830505, grad norm: 0.5357402563095093\n",
      "Epoch 1013, loss: 0.6371058225631714, grad norm: 0.5373059511184692\n",
      "Epoch 1014, loss: 0.6369850635528564, grad norm: 0.5388136506080627\n",
      "Epoch 1015, loss: 0.6368660926818848, grad norm: 0.5404840707778931\n",
      "Epoch 1016, loss: 0.6367481350898743, grad norm: 0.5420506596565247\n",
      "Epoch 1017, loss: 0.636627197265625, grad norm: 0.5437175035476685\n",
      "Epoch 1018, loss: 0.6365066170692444, grad norm: 0.5453049540519714\n",
      "Epoch 1019, loss: 0.6363892555236816, grad norm: 0.5468605756759644\n",
      "Epoch 1020, loss: 0.6362661123275757, grad norm: 0.5483958721160889\n",
      "Epoch 1021, loss: 0.636144757270813, grad norm: 0.5500810146331787\n",
      "Epoch 1022, loss: 0.6360233426094055, grad norm: 0.5516151189804077\n",
      "Epoch 1023, loss: 0.6359021067619324, grad norm: 0.5531782507896423\n",
      "Epoch 1024, loss: 0.6357795596122742, grad norm: 0.5548547506332397\n",
      "Epoch 1025, loss: 0.6356557607650757, grad norm: 0.5564902424812317\n",
      "Epoch 1026, loss: 0.6355336904525757, grad norm: 0.5580865144729614\n",
      "Epoch 1027, loss: 0.6354101896286011, grad norm: 0.5597185492515564\n",
      "Epoch 1028, loss: 0.635286271572113, grad norm: 0.5612205862998962\n",
      "Epoch 1029, loss: 0.6351633071899414, grad norm: 0.5628606677055359\n",
      "Epoch 1030, loss: 0.6350376605987549, grad norm: 0.5642796754837036\n",
      "Epoch 1031, loss: 0.6349132061004639, grad norm: 0.5659217238426208\n",
      "Epoch 1032, loss: 0.6347880959510803, grad norm: 0.5673816204071045\n",
      "Epoch 1033, loss: 0.6346627473831177, grad norm: 0.5690692067146301\n",
      "Epoch 1034, loss: 0.63453608751297, grad norm: 0.5704821944236755\n",
      "Epoch 1035, loss: 0.6344128847122192, grad norm: 0.5721233487129211\n",
      "Epoch 1036, loss: 0.6342859268188477, grad norm: 0.573636531829834\n",
      "Epoch 1037, loss: 0.6341573596000671, grad norm: 0.5751368999481201\n",
      "Epoch 1038, loss: 0.6340323686599731, grad norm: 0.576615035533905\n",
      "Epoch 1039, loss: 0.6339040994644165, grad norm: 0.5781627893447876\n",
      "Epoch 1040, loss: 0.6337766647338867, grad norm: 0.57967609167099\n",
      "Epoch 1041, loss: 0.6336479187011719, grad norm: 0.5811370015144348\n",
      "Epoch 1042, loss: 0.6335182785987854, grad norm: 0.5826531052589417\n",
      "Epoch 1043, loss: 0.6333879232406616, grad norm: 0.5841552019119263\n",
      "Epoch 1044, loss: 0.6332603693008423, grad norm: 0.5856031179428101\n",
      "Epoch 1045, loss: 0.6331291198730469, grad norm: 0.5871182084083557\n",
      "Epoch 1046, loss: 0.6329977512359619, grad norm: 0.5885348320007324\n",
      "Epoch 1047, loss: 0.6328682899475098, grad norm: 0.5900164842605591\n",
      "Epoch 1048, loss: 0.6327362656593323, grad norm: 0.5913846492767334\n",
      "Epoch 1049, loss: 0.6326041221618652, grad norm: 0.5928505063056946\n",
      "Epoch 1050, loss: 0.632472574710846, grad norm: 0.5943083167076111\n",
      "Epoch 1051, loss: 0.6323399543762207, grad norm: 0.5957278609275818\n",
      "Epoch 1052, loss: 0.6322070956230164, grad norm: 0.5970072150230408\n",
      "Epoch 1053, loss: 0.632072925567627, grad norm: 0.5984274744987488\n",
      "Epoch 1054, loss: 0.6319414377212524, grad norm: 0.5997834801673889\n",
      "Epoch 1055, loss: 0.6318061947822571, grad norm: 0.6011078357696533\n",
      "Epoch 1056, loss: 0.6316709518432617, grad norm: 0.6025009155273438\n",
      "Epoch 1057, loss: 0.6315361261367798, grad norm: 0.603753387928009\n",
      "Epoch 1058, loss: 0.6314011216163635, grad norm: 0.605175793170929\n",
      "Epoch 1059, loss: 0.6312664151191711, grad norm: 0.6063337326049805\n",
      "Epoch 1060, loss: 0.6311291456222534, grad norm: 0.6076222658157349\n",
      "Epoch 1061, loss: 0.6309925317764282, grad norm: 0.6089603900909424\n",
      "Epoch 1062, loss: 0.6308550834655762, grad norm: 0.6101659536361694\n",
      "Epoch 1063, loss: 0.6307175159454346, grad norm: 0.6115217804908752\n",
      "Epoch 1064, loss: 0.6305813193321228, grad norm: 0.6127294301986694\n",
      "Epoch 1065, loss: 0.630441427230835, grad norm: 0.6139609217643738\n",
      "Epoch 1066, loss: 0.6303051114082336, grad norm: 0.6151145100593567\n",
      "Epoch 1067, loss: 0.6301642656326294, grad norm: 0.616341769695282\n",
      "Epoch 1068, loss: 0.6300263404846191, grad norm: 0.6174604296684265\n",
      "Epoch 1069, loss: 0.6298863887786865, grad norm: 0.6186544895172119\n",
      "Epoch 1070, loss: 0.6297453045845032, grad norm: 0.6198441386222839\n",
      "Epoch 1071, loss: 0.629605233669281, grad norm: 0.6209448575973511\n",
      "Epoch 1072, loss: 0.62946617603302, grad norm: 0.6219346523284912\n",
      "Epoch 1073, loss: 0.6293240189552307, grad norm: 0.6228703260421753\n",
      "Epoch 1074, loss: 0.6291821599006653, grad norm: 0.624025821685791\n",
      "Epoch 1075, loss: 0.6290389895439148, grad norm: 0.6250280737876892\n",
      "Epoch 1076, loss: 0.6288981437683105, grad norm: 0.6261196136474609\n",
      "Epoch 1077, loss: 0.6287557482719421, grad norm: 0.6270108819007874\n",
      "Epoch 1078, loss: 0.6286122798919678, grad norm: 0.627911388874054\n",
      "Epoch 1079, loss: 0.6284696459770203, grad norm: 0.6289010643959045\n",
      "Epoch 1080, loss: 0.6283267140388489, grad norm: 0.6297940611839294\n",
      "Epoch 1081, loss: 0.628182590007782, grad norm: 0.6306794285774231\n",
      "Epoch 1082, loss: 0.6280377507209778, grad norm: 0.631560206413269\n",
      "Epoch 1083, loss: 0.6278939247131348, grad norm: 0.6323134899139404\n",
      "Epoch 1084, loss: 0.6277492046356201, grad norm: 0.6332014799118042\n",
      "Epoch 1085, loss: 0.6276028156280518, grad norm: 0.6340758800506592\n",
      "Epoch 1086, loss: 0.6274579167366028, grad norm: 0.634840190410614\n",
      "Epoch 1087, loss: 0.6273127794265747, grad norm: 0.6355966925621033\n",
      "Epoch 1088, loss: 0.6271663308143616, grad norm: 0.6362357139587402\n",
      "Epoch 1089, loss: 0.6270201802253723, grad norm: 0.6369880437850952\n",
      "Epoch 1090, loss: 0.6268740892410278, grad norm: 0.6376218795776367\n",
      "Epoch 1091, loss: 0.6267279386520386, grad norm: 0.6382376551628113\n",
      "Epoch 1092, loss: 0.6265822052955627, grad norm: 0.6389004588127136\n",
      "Epoch 1093, loss: 0.6264339089393616, grad norm: 0.6395418643951416\n",
      "Epoch 1094, loss: 0.626286506652832, grad norm: 0.6402165293693542\n",
      "Epoch 1095, loss: 0.6261388063430786, grad norm: 0.640626072883606\n",
      "Epoch 1096, loss: 0.6259913444519043, grad norm: 0.6411416530609131\n",
      "Epoch 1097, loss: 0.6258435249328613, grad norm: 0.6415868401527405\n",
      "Epoch 1098, loss: 0.625695526599884, grad norm: 0.6421017050743103\n",
      "Epoch 1099, loss: 0.6255474090576172, grad norm: 0.6425072550773621\n",
      "Epoch 1100, loss: 0.6254000663757324, grad norm: 0.6430246829986572\n",
      "Epoch 1101, loss: 0.6252513527870178, grad norm: 0.6433960199356079\n",
      "Epoch 1102, loss: 0.6251009106636047, grad norm: 0.6437442898750305\n",
      "Epoch 1103, loss: 0.6249532699584961, grad norm: 0.6440303325653076\n",
      "Epoch 1104, loss: 0.6248046159744263, grad norm: 0.6443750262260437\n",
      "Epoch 1105, loss: 0.6246541738510132, grad norm: 0.6446710228919983\n",
      "Epoch 1106, loss: 0.6245070695877075, grad norm: 0.6448732614517212\n",
      "Epoch 1107, loss: 0.624355673789978, grad norm: 0.6451682448387146\n",
      "Epoch 1108, loss: 0.624207079410553, grad norm: 0.6453637480735779\n",
      "Epoch 1109, loss: 0.6240592002868652, grad norm: 0.6454178690910339\n",
      "Epoch 1110, loss: 0.6239102482795715, grad norm: 0.6455485820770264\n",
      "Epoch 1111, loss: 0.6237597465515137, grad norm: 0.6457054615020752\n",
      "Epoch 1112, loss: 0.6236096620559692, grad norm: 0.6456591486930847\n",
      "Epoch 1113, loss: 0.6234605312347412, grad norm: 0.6457483172416687\n",
      "Epoch 1114, loss: 0.6233117580413818, grad norm: 0.645768404006958\n",
      "Epoch 1115, loss: 0.6231626272201538, grad norm: 0.6456228494644165\n",
      "Epoch 1116, loss: 0.6230129599571228, grad norm: 0.6456031799316406\n",
      "Epoch 1117, loss: 0.6228627562522888, grad norm: 0.6454529166221619\n",
      "Epoch 1118, loss: 0.622713565826416, grad norm: 0.6454015970230103\n",
      "Epoch 1119, loss: 0.6225641965866089, grad norm: 0.6451819539070129\n",
      "Epoch 1120, loss: 0.6224150657653809, grad norm: 0.6450533270835876\n",
      "Epoch 1121, loss: 0.6222665905952454, grad norm: 0.6447657942771912\n",
      "Epoch 1122, loss: 0.6221175193786621, grad norm: 0.644450843334198\n",
      "Epoch 1123, loss: 0.621968686580658, grad norm: 0.6442707777023315\n",
      "Epoch 1124, loss: 0.621819257736206, grad norm: 0.6439254283905029\n",
      "Epoch 1125, loss: 0.6216706037521362, grad norm: 0.6435436010360718\n",
      "Epoch 1126, loss: 0.6215229034423828, grad norm: 0.6432077288627625\n",
      "Epoch 1127, loss: 0.6213735342025757, grad norm: 0.6428543925285339\n",
      "Epoch 1128, loss: 0.6212255358695984, grad norm: 0.6423256397247314\n",
      "Epoch 1129, loss: 0.6210783123970032, grad norm: 0.6418588161468506\n",
      "Epoch 1130, loss: 0.6209290623664856, grad norm: 0.6413768529891968\n",
      "Epoch 1131, loss: 0.6207819581031799, grad norm: 0.6408288478851318\n",
      "Epoch 1132, loss: 0.6206353902816772, grad norm: 0.64019775390625\n",
      "Epoch 1133, loss: 0.6204885244369507, grad norm: 0.6396077871322632\n",
      "Epoch 1134, loss: 0.620340883731842, grad norm: 0.6389986872673035\n",
      "Epoch 1135, loss: 0.6201946139335632, grad norm: 0.6383960843086243\n",
      "Epoch 1136, loss: 0.6200488209724426, grad norm: 0.637673556804657\n",
      "Epoch 1137, loss: 0.6199020147323608, grad norm: 0.6369576454162598\n",
      "Epoch 1138, loss: 0.6197559833526611, grad norm: 0.6362383365631104\n",
      "Epoch 1139, loss: 0.619611382484436, grad norm: 0.6354800462722778\n",
      "Epoch 1140, loss: 0.6194661855697632, grad norm: 0.634637713432312\n",
      "Epoch 1141, loss: 0.6193221807479858, grad norm: 0.6337775588035583\n",
      "Epoch 1142, loss: 0.6191776990890503, grad norm: 0.6328907608985901\n",
      "Epoch 1143, loss: 0.6190332174301147, grad norm: 0.6318891644477844\n",
      "Epoch 1144, loss: 0.6188889741897583, grad norm: 0.6311313509941101\n",
      "Epoch 1145, loss: 0.618745744228363, grad norm: 0.6301170587539673\n",
      "Epoch 1146, loss: 0.6186018586158752, grad norm: 0.6289945244789124\n",
      "Epoch 1147, loss: 0.6184612512588501, grad norm: 0.6280274987220764\n",
      "Epoch 1148, loss: 0.6183187365531921, grad norm: 0.6270071268081665\n",
      "Epoch 1149, loss: 0.6181771159172058, grad norm: 0.6259568333625793\n",
      "Epoch 1150, loss: 0.6180353164672852, grad norm: 0.624833345413208\n",
      "Epoch 1151, loss: 0.6178948879241943, grad norm: 0.6237169504165649\n",
      "Epoch 1152, loss: 0.6177549362182617, grad norm: 0.6224732398986816\n",
      "Epoch 1153, loss: 0.6176151037216187, grad norm: 0.6214672923088074\n",
      "Epoch 1154, loss: 0.6174766421318054, grad norm: 0.620064914226532\n",
      "Epoch 1155, loss: 0.6173363327980042, grad norm: 0.6186861395835876\n",
      "Epoch 1156, loss: 0.6171988248825073, grad norm: 0.6175895929336548\n",
      "Epoch 1157, loss: 0.617061972618103, grad norm: 0.6162297129631042\n",
      "Epoch 1158, loss: 0.6169233918190002, grad norm: 0.6148428320884705\n",
      "Epoch 1159, loss: 0.6167864799499512, grad norm: 0.6135075688362122\n",
      "Epoch 1160, loss: 0.6166519522666931, grad norm: 0.6119920015335083\n",
      "Epoch 1161, loss: 0.6165139675140381, grad norm: 0.6106269359588623\n",
      "Epoch 1162, loss: 0.6163811683654785, grad norm: 0.6091547608375549\n",
      "Epoch 1163, loss: 0.6162468791007996, grad norm: 0.6076211929321289\n",
      "Epoch 1164, loss: 0.61611407995224, grad norm: 0.6063643097877502\n",
      "Epoch 1165, loss: 0.615979790687561, grad norm: 0.6048049926757812\n",
      "Epoch 1166, loss: 0.6158478856086731, grad norm: 0.6032391786575317\n",
      "Epoch 1167, loss: 0.6157151460647583, grad norm: 0.6016482710838318\n",
      "Epoch 1168, loss: 0.6155837178230286, grad norm: 0.600183367729187\n",
      "Epoch 1169, loss: 0.615455687046051, grad norm: 0.5983683466911316\n",
      "Epoch 1170, loss: 0.6153243184089661, grad norm: 0.5967951416969299\n",
      "Epoch 1171, loss: 0.6151947975158691, grad norm: 0.5952093005180359\n",
      "Epoch 1172, loss: 0.6150668859481812, grad norm: 0.5933939218521118\n",
      "Epoch 1173, loss: 0.6149372458457947, grad norm: 0.5918288826942444\n",
      "Epoch 1174, loss: 0.6148110628128052, grad norm: 0.5899989604949951\n",
      "Epoch 1175, loss: 0.6146836280822754, grad norm: 0.5883694291114807\n",
      "Epoch 1176, loss: 0.6145581603050232, grad norm: 0.5866114497184753\n",
      "Epoch 1177, loss: 0.6144323945045471, grad norm: 0.584753692150116\n",
      "Epoch 1178, loss: 0.6143086552619934, grad norm: 0.5829451084136963\n",
      "Epoch 1179, loss: 0.6141849756240845, grad norm: 0.581116795539856\n",
      "Epoch 1180, loss: 0.6140620708465576, grad norm: 0.579321026802063\n",
      "Epoch 1181, loss: 0.6139401197433472, grad norm: 0.5772578120231628\n",
      "Epoch 1182, loss: 0.6138173937797546, grad norm: 0.5755738019943237\n",
      "Epoch 1183, loss: 0.6136960983276367, grad norm: 0.5734741687774658\n",
      "Epoch 1184, loss: 0.6135761737823486, grad norm: 0.5716917514801025\n",
      "Epoch 1185, loss: 0.6134581565856934, grad norm: 0.569815456867218\n",
      "Epoch 1186, loss: 0.6133397221565247, grad norm: 0.567762553691864\n",
      "Epoch 1187, loss: 0.613221287727356, grad norm: 0.5658608078956604\n",
      "Epoch 1188, loss: 0.6131036877632141, grad norm: 0.5638797283172607\n",
      "Epoch 1189, loss: 0.6129888296127319, grad norm: 0.5618290901184082\n",
      "Epoch 1190, loss: 0.6128721237182617, grad norm: 0.5597593188285828\n",
      "Epoch 1191, loss: 0.6127576231956482, grad norm: 0.5578967332839966\n",
      "Epoch 1192, loss: 0.6126440763473511, grad norm: 0.5557343363761902\n",
      "Epoch 1193, loss: 0.6125301122665405, grad norm: 0.5537505745887756\n",
      "Epoch 1194, loss: 0.612418532371521, grad norm: 0.5516632199287415\n",
      "Epoch 1195, loss: 0.6123054027557373, grad norm: 0.5496640205383301\n",
      "Epoch 1196, loss: 0.6121959686279297, grad norm: 0.5475065112113953\n",
      "Epoch 1197, loss: 0.6120858192443848, grad norm: 0.5453318357467651\n",
      "Epoch 1198, loss: 0.6119755506515503, grad norm: 0.5430780053138733\n",
      "Epoch 1199, loss: 0.6118674874305725, grad norm: 0.541151225566864\n",
      "Epoch 1200, loss: 0.6117600798606873, grad norm: 0.538874089717865\n",
      "Epoch 1201, loss: 0.6116530895233154, grad norm: 0.5368568897247314\n",
      "Epoch 1202, loss: 0.6115474700927734, grad norm: 0.5344957709312439\n",
      "Epoch 1203, loss: 0.6114424467086792, grad norm: 0.5325562357902527\n",
      "Epoch 1204, loss: 0.6113380193710327, grad norm: 0.530292809009552\n",
      "Epoch 1205, loss: 0.6112342476844788, grad norm: 0.5281244516372681\n",
      "Epoch 1206, loss: 0.611131489276886, grad norm: 0.5259557366371155\n",
      "Epoch 1207, loss: 0.6110292673110962, grad norm: 0.5237698554992676\n",
      "Epoch 1208, loss: 0.610927939414978, grad norm: 0.5216124057769775\n",
      "Epoch 1209, loss: 0.6108279228210449, grad norm: 0.5194118618965149\n",
      "Epoch 1210, loss: 0.6107281446456909, grad norm: 0.5171506404876709\n",
      "Epoch 1211, loss: 0.6106293201446533, grad norm: 0.5148248076438904\n",
      "Epoch 1212, loss: 0.610531210899353, grad norm: 0.5126526951789856\n",
      "Epoch 1213, loss: 0.6104339361190796, grad norm: 0.5102616548538208\n",
      "Epoch 1214, loss: 0.6103371381759644, grad norm: 0.5082281827926636\n",
      "Epoch 1215, loss: 0.6102409362792969, grad norm: 0.5058228969573975\n",
      "Epoch 1216, loss: 0.6101471185684204, grad norm: 0.5034223794937134\n",
      "Epoch 1217, loss: 0.6100523471832275, grad norm: 0.5012108683586121\n",
      "Epoch 1218, loss: 0.609959602355957, grad norm: 0.49899160861968994\n",
      "Epoch 1219, loss: 0.6098666787147522, grad norm: 0.4966859519481659\n",
      "Epoch 1220, loss: 0.6097747087478638, grad norm: 0.4943578839302063\n",
      "Epoch 1221, loss: 0.6096845269203186, grad norm: 0.49222418665885925\n",
      "Epoch 1222, loss: 0.6095945239067078, grad norm: 0.49003905057907104\n",
      "Epoch 1223, loss: 0.6095051765441895, grad norm: 0.4879036247730255\n",
      "Epoch 1224, loss: 0.6094176173210144, grad norm: 0.48551908135414124\n",
      "Epoch 1225, loss: 0.609328031539917, grad norm: 0.483104944229126\n",
      "Epoch 1226, loss: 0.6092420816421509, grad norm: 0.48090624809265137\n",
      "Epoch 1227, loss: 0.6091558337211609, grad norm: 0.47847437858581543\n",
      "Epoch 1228, loss: 0.6090707182884216, grad norm: 0.4762369692325592\n",
      "Epoch 1229, loss: 0.6089856028556824, grad norm: 0.473922997713089\n",
      "Epoch 1230, loss: 0.608901858329773, grad norm: 0.47179898619651794\n",
      "Epoch 1231, loss: 0.6088195443153381, grad norm: 0.46951842308044434\n",
      "Epoch 1232, loss: 0.6087379455566406, grad norm: 0.4671286344528198\n",
      "Epoch 1233, loss: 0.608655571937561, grad norm: 0.46485039591789246\n",
      "Epoch 1234, loss: 0.6085745096206665, grad norm: 0.4626598656177521\n",
      "Epoch 1235, loss: 0.6084944009780884, grad norm: 0.460191935300827\n",
      "Epoch 1236, loss: 0.6084136962890625, grad norm: 0.4580257833003998\n",
      "Epoch 1237, loss: 0.6083346009254456, grad norm: 0.4557930827140808\n",
      "Epoch 1238, loss: 0.6082568168640137, grad norm: 0.4535626769065857\n",
      "Epoch 1239, loss: 0.6081809997558594, grad norm: 0.45114535093307495\n",
      "Epoch 1240, loss: 0.6081035137176514, grad norm: 0.44896528124809265\n",
      "Epoch 1241, loss: 0.6080275774002075, grad norm: 0.44667670130729675\n",
      "Epoch 1242, loss: 0.6079533696174622, grad norm: 0.4444241523742676\n",
      "Epoch 1243, loss: 0.6078781485557556, grad norm: 0.44214415550231934\n",
      "Epoch 1244, loss: 0.6078045964241028, grad norm: 0.4400825500488281\n",
      "Epoch 1245, loss: 0.6077316403388977, grad norm: 0.4376339316368103\n",
      "Epoch 1246, loss: 0.6076578497886658, grad norm: 0.4355336129665375\n",
      "Epoch 1247, loss: 0.6075873970985413, grad norm: 0.43332189321517944\n",
      "Epoch 1248, loss: 0.6075164079666138, grad norm: 0.43124040961265564\n",
      "Epoch 1249, loss: 0.6074467301368713, grad norm: 0.4288339912891388\n",
      "Epoch 1250, loss: 0.6073762774467468, grad norm: 0.42669278383255005\n",
      "Epoch 1251, loss: 0.6073080897331238, grad norm: 0.42450225353240967\n",
      "Epoch 1252, loss: 0.607239842414856, grad norm: 0.4222899377346039\n",
      "Epoch 1253, loss: 0.6071723103523254, grad norm: 0.4200211763381958\n",
      "Epoch 1254, loss: 0.6071042418479919, grad norm: 0.4179171919822693\n",
      "Epoch 1255, loss: 0.6070387363433838, grad norm: 0.415637731552124\n",
      "Epoch 1256, loss: 0.6069730520248413, grad norm: 0.4134509265422821\n",
      "Epoch 1257, loss: 0.6069076657295227, grad norm: 0.41128942370414734\n",
      "Epoch 1258, loss: 0.606843888759613, grad norm: 0.4092002809047699\n",
      "Epoch 1259, loss: 0.6067806482315063, grad norm: 0.40703943371772766\n",
      "Epoch 1260, loss: 0.6067171692848206, grad norm: 0.40474942326545715\n",
      "Epoch 1261, loss: 0.6066544651985168, grad norm: 0.4027099907398224\n",
      "Epoch 1262, loss: 0.6065911054611206, grad norm: 0.4005567729473114\n",
      "Epoch 1263, loss: 0.6065305471420288, grad norm: 0.3985314965248108\n",
      "Epoch 1264, loss: 0.6064713001251221, grad norm: 0.39647695422172546\n",
      "Epoch 1265, loss: 0.6064097881317139, grad norm: 0.3944152295589447\n",
      "Epoch 1266, loss: 0.6063516736030579, grad norm: 0.3921603560447693\n",
      "Epoch 1267, loss: 0.6062926054000854, grad norm: 0.3901379108428955\n",
      "Epoch 1268, loss: 0.6062339544296265, grad norm: 0.38805505633354187\n",
      "Epoch 1269, loss: 0.6061769723892212, grad norm: 0.38605302572250366\n",
      "Epoch 1270, loss: 0.606118381023407, grad norm: 0.38378244638442993\n",
      "Epoch 1271, loss: 0.6060614585876465, grad norm: 0.38184821605682373\n",
      "Epoch 1272, loss: 0.606005072593689, grad norm: 0.3799136281013489\n",
      "Epoch 1273, loss: 0.6059504151344299, grad norm: 0.3778572380542755\n",
      "Epoch 1274, loss: 0.6058951020240784, grad norm: 0.3757144808769226\n",
      "Epoch 1275, loss: 0.6058406829833984, grad norm: 0.3738667666912079\n",
      "Epoch 1276, loss: 0.6057881116867065, grad norm: 0.37197384238243103\n",
      "Epoch 1277, loss: 0.605732798576355, grad norm: 0.369840145111084\n",
      "Epoch 1278, loss: 0.6056801080703735, grad norm: 0.36782413721084595\n",
      "Epoch 1279, loss: 0.605628252029419, grad norm: 0.3659793436527252\n",
      "Epoch 1280, loss: 0.6055771112442017, grad norm: 0.36392876505851746\n",
      "Epoch 1281, loss: 0.6055258512496948, grad norm: 0.36203762888908386\n",
      "Epoch 1282, loss: 0.6054736375808716, grad norm: 0.36002954840660095\n",
      "Epoch 1283, loss: 0.6054226160049438, grad norm: 0.3581591546535492\n",
      "Epoch 1284, loss: 0.6053740978240967, grad norm: 0.35628029704093933\n",
      "Epoch 1285, loss: 0.605324923992157, grad norm: 0.3543074429035187\n",
      "Epoch 1286, loss: 0.6052761077880859, grad norm: 0.3525118827819824\n",
      "Epoch 1287, loss: 0.6052259802818298, grad norm: 0.3506077229976654\n",
      "Epoch 1288, loss: 0.6051791906356812, grad norm: 0.34882184863090515\n",
      "Epoch 1289, loss: 0.6051325798034668, grad norm: 0.3467707633972168\n",
      "Epoch 1290, loss: 0.6050841808319092, grad norm: 0.3450324833393097\n",
      "Epoch 1291, loss: 0.6050373315811157, grad norm: 0.3432779014110565\n",
      "Epoch 1292, loss: 0.6049918532371521, grad norm: 0.34119316935539246\n",
      "Epoch 1293, loss: 0.6049460172653198, grad norm: 0.33943432569503784\n",
      "Epoch 1294, loss: 0.6049007177352905, grad norm: 0.33752354979515076\n",
      "Epoch 1295, loss: 0.6048566102981567, grad norm: 0.33572691679000854\n",
      "Epoch 1296, loss: 0.6048108339309692, grad norm: 0.3340381383895874\n",
      "Epoch 1297, loss: 0.6047675609588623, grad norm: 0.33234021067619324\n",
      "Epoch 1298, loss: 0.6047236919403076, grad norm: 0.3305893540382385\n",
      "Epoch 1299, loss: 0.6046809554100037, grad norm: 0.32876330614089966\n",
      "Epoch 1300, loss: 0.6046386361122131, grad norm: 0.32703959941864014\n",
      "Epoch 1301, loss: 0.6045952439308167, grad norm: 0.3252676725387573\n",
      "Epoch 1302, loss: 0.6045531630516052, grad norm: 0.32357633113861084\n",
      "Epoch 1303, loss: 0.6045109033584595, grad norm: 0.3218819499015808\n",
      "Epoch 1304, loss: 0.6044694781303406, grad norm: 0.320221871137619\n",
      "Epoch 1305, loss: 0.6044299602508545, grad norm: 0.31849536299705505\n",
      "Epoch 1306, loss: 0.6043887138366699, grad norm: 0.31700921058654785\n",
      "Epoch 1307, loss: 0.6043484210968018, grad norm: 0.31534332036972046\n",
      "Epoch 1308, loss: 0.6043084859848022, grad norm: 0.3136996626853943\n",
      "Epoch 1309, loss: 0.6042709946632385, grad norm: 0.31195342540740967\n",
      "Epoch 1310, loss: 0.6042313575744629, grad norm: 0.3103897273540497\n",
      "Epoch 1311, loss: 0.6041916608810425, grad norm: 0.3086763024330139\n",
      "Epoch 1312, loss: 0.6041548252105713, grad norm: 0.3071660101413727\n",
      "Epoch 1313, loss: 0.6041158437728882, grad norm: 0.3056398332118988\n",
      "Epoch 1314, loss: 0.6040788292884827, grad norm: 0.30405110120773315\n",
      "Epoch 1315, loss: 0.6040416955947876, grad norm: 0.3024986982345581\n",
      "Epoch 1316, loss: 0.6040041446685791, grad norm: 0.3009655177593231\n",
      "Epoch 1317, loss: 0.6039695143699646, grad norm: 0.2993610203266144\n",
      "Epoch 1318, loss: 0.6039326786994934, grad norm: 0.29770156741142273\n",
      "Epoch 1319, loss: 0.603895366191864, grad norm: 0.296255499124527\n",
      "Epoch 1320, loss: 0.6038607954978943, grad norm: 0.2947041392326355\n",
      "Epoch 1321, loss: 0.6038239002227783, grad norm: 0.293332576751709\n",
      "Epoch 1322, loss: 0.6037908792495728, grad norm: 0.29176685214042664\n",
      "Epoch 1323, loss: 0.6037559509277344, grad norm: 0.29024842381477356\n",
      "Epoch 1324, loss: 0.6037208437919617, grad norm: 0.28863832354545593\n",
      "Epoch 1325, loss: 0.6036878824234009, grad norm: 0.2873404026031494\n",
      "Epoch 1326, loss: 0.603654146194458, grad norm: 0.28590112924575806\n",
      "Epoch 1327, loss: 0.6036192178726196, grad norm: 0.28434130549430847\n",
      "Epoch 1328, loss: 0.6035866737365723, grad norm: 0.2830856442451477\n",
      "Epoch 1329, loss: 0.6035541296005249, grad norm: 0.2816033661365509\n",
      "Epoch 1330, loss: 0.6035215854644775, grad norm: 0.2803300619125366\n",
      "Epoch 1331, loss: 0.6034888029098511, grad norm: 0.2787330150604248\n",
      "Epoch 1332, loss: 0.6034558415412903, grad norm: 0.2774260938167572\n",
      "Epoch 1333, loss: 0.6034237146377563, grad norm: 0.2761007845401764\n",
      "Epoch 1334, loss: 0.6033934354782104, grad norm: 0.2746734619140625\n",
      "Epoch 1335, loss: 0.6033610701560974, grad norm: 0.27331289649009705\n",
      "Epoch 1336, loss: 0.6033298373222351, grad norm: 0.27203598618507385\n",
      "Epoch 1337, loss: 0.6032998561859131, grad norm: 0.2707836627960205\n",
      "Epoch 1338, loss: 0.6032710671424866, grad norm: 0.2695336937904358\n",
      "Epoch 1339, loss: 0.6032396554946899, grad norm: 0.2679801285266876\n",
      "Epoch 1340, loss: 0.6032083034515381, grad norm: 0.26685309410095215\n",
      "Epoch 1341, loss: 0.6031807661056519, grad norm: 0.265619158744812\n",
      "Epoch 1342, loss: 0.6031484007835388, grad norm: 0.2644186019897461\n",
      "Epoch 1343, loss: 0.6031206846237183, grad norm: 0.2630707025527954\n",
      "Epoch 1344, loss: 0.603091299533844, grad norm: 0.2618263363838196\n",
      "Epoch 1345, loss: 0.6030634641647339, grad norm: 0.2605811059474945\n",
      "Epoch 1346, loss: 0.603035032749176, grad norm: 0.2592800259590149\n",
      "Epoch 1347, loss: 0.60300612449646, grad norm: 0.2580682635307312\n",
      "Epoch 1348, loss: 0.6029766798019409, grad norm: 0.25684022903442383\n",
      "Epoch 1349, loss: 0.602949857711792, grad norm: 0.25559771060943604\n",
      "Epoch 1350, loss: 0.6029229760169983, grad norm: 0.2544749677181244\n",
      "Epoch 1351, loss: 0.6028958559036255, grad norm: 0.25323787331581116\n",
      "Epoch 1352, loss: 0.6028688549995422, grad norm: 0.25197315216064453\n",
      "Epoch 1353, loss: 0.6028423309326172, grad norm: 0.250814288854599\n",
      "Epoch 1354, loss: 0.6028133034706116, grad norm: 0.24982644617557526\n",
      "Epoch 1355, loss: 0.6027886867523193, grad norm: 0.24838787317276\n",
      "Epoch 1356, loss: 0.6027604341506958, grad norm: 0.24745427072048187\n",
      "Epoch 1357, loss: 0.602734386920929, grad norm: 0.24625332653522491\n",
      "Epoch 1358, loss: 0.6027084589004517, grad norm: 0.24509388208389282\n",
      "Epoch 1359, loss: 0.6026830673217773, grad norm: 0.24401476979255676\n",
      "Epoch 1360, loss: 0.602656900882721, grad norm: 0.24293772876262665\n",
      "Epoch 1361, loss: 0.6026322245597839, grad norm: 0.2419789582490921\n",
      "Epoch 1362, loss: 0.6026066541671753, grad norm: 0.24077723920345306\n",
      "Epoch 1363, loss: 0.6025805473327637, grad norm: 0.2397388219833374\n",
      "Epoch 1364, loss: 0.6025559902191162, grad norm: 0.23875772953033447\n",
      "Epoch 1365, loss: 0.6025326251983643, grad norm: 0.23770108819007874\n",
      "Epoch 1366, loss: 0.6025068163871765, grad norm: 0.23659087717533112\n",
      "Epoch 1367, loss: 0.6024824380874634, grad norm: 0.2357504516839981\n",
      "Epoch 1368, loss: 0.6024585962295532, grad norm: 0.23465822637081146\n",
      "Epoch 1369, loss: 0.6024355888366699, grad norm: 0.23358707129955292\n",
      "Epoch 1370, loss: 0.6024096012115479, grad norm: 0.23247067630290985\n",
      "Epoch 1371, loss: 0.602385938167572, grad norm: 0.23164914548397064\n",
      "Epoch 1372, loss: 0.6023641228675842, grad norm: 0.23083274066448212\n",
      "Epoch 1373, loss: 0.6023418307304382, grad norm: 0.2295500785112381\n",
      "Epoch 1374, loss: 0.602317214012146, grad norm: 0.2285182625055313\n",
      "Epoch 1375, loss: 0.602293848991394, grad norm: 0.22777166962623596\n",
      "Epoch 1376, loss: 0.6022714972496033, grad norm: 0.2267455905675888\n",
      "Epoch 1377, loss: 0.6022474765777588, grad norm: 0.22568465769290924\n",
      "Epoch 1378, loss: 0.6022266149520874, grad norm: 0.22463150322437286\n",
      "Epoch 1379, loss: 0.6022024154663086, grad norm: 0.223903626203537\n",
      "Epoch 1380, loss: 0.6021814346313477, grad norm: 0.2227972447872162\n",
      "Epoch 1381, loss: 0.6021591424942017, grad norm: 0.2220044881105423\n",
      "Epoch 1382, loss: 0.602136492729187, grad norm: 0.22115297615528107\n",
      "Epoch 1383, loss: 0.6021153926849365, grad norm: 0.22030919790267944\n",
      "Epoch 1384, loss: 0.6020926237106323, grad norm: 0.21934576332569122\n",
      "Epoch 1385, loss: 0.6020713448524475, grad norm: 0.2184799313545227\n",
      "Epoch 1386, loss: 0.6020498871803284, grad norm: 0.21771948039531708\n",
      "Epoch 1387, loss: 0.6020300984382629, grad norm: 0.21680466830730438\n",
      "Epoch 1388, loss: 0.6020093560218811, grad norm: 0.2157512605190277\n",
      "Epoch 1389, loss: 0.601985514163971, grad norm: 0.21495847404003143\n",
      "Epoch 1390, loss: 0.6019662618637085, grad norm: 0.21410590410232544\n",
      "Epoch 1391, loss: 0.6019458770751953, grad norm: 0.21325655281543732\n",
      "Epoch 1392, loss: 0.6019253134727478, grad norm: 0.21250490844249725\n",
      "Epoch 1393, loss: 0.6019045114517212, grad norm: 0.21168875694274902\n",
      "Epoch 1394, loss: 0.6018848419189453, grad norm: 0.2108696699142456\n",
      "Epoch 1395, loss: 0.6018638014793396, grad norm: 0.21014884114265442\n",
      "Epoch 1396, loss: 0.6018433570861816, grad norm: 0.20920667052268982\n",
      "Epoch 1397, loss: 0.6018239259719849, grad norm: 0.20843000710010529\n",
      "Epoch 1398, loss: 0.6018040180206299, grad norm: 0.20774589478969574\n",
      "Epoch 1399, loss: 0.6017847061157227, grad norm: 0.20686690509319305\n",
      "Epoch 1400, loss: 0.6017651557922363, grad norm: 0.20617112517356873\n",
      "Epoch 1401, loss: 0.6017452478408813, grad norm: 0.20533080399036407\n",
      "Epoch 1402, loss: 0.6017262935638428, grad norm: 0.20459260046482086\n",
      "Epoch 1403, loss: 0.6017065048217773, grad norm: 0.20380625128746033\n",
      "Epoch 1404, loss: 0.6016862392425537, grad norm: 0.20298928022384644\n",
      "Epoch 1405, loss: 0.6016667485237122, grad norm: 0.2023206204175949\n",
      "Epoch 1406, loss: 0.6016495227813721, grad norm: 0.2015685886144638\n",
      "Epoch 1407, loss: 0.6016291379928589, grad norm: 0.20081214606761932\n",
      "Epoch 1408, loss: 0.6016112565994263, grad norm: 0.20012615621089935\n",
      "Epoch 1409, loss: 0.601593554019928, grad norm: 0.19952505826950073\n",
      "Epoch 1410, loss: 0.6015756130218506, grad norm: 0.19879589974880219\n",
      "Epoch 1411, loss: 0.6015560626983643, grad norm: 0.19805555045604706\n",
      "Epoch 1412, loss: 0.6015366315841675, grad norm: 0.19737359881401062\n",
      "Epoch 1413, loss: 0.6015201807022095, grad norm: 0.19689032435417175\n",
      "Epoch 1414, loss: 0.6015030741691589, grad norm: 0.196106418967247\n",
      "Epoch 1415, loss: 0.6014834046363831, grad norm: 0.19536979496479034\n",
      "Epoch 1416, loss: 0.601464033126831, grad norm: 0.19479641318321228\n",
      "Epoch 1417, loss: 0.6014468669891357, grad norm: 0.19418585300445557\n",
      "Epoch 1418, loss: 0.6014301776885986, grad norm: 0.19350317120552063\n",
      "Epoch 1419, loss: 0.6014130115509033, grad norm: 0.1928592324256897\n",
      "Epoch 1420, loss: 0.6013950109481812, grad norm: 0.19219902157783508\n",
      "Epoch 1421, loss: 0.6013772487640381, grad norm: 0.19140124320983887\n",
      "Epoch 1422, loss: 0.6013598442077637, grad norm: 0.1908755749464035\n",
      "Epoch 1423, loss: 0.6013437509536743, grad norm: 0.1902337223291397\n",
      "Epoch 1424, loss: 0.6013247966766357, grad norm: 0.18945617973804474\n",
      "Epoch 1425, loss: 0.6013085246086121, grad norm: 0.18883511424064636\n",
      "Epoch 1426, loss: 0.6012911796569824, grad norm: 0.18822847306728363\n",
      "Epoch 1427, loss: 0.6012740731239319, grad norm: 0.1877099722623825\n",
      "Epoch 1428, loss: 0.6012587547302246, grad norm: 0.18706311285495758\n",
      "Epoch 1429, loss: 0.6012412309646606, grad norm: 0.18652409315109253\n",
      "Epoch 1430, loss: 0.6012246608734131, grad norm: 0.18591374158859253\n",
      "Epoch 1431, loss: 0.6012083292007446, grad norm: 0.1853216141462326\n",
      "Epoch 1432, loss: 0.6011916995048523, grad norm: 0.18474364280700684\n",
      "Epoch 1433, loss: 0.6011732816696167, grad norm: 0.18424586951732635\n",
      "Epoch 1434, loss: 0.6011582612991333, grad norm: 0.18366791307926178\n",
      "Epoch 1435, loss: 0.6011422872543335, grad norm: 0.18315458297729492\n",
      "Epoch 1436, loss: 0.6011266708374023, grad norm: 0.1825718730688095\n",
      "Epoch 1437, loss: 0.6011109352111816, grad norm: 0.18210378289222717\n",
      "Epoch 1438, loss: 0.601094663143158, grad norm: 0.18160316348075867\n",
      "Epoch 1439, loss: 0.6010785102844238, grad norm: 0.18095441162586212\n",
      "Epoch 1440, loss: 0.6010626554489136, grad norm: 0.18052732944488525\n",
      "Epoch 1441, loss: 0.6010479927062988, grad norm: 0.17984220385551453\n",
      "Epoch 1442, loss: 0.6010307669639587, grad norm: 0.1792391836643219\n",
      "Epoch 1443, loss: 0.6010141968727112, grad norm: 0.17882736027240753\n",
      "Epoch 1444, loss: 0.6009987592697144, grad norm: 0.1782602220773697\n",
      "Epoch 1445, loss: 0.6009825468063354, grad norm: 0.17773397266864777\n",
      "Epoch 1446, loss: 0.600967288017273, grad norm: 0.17724066972732544\n",
      "Epoch 1447, loss: 0.600951611995697, grad norm: 0.17692723870277405\n",
      "Epoch 1448, loss: 0.6009383201599121, grad norm: 0.1763550341129303\n",
      "Epoch 1449, loss: 0.600921630859375, grad norm: 0.1757761389017105\n",
      "Epoch 1450, loss: 0.6009066104888916, grad norm: 0.17536193132400513\n",
      "Epoch 1451, loss: 0.6008909940719604, grad norm: 0.17490579187870026\n",
      "Epoch 1452, loss: 0.6008760929107666, grad norm: 0.17435036599636078\n",
      "Epoch 1453, loss: 0.6008621454238892, grad norm: 0.17382487654685974\n",
      "Epoch 1454, loss: 0.6008462905883789, grad norm: 0.17349345982074738\n",
      "Epoch 1455, loss: 0.6008314490318298, grad norm: 0.1730448603630066\n",
      "Epoch 1456, loss: 0.6008186340332031, grad norm: 0.17244605720043182\n",
      "Epoch 1457, loss: 0.6008020639419556, grad norm: 0.1721300333738327\n",
      "Epoch 1458, loss: 0.6007884740829468, grad norm: 0.17165957391262054\n",
      "Epoch 1459, loss: 0.6007721424102783, grad norm: 0.1711268573999405\n",
      "Epoch 1460, loss: 0.6007582545280457, grad norm: 0.17078813910484314\n",
      "Epoch 1461, loss: 0.6007434725761414, grad norm: 0.1703035980463028\n",
      "Epoch 1462, loss: 0.6007287502288818, grad norm: 0.1698407083749771\n",
      "Epoch 1463, loss: 0.600714921951294, grad norm: 0.16940738260746002\n",
      "Epoch 1464, loss: 0.6006996631622314, grad norm: 0.16906249523162842\n",
      "Epoch 1465, loss: 0.6006852388381958, grad norm: 0.16856983304023743\n",
      "Epoch 1466, loss: 0.6006717681884766, grad norm: 0.16819186508655548\n",
      "Epoch 1467, loss: 0.6006581783294678, grad norm: 0.16778407990932465\n",
      "Epoch 1468, loss: 0.6006430387496948, grad norm: 0.16738902032375336\n",
      "Epoch 1469, loss: 0.6006301641464233, grad norm: 0.16698919236660004\n",
      "Epoch 1470, loss: 0.6006165742874146, grad norm: 0.16656777262687683\n",
      "Epoch 1471, loss: 0.6006016731262207, grad norm: 0.16609910130500793\n",
      "Epoch 1472, loss: 0.6005874872207642, grad norm: 0.16576842963695526\n",
      "Epoch 1473, loss: 0.6005741357803345, grad norm: 0.16529132425785065\n",
      "Epoch 1474, loss: 0.6005586385726929, grad norm: 0.16497845947742462\n",
      "Epoch 1475, loss: 0.6005455255508423, grad norm: 0.1646602600812912\n",
      "Epoch 1476, loss: 0.6005321741104126, grad norm: 0.16427533328533173\n",
      "Epoch 1477, loss: 0.6005190014839172, grad norm: 0.1639273762702942\n",
      "Epoch 1478, loss: 0.600504457950592, grad norm: 0.16346445679664612\n",
      "Epoch 1479, loss: 0.6004917621612549, grad norm: 0.16314303874969482\n",
      "Epoch 1480, loss: 0.6004785895347595, grad norm: 0.1627863496541977\n",
      "Epoch 1481, loss: 0.6004630923271179, grad norm: 0.16244463622570038\n",
      "Epoch 1482, loss: 0.6004494428634644, grad norm: 0.16210418939590454\n",
      "Epoch 1483, loss: 0.6004374623298645, grad norm: 0.1618402749300003\n",
      "Epoch 1484, loss: 0.6004238128662109, grad norm: 0.16146869957447052\n",
      "Epoch 1485, loss: 0.6004108190536499, grad norm: 0.16111120581626892\n",
      "Epoch 1486, loss: 0.6003963947296143, grad norm: 0.1607992947101593\n",
      "Epoch 1487, loss: 0.6003842353820801, grad norm: 0.1604834944009781\n",
      "Epoch 1488, loss: 0.6003708243370056, grad norm: 0.1599980890750885\n",
      "Epoch 1489, loss: 0.600358247756958, grad norm: 0.15971678495407104\n",
      "Epoch 1490, loss: 0.600344717502594, grad norm: 0.1593310832977295\n",
      "Epoch 1491, loss: 0.6003314256668091, grad norm: 0.15910159051418304\n",
      "Epoch 1492, loss: 0.600318431854248, grad norm: 0.15866298973560333\n",
      "Epoch 1493, loss: 0.6003053188323975, grad norm: 0.15821950137615204\n",
      "Epoch 1494, loss: 0.6002932190895081, grad norm: 0.15799778699874878\n",
      "Epoch 1495, loss: 0.6002805829048157, grad norm: 0.15781278908252716\n",
      "Epoch 1496, loss: 0.6002686023712158, grad norm: 0.1573733687400818\n",
      "Epoch 1497, loss: 0.6002537608146667, grad norm: 0.1572963148355484\n",
      "Epoch 1498, loss: 0.6002432107925415, grad norm: 0.15680906176567078\n",
      "Epoch 1499, loss: 0.6002290844917297, grad norm: 0.15666775405406952\n",
      "Epoch 1500, loss: 0.6002165675163269, grad norm: 0.1563531905412674\n",
      "Epoch 1501, loss: 0.600204586982727, grad norm: 0.15592125058174133\n",
      "Epoch 1502, loss: 0.6001907587051392, grad norm: 0.1556158810853958\n",
      "Epoch 1503, loss: 0.6001784801483154, grad norm: 0.1553514152765274\n",
      "Epoch 1504, loss: 0.6001665592193604, grad norm: 0.15516571700572968\n",
      "Epoch 1505, loss: 0.6001534461975098, grad norm: 0.1548933982849121\n",
      "Epoch 1506, loss: 0.6001404523849487, grad norm: 0.15470901131629944\n",
      "Epoch 1507, loss: 0.6001282334327698, grad norm: 0.15438643097877502\n",
      "Epoch 1508, loss: 0.6001155972480774, grad norm: 0.15392382442951202\n",
      "Epoch 1509, loss: 0.6001020073890686, grad norm: 0.15370504558086395\n",
      "Epoch 1510, loss: 0.6000893712043762, grad norm: 0.15351594984531403\n",
      "Epoch 1511, loss: 0.6000784635543823, grad norm: 0.15320147573947906\n",
      "Epoch 1512, loss: 0.6000670194625854, grad norm: 0.1530745029449463\n",
      "Epoch 1513, loss: 0.6000534296035767, grad norm: 0.15280300378799438\n",
      "Epoch 1514, loss: 0.6000397205352783, grad norm: 0.15247967839241028\n",
      "Epoch 1515, loss: 0.6000295877456665, grad norm: 0.15235376358032227\n",
      "Epoch 1516, loss: 0.6000185012817383, grad norm: 0.15207679569721222\n",
      "Epoch 1517, loss: 0.6000055074691772, grad norm: 0.15181946754455566\n",
      "Epoch 1518, loss: 0.5999945402145386, grad norm: 0.151610866189003\n",
      "Epoch 1519, loss: 0.5999823808670044, grad norm: 0.15127979218959808\n",
      "Epoch 1520, loss: 0.5999692678451538, grad norm: 0.15108811855316162\n",
      "Epoch 1521, loss: 0.5999574661254883, grad norm: 0.15085701644420624\n",
      "Epoch 1522, loss: 0.599943995475769, grad norm: 0.15064404904842377\n",
      "Epoch 1523, loss: 0.5999333262443542, grad norm: 0.150339737534523\n",
      "Epoch 1524, loss: 0.5999206900596619, grad norm: 0.15014177560806274\n",
      "Epoch 1525, loss: 0.5999098420143127, grad norm: 0.14990319311618805\n",
      "Epoch 1526, loss: 0.5998973250389099, grad norm: 0.1496298611164093\n",
      "Epoch 1527, loss: 0.5998852252960205, grad norm: 0.14939181506633759\n",
      "Epoch 1528, loss: 0.5998722314834595, grad norm: 0.1492343693971634\n",
      "Epoch 1529, loss: 0.5998618602752686, grad norm: 0.14893577992916107\n",
      "Epoch 1530, loss: 0.5998505353927612, grad norm: 0.1488560140132904\n",
      "Epoch 1531, loss: 0.5998393297195435, grad norm: 0.14846079051494598\n",
      "Epoch 1532, loss: 0.5998265743255615, grad norm: 0.14817485213279724\n",
      "Epoch 1533, loss: 0.5998135805130005, grad norm: 0.14814135432243347\n",
      "Epoch 1534, loss: 0.5998030304908752, grad norm: 0.14792588353157043\n",
      "Epoch 1535, loss: 0.5997905731201172, grad norm: 0.14780017733573914\n",
      "Epoch 1536, loss: 0.5997799634933472, grad norm: 0.1477019041776657\n",
      "Epoch 1537, loss: 0.599767804145813, grad norm: 0.1474534273147583\n",
      "Epoch 1538, loss: 0.5997564792633057, grad norm: 0.14731980860233307\n",
      "Epoch 1539, loss: 0.5997447967529297, grad norm: 0.1470111906528473\n",
      "Epoch 1540, loss: 0.5997321605682373, grad norm: 0.146845743060112\n",
      "Epoch 1541, loss: 0.5997203588485718, grad norm: 0.14671124517917633\n",
      "Epoch 1542, loss: 0.5997104644775391, grad norm: 0.14658324420452118\n",
      "Epoch 1543, loss: 0.5996975898742676, grad norm: 0.14645427465438843\n",
      "Epoch 1544, loss: 0.5996870994567871, grad norm: 0.14625176787376404\n",
      "Epoch 1545, loss: 0.5996745824813843, grad norm: 0.1461082398891449\n",
      "Epoch 1546, loss: 0.5996646285057068, grad norm: 0.14592669904232025\n",
      "Epoch 1547, loss: 0.5996529459953308, grad norm: 0.14563344419002533\n",
      "Epoch 1548, loss: 0.5996422171592712, grad norm: 0.14545124769210815\n",
      "Epoch 1549, loss: 0.5996304750442505, grad norm: 0.14525993168354034\n",
      "Epoch 1550, loss: 0.5996202826499939, grad norm: 0.14513473212718964\n",
      "Epoch 1551, loss: 0.599606990814209, grad norm: 0.14493419229984283\n",
      "Epoch 1552, loss: 0.5995959043502808, grad norm: 0.14479215443134308\n",
      "Epoch 1553, loss: 0.5995854139328003, grad norm: 0.14458641409873962\n",
      "Epoch 1554, loss: 0.5995751619338989, grad norm: 0.1444276124238968\n",
      "Epoch 1555, loss: 0.5995625257492065, grad norm: 0.14446964859962463\n",
      "Epoch 1556, loss: 0.5995508432388306, grad norm: 0.14431890845298767\n",
      "Epoch 1557, loss: 0.5995389223098755, grad norm: 0.1440625935792923\n",
      "Epoch 1558, loss: 0.5995292067527771, grad norm: 0.14395953714847565\n",
      "Epoch 1559, loss: 0.5995184779167175, grad norm: 0.14362649619579315\n",
      "Epoch 1560, loss: 0.5995054244995117, grad norm: 0.1435132473707199\n",
      "Epoch 1561, loss: 0.599494993686676, grad norm: 0.14341047406196594\n",
      "Epoch 1562, loss: 0.5994836091995239, grad norm: 0.14327773451805115\n",
      "Epoch 1563, loss: 0.5994726419448853, grad norm: 0.14319129288196564\n",
      "Epoch 1564, loss: 0.5994617938995361, grad norm: 0.14302881062030792\n",
      "Epoch 1565, loss: 0.5994490385055542, grad norm: 0.14290639758110046\n",
      "Epoch 1566, loss: 0.5994389057159424, grad norm: 0.14285151660442352\n",
      "Epoch 1567, loss: 0.5994283556938171, grad norm: 0.1427406370639801\n",
      "Epoch 1568, loss: 0.5994187593460083, grad norm: 0.1427038013935089\n",
      "Epoch 1569, loss: 0.5994064807891846, grad norm: 0.14245235919952393\n",
      "Epoch 1570, loss: 0.5993943214416504, grad norm: 0.14244824647903442\n",
      "Epoch 1571, loss: 0.5993841290473938, grad norm: 0.14232490956783295\n",
      "Epoch 1572, loss: 0.5993717312812805, grad norm: 0.14216336607933044\n",
      "Epoch 1573, loss: 0.5993609428405762, grad norm: 0.14199373126029968\n",
      "Epoch 1574, loss: 0.5993496775627136, grad norm: 0.14182013273239136\n",
      "Epoch 1575, loss: 0.5993379354476929, grad norm: 0.14176078140735626\n",
      "Epoch 1576, loss: 0.5993287563323975, grad norm: 0.141602024435997\n",
      "Epoch 1577, loss: 0.5993164777755737, grad norm: 0.14153429865837097\n",
      "Epoch 1578, loss: 0.599307119846344, grad norm: 0.14153306186199188\n",
      "Epoch 1579, loss: 0.5992963910102844, grad norm: 0.14130528271198273\n",
      "Epoch 1580, loss: 0.5992867350578308, grad norm: 0.14108806848526\n",
      "Epoch 1581, loss: 0.5992728471755981, grad norm: 0.14107364416122437\n",
      "Epoch 1582, loss: 0.5992627739906311, grad norm: 0.14100152254104614\n",
      "Epoch 1583, loss: 0.599251389503479, grad norm: 0.14096283912658691\n",
      "Epoch 1584, loss: 0.5992412567138672, grad norm: 0.14090441167354584\n",
      "Epoch 1585, loss: 0.5992303490638733, grad norm: 0.14074376225471497\n",
      "Epoch 1586, loss: 0.5992188453674316, grad norm: 0.1407560110092163\n",
      "Epoch 1587, loss: 0.599211573600769, grad norm: 0.14051595330238342\n",
      "Epoch 1588, loss: 0.5991977453231812, grad norm: 0.14057981967926025\n",
      "Epoch 1589, loss: 0.5991879105567932, grad norm: 0.14060132205486298\n",
      "Epoch 1590, loss: 0.5991758108139038, grad norm: 0.14030821621418\n",
      "Epoch 1591, loss: 0.5991659760475159, grad norm: 0.14024019241333008\n",
      "Epoch 1592, loss: 0.5991553068161011, grad norm: 0.14030492305755615\n",
      "Epoch 1593, loss: 0.5991441011428833, grad norm: 0.14014476537704468\n",
      "Epoch 1594, loss: 0.5991350412368774, grad norm: 0.1400599479675293\n",
      "Epoch 1595, loss: 0.5991232991218567, grad norm: 0.13994050025939941\n",
      "Epoch 1596, loss: 0.5991133451461792, grad norm: 0.13984405994415283\n",
      "Epoch 1597, loss: 0.5991005301475525, grad norm: 0.13977351784706116\n",
      "Epoch 1598, loss: 0.5990888476371765, grad norm: 0.13967977464199066\n",
      "Epoch 1599, loss: 0.5990787744522095, grad norm: 0.13951987028121948\n",
      "Epoch 1600, loss: 0.5990668535232544, grad norm: 0.13955797255039215\n",
      "Epoch 1601, loss: 0.59906005859375, grad norm: 0.1394239217042923\n",
      "Epoch 1602, loss: 0.5990480780601501, grad norm: 0.13937944173812866\n",
      "Epoch 1603, loss: 0.5990362167358398, grad norm: 0.13948680460453033\n",
      "Epoch 1604, loss: 0.5990254878997803, grad norm: 0.1394323706626892\n",
      "Epoch 1605, loss: 0.5990145802497864, grad norm: 0.1393168717622757\n",
      "Epoch 1606, loss: 0.5990033745765686, grad norm: 0.13935768604278564\n",
      "Epoch 1607, loss: 0.5989946126937866, grad norm: 0.13933652639389038\n",
      "Epoch 1608, loss: 0.5989830493927002, grad norm: 0.13915079832077026\n",
      "Epoch 1609, loss: 0.5989713072776794, grad norm: 0.13910850882530212\n",
      "Epoch 1610, loss: 0.5989594459533691, grad norm: 0.139060378074646\n",
      "Epoch 1611, loss: 0.598950982093811, grad norm: 0.1392030566930771\n",
      "Epoch 1612, loss: 0.5989387631416321, grad norm: 0.13904279470443726\n",
      "Epoch 1613, loss: 0.5989285111427307, grad norm: 0.13889560103416443\n",
      "Epoch 1614, loss: 0.5989182591438293, grad norm: 0.1389097422361374\n",
      "Epoch 1615, loss: 0.5989067554473877, grad norm: 0.13891005516052246\n",
      "Epoch 1616, loss: 0.5988967418670654, grad norm: 0.138900026679039\n",
      "Epoch 1617, loss: 0.5988848209381104, grad norm: 0.13877776265144348\n",
      "Epoch 1618, loss: 0.5988761782646179, grad norm: 0.13883163034915924\n",
      "Epoch 1619, loss: 0.5988645553588867, grad norm: 0.13858263194561005\n",
      "Epoch 1620, loss: 0.5988526940345764, grad norm: 0.1385023295879364\n",
      "Epoch 1621, loss: 0.5988410711288452, grad norm: 0.13843409717082977\n",
      "Epoch 1622, loss: 0.5988290905952454, grad norm: 0.13858050107955933\n",
      "Epoch 1623, loss: 0.5988198518753052, grad norm: 0.13854481279850006\n",
      "Epoch 1624, loss: 0.5988104343414307, grad norm: 0.13843350112438202\n",
      "Epoch 1625, loss: 0.5987986326217651, grad norm: 0.13856631517410278\n",
      "Epoch 1626, loss: 0.5987889170646667, grad norm: 0.13864201307296753\n",
      "Epoch 1627, loss: 0.5987798571586609, grad norm: 0.13853561878204346\n",
      "Epoch 1628, loss: 0.5987674593925476, grad norm: 0.13860280811786652\n",
      "Epoch 1629, loss: 0.5987566113471985, grad norm: 0.13840250670909882\n",
      "Epoch 1630, loss: 0.5987465977668762, grad norm: 0.13847187161445618\n",
      "Epoch 1631, loss: 0.5987356305122375, grad norm: 0.13851001858711243\n",
      "Epoch 1632, loss: 0.5987255573272705, grad norm: 0.13842803239822388\n",
      "Epoch 1633, loss: 0.5987130403518677, grad norm: 0.1385207325220108\n",
      "Epoch 1634, loss: 0.5987029671669006, grad norm: 0.1384810209274292\n",
      "Epoch 1635, loss: 0.5986915826797485, grad norm: 0.1384137123823166\n",
      "Epoch 1636, loss: 0.5986804962158203, grad norm: 0.13840194046497345\n",
      "Epoch 1637, loss: 0.5986694693565369, grad norm: 0.13834640383720398\n",
      "Epoch 1638, loss: 0.5986588597297668, grad norm: 0.1383591592311859\n",
      "Epoch 1639, loss: 0.5986484289169312, grad norm: 0.13842010498046875\n",
      "Epoch 1640, loss: 0.5986371040344238, grad norm: 0.1383732408285141\n",
      "Epoch 1641, loss: 0.5986263751983643, grad norm: 0.13831926882266998\n",
      "Epoch 1642, loss: 0.5986179113388062, grad norm: 0.13842031359672546\n",
      "Epoch 1643, loss: 0.5986071825027466, grad norm: 0.138431116938591\n",
      "Epoch 1644, loss: 0.598594605922699, grad norm: 0.13846313953399658\n",
      "Epoch 1645, loss: 0.598585307598114, grad norm: 0.13833534717559814\n",
      "Epoch 1646, loss: 0.5985742807388306, grad norm: 0.13850592076778412\n",
      "Epoch 1647, loss: 0.5985626578330994, grad norm: 0.13841743767261505\n",
      "Epoch 1648, loss: 0.5985521078109741, grad norm: 0.13846474885940552\n",
      "Epoch 1649, loss: 0.5985407829284668, grad norm: 0.13843989372253418\n",
      "Epoch 1650, loss: 0.598530650138855, grad norm: 0.1384679079055786\n",
      "Epoch 1651, loss: 0.5985192656517029, grad norm: 0.13848787546157837\n",
      "Epoch 1652, loss: 0.598508358001709, grad norm: 0.1385226547718048\n",
      "Epoch 1653, loss: 0.5984972715377808, grad norm: 0.13845980167388916\n",
      "Epoch 1654, loss: 0.5984855890274048, grad norm: 0.13864827156066895\n",
      "Epoch 1655, loss: 0.5984766483306885, grad norm: 0.13856059312820435\n",
      "Epoch 1656, loss: 0.5984645485877991, grad norm: 0.13863682746887207\n",
      "Epoch 1657, loss: 0.5984536409378052, grad norm: 0.1387498527765274\n",
      "Epoch 1658, loss: 0.5984443426132202, grad norm: 0.13861152529716492\n",
      "Epoch 1659, loss: 0.5984311103820801, grad norm: 0.13868433237075806\n",
      "Epoch 1660, loss: 0.5984206199645996, grad norm: 0.13889563083648682\n",
      "Epoch 1661, loss: 0.5984112620353699, grad norm: 0.13874833285808563\n",
      "Epoch 1662, loss: 0.5983996391296387, grad norm: 0.13871753215789795\n",
      "Epoch 1663, loss: 0.5983880758285522, grad norm: 0.13880740106105804\n",
      "Epoch 1664, loss: 0.5983757972717285, grad norm: 0.13872185349464417\n",
      "Epoch 1665, loss: 0.598363995552063, grad norm: 0.13888806104660034\n",
      "Epoch 1666, loss: 0.5983543395996094, grad norm: 0.13905887305736542\n",
      "Epoch 1667, loss: 0.5983445644378662, grad norm: 0.1388300210237503\n",
      "Epoch 1668, loss: 0.5983312129974365, grad norm: 0.13897894322872162\n",
      "Epoch 1669, loss: 0.598321259021759, grad norm: 0.13907158374786377\n",
      "Epoch 1670, loss: 0.5983108282089233, grad norm: 0.1390516757965088\n",
      "Epoch 1671, loss: 0.5982992649078369, grad norm: 0.13929779827594757\n",
      "Epoch 1672, loss: 0.5982903242111206, grad norm: 0.1392432004213333\n",
      "Epoch 1673, loss: 0.5982779264450073, grad norm: 0.13930699229240417\n",
      "Epoch 1674, loss: 0.5982677936553955, grad norm: 0.13933366537094116\n",
      "Epoch 1675, loss: 0.5982556939125061, grad norm: 0.1393650621175766\n",
      "Epoch 1676, loss: 0.5982459783554077, grad norm: 0.13930928707122803\n",
      "Epoch 1677, loss: 0.598234236240387, grad norm: 0.13959814608097076\n",
      "Epoch 1678, loss: 0.5982222557067871, grad norm: 0.1395055055618286\n",
      "Epoch 1679, loss: 0.5982122421264648, grad norm: 0.1396310031414032\n",
      "Epoch 1680, loss: 0.5982005596160889, grad norm: 0.13960020244121552\n",
      "Epoch 1681, loss: 0.5981886982917786, grad norm: 0.13973446190357208\n",
      "Epoch 1682, loss: 0.5981770753860474, grad norm: 0.13975827395915985\n",
      "Epoch 1683, loss: 0.5981658101081848, grad norm: 0.13975980877876282\n",
      "Epoch 1684, loss: 0.5981557369232178, grad norm: 0.1399853378534317\n",
      "Epoch 1685, loss: 0.5981459021568298, grad norm: 0.14002931118011475\n",
      "Epoch 1686, loss: 0.5981339812278748, grad norm: 0.13991162180900574\n",
      "Epoch 1687, loss: 0.5981202721595764, grad norm: 0.14000141620635986\n",
      "Epoch 1688, loss: 0.5981107950210571, grad norm: 0.14014306664466858\n",
      "Epoch 1689, loss: 0.598099410533905, grad norm: 0.14007514715194702\n",
      "Epoch 1690, loss: 0.5980854034423828, grad norm: 0.14037486910820007\n",
      "Epoch 1691, loss: 0.5980760455131531, grad norm: 0.1403726041316986\n",
      "Epoch 1692, loss: 0.5980652570724487, grad norm: 0.14062197506427765\n",
      "Epoch 1693, loss: 0.5980561971664429, grad norm: 0.14052797853946686\n",
      "Epoch 1694, loss: 0.5980417728424072, grad norm: 0.1406361311674118\n",
      "Epoch 1695, loss: 0.5980318784713745, grad norm: 0.14078697562217712\n",
      "Epoch 1696, loss: 0.598020076751709, grad norm: 0.14091451466083527\n",
      "Epoch 1697, loss: 0.5980099439620972, grad norm: 0.14069901406764984\n",
      "Epoch 1698, loss: 0.5979970693588257, grad norm: 0.14094404876232147\n",
      "Epoch 1699, loss: 0.5979853272438049, grad norm: 0.14097563922405243\n",
      "Epoch 1700, loss: 0.5979732275009155, grad norm: 0.14103662967681885\n",
      "Epoch 1701, loss: 0.5979609489440918, grad norm: 0.14127904176712036\n",
      "Epoch 1702, loss: 0.5979515314102173, grad norm: 0.1412692815065384\n",
      "Epoch 1703, loss: 0.5979400873184204, grad norm: 0.14161013066768646\n",
      "Epoch 1704, loss: 0.5979300737380981, grad norm: 0.14143526554107666\n",
      "Epoch 1705, loss: 0.5979164838790894, grad norm: 0.14144855737686157\n",
      "Epoch 1706, loss: 0.5979054570198059, grad norm: 0.14160072803497314\n",
      "Epoch 1707, loss: 0.5978929996490479, grad norm: 0.14169402420520782\n",
      "Epoch 1708, loss: 0.5978822112083435, grad norm: 0.14185437560081482\n",
      "Epoch 1709, loss: 0.5978704690933228, grad norm: 0.1419329047203064\n",
      "Epoch 1710, loss: 0.5978587865829468, grad norm: 0.142068013548851\n",
      "Epoch 1711, loss: 0.5978464484214783, grad norm: 0.14215187728405\n",
      "Epoch 1712, loss: 0.5978350639343262, grad norm: 0.14237646758556366\n",
      "Epoch 1713, loss: 0.597823977470398, grad norm: 0.14235180616378784\n",
      "Epoch 1714, loss: 0.5978136658668518, grad norm: 0.1425083428621292\n",
      "Epoch 1715, loss: 0.5977994799613953, grad norm: 0.14272555708885193\n",
      "Epoch 1716, loss: 0.597788393497467, grad norm: 0.1427706629037857\n",
      "Epoch 1717, loss: 0.5977765321731567, grad norm: 0.1429062783718109\n",
      "Epoch 1718, loss: 0.597764253616333, grad norm: 0.14291530847549438\n",
      "Epoch 1719, loss: 0.597752034664154, grad norm: 0.14307084679603577\n",
      "Epoch 1720, loss: 0.5977401733398438, grad norm: 0.14314515888690948\n",
      "Epoch 1721, loss: 0.5977286100387573, grad norm: 0.14321677386760712\n",
      "Epoch 1722, loss: 0.5977163314819336, grad norm: 0.14335030317306519\n",
      "Epoch 1723, loss: 0.597703754901886, grad norm: 0.1434689313173294\n",
      "Epoch 1724, loss: 0.5976926684379578, grad norm: 0.14355455338954926\n",
      "Epoch 1725, loss: 0.5976788997650146, grad norm: 0.1436856985092163\n",
      "Epoch 1726, loss: 0.5976697206497192, grad norm: 0.1438969522714615\n",
      "Epoch 1727, loss: 0.5976564884185791, grad norm: 0.14383608102798462\n",
      "Epoch 1728, loss: 0.5976424217224121, grad norm: 0.14411288499832153\n",
      "Epoch 1729, loss: 0.5976331233978271, grad norm: 0.14429806172847748\n",
      "Epoch 1730, loss: 0.5976207852363586, grad norm: 0.14427636563777924\n",
      "Epoch 1731, loss: 0.5976067781448364, grad norm: 0.144509956240654\n",
      "Epoch 1732, loss: 0.5975962281227112, grad norm: 0.14456060528755188\n",
      "Epoch 1733, loss: 0.5975829362869263, grad norm: 0.1447705775499344\n",
      "Epoch 1734, loss: 0.5975701808929443, grad norm: 0.14494863152503967\n",
      "Epoch 1735, loss: 0.5975579023361206, grad norm: 0.1451183706521988\n",
      "Epoch 1736, loss: 0.5975481271743774, grad norm: 0.1452096402645111\n",
      "Epoch 1737, loss: 0.5975344777107239, grad norm: 0.14538736641407013\n",
      "Epoch 1738, loss: 0.5975222587585449, grad norm: 0.14538131654262543\n",
      "Epoch 1739, loss: 0.5975080728530884, grad norm: 0.14564327895641327\n",
      "Epoch 1740, loss: 0.5974980592727661, grad norm: 0.1457788646221161\n",
      "Epoch 1741, loss: 0.5974857807159424, grad norm: 0.14587189257144928\n",
      "Epoch 1742, loss: 0.5974724292755127, grad norm: 0.14606750011444092\n",
      "Epoch 1743, loss: 0.597460150718689, grad norm: 0.1460968554019928\n",
      "Epoch 1744, loss: 0.5974462032318115, grad norm: 0.1461564302444458\n",
      "Epoch 1745, loss: 0.5974339842796326, grad norm: 0.1463942676782608\n",
      "Epoch 1746, loss: 0.5974212884902954, grad norm: 0.14664605259895325\n",
      "Epoch 1747, loss: 0.5974093675613403, grad norm: 0.14672766625881195\n",
      "Epoch 1748, loss: 0.5973981618881226, grad norm: 0.14692050218582153\n",
      "Epoch 1749, loss: 0.5973842144012451, grad norm: 0.14712734520435333\n",
      "Epoch 1750, loss: 0.5973700284957886, grad norm: 0.14734108746051788\n",
      "Epoch 1751, loss: 0.5973595380783081, grad norm: 0.1473684310913086\n",
      "Epoch 1752, loss: 0.5973464250564575, grad norm: 0.14753571152687073\n",
      "Epoch 1753, loss: 0.5973328351974487, grad norm: 0.14765678346157074\n",
      "Epoch 1754, loss: 0.5973179340362549, grad norm: 0.14785446226596832\n",
      "Epoch 1755, loss: 0.5973066091537476, grad norm: 0.14808139204978943\n",
      "Epoch 1756, loss: 0.5972963571548462, grad norm: 0.1481822431087494\n",
      "Epoch 1757, loss: 0.5972814559936523, grad norm: 0.14831571280956268\n",
      "Epoch 1758, loss: 0.5972689390182495, grad norm: 0.14860989153385162\n",
      "Epoch 1759, loss: 0.5972563624382019, grad norm: 0.14868442714214325\n",
      "Epoch 1760, loss: 0.5972427725791931, grad norm: 0.14890533685684204\n",
      "Epoch 1761, loss: 0.5972291231155396, grad norm: 0.14899657666683197\n",
      "Epoch 1762, loss: 0.5972163081169128, grad norm: 0.14908988773822784\n",
      "Epoch 1763, loss: 0.597203254699707, grad norm: 0.1492844521999359\n",
      "Epoch 1764, loss: 0.5971890687942505, grad norm: 0.14937813580036163\n",
      "Epoch 1765, loss: 0.5971766710281372, grad norm: 0.14955531060695648\n",
      "Epoch 1766, loss: 0.5971628427505493, grad norm: 0.14985664188861847\n",
      "Epoch 1767, loss: 0.5971492528915405, grad norm: 0.14994250237941742\n",
      "Epoch 1768, loss: 0.5971392393112183, grad norm: 0.15017995238304138\n",
      "Epoch 1769, loss: 0.5971224904060364, grad norm: 0.15048642456531525\n",
      "Epoch 1770, loss: 0.5971097946166992, grad norm: 0.15048985183238983\n",
      "Epoch 1771, loss: 0.5970979928970337, grad norm: 0.1507353037595749\n",
      "Epoch 1772, loss: 0.5970836281776428, grad norm: 0.15091393887996674\n",
      "Epoch 1773, loss: 0.5970677137374878, grad norm: 0.15100853145122528\n",
      "Epoch 1774, loss: 0.5970548987388611, grad norm: 0.1512944996356964\n",
      "Epoch 1775, loss: 0.5970426797866821, grad norm: 0.15156039595603943\n",
      "Epoch 1776, loss: 0.597028374671936, grad norm: 0.15175601840019226\n",
      "Epoch 1777, loss: 0.5970159769058228, grad norm: 0.15196873247623444\n",
      "Epoch 1778, loss: 0.597000777721405, grad norm: 0.15219008922576904\n",
      "Epoch 1779, loss: 0.5969880223274231, grad norm: 0.1522887498140335\n",
      "Epoch 1780, loss: 0.5969741344451904, grad norm: 0.15247556567192078\n",
      "Epoch 1781, loss: 0.5969617962837219, grad norm: 0.15267963707447052\n",
      "Epoch 1782, loss: 0.5969452857971191, grad norm: 0.1528683751821518\n",
      "Epoch 1783, loss: 0.5969325304031372, grad norm: 0.15306739509105682\n",
      "Epoch 1784, loss: 0.5969187021255493, grad norm: 0.1532234251499176\n",
      "Epoch 1785, loss: 0.5969031453132629, grad norm: 0.153335303068161\n",
      "Epoch 1786, loss: 0.5968888401985168, grad norm: 0.15353482961654663\n",
      "Epoch 1787, loss: 0.5968755483627319, grad norm: 0.15385743975639343\n",
      "Epoch 1788, loss: 0.5968619585037231, grad norm: 0.15410396456718445\n",
      "Epoch 1789, loss: 0.5968480706214905, grad norm: 0.15419818460941315\n",
      "Epoch 1790, loss: 0.5968316197395325, grad norm: 0.1545144021511078\n",
      "Epoch 1791, loss: 0.5968211889266968, grad norm: 0.15462899208068848\n",
      "Epoch 1792, loss: 0.5968044400215149, grad norm: 0.15491119027137756\n",
      "Epoch 1793, loss: 0.5967905521392822, grad norm: 0.1550695151090622\n",
      "Epoch 1794, loss: 0.5967762470245361, grad norm: 0.15532851219177246\n",
      "Epoch 1795, loss: 0.5967623591423035, grad norm: 0.15542031824588776\n",
      "Epoch 1796, loss: 0.5967488884925842, grad norm: 0.15570595860481262\n",
      "Epoch 1797, loss: 0.5967327356338501, grad norm: 0.155907541513443\n",
      "Epoch 1798, loss: 0.5967197418212891, grad norm: 0.156076118350029\n",
      "Epoch 1799, loss: 0.5967041850090027, grad norm: 0.1562705934047699\n",
      "Epoch 1800, loss: 0.5966893434524536, grad norm: 0.15649989247322083\n",
      "Epoch 1801, loss: 0.5966747999191284, grad norm: 0.15677157044410706\n",
      "Epoch 1802, loss: 0.5966590046882629, grad norm: 0.15696930885314941\n",
      "Epoch 1803, loss: 0.5966442823410034, grad norm: 0.1572141945362091\n",
      "Epoch 1804, loss: 0.596630334854126, grad norm: 0.1574370563030243\n",
      "Epoch 1805, loss: 0.5966157913208008, grad norm: 0.15779025852680206\n",
      "Epoch 1806, loss: 0.5966004133224487, grad norm: 0.15799987316131592\n",
      "Epoch 1807, loss: 0.5965868234634399, grad norm: 0.15815024077892303\n",
      "Epoch 1808, loss: 0.5965696573257446, grad norm: 0.1583987921476364\n",
      "Epoch 1809, loss: 0.5965564250946045, grad norm: 0.15851432085037231\n",
      "Epoch 1810, loss: 0.5965409278869629, grad norm: 0.15867581963539124\n",
      "Epoch 1811, loss: 0.596523642539978, grad norm: 0.15901285409927368\n",
      "Epoch 1812, loss: 0.5965076684951782, grad norm: 0.1593325138092041\n",
      "Epoch 1813, loss: 0.5964963436126709, grad norm: 0.15940283238887787\n",
      "Epoch 1814, loss: 0.5964781045913696, grad norm: 0.15960653126239777\n",
      "Epoch 1815, loss: 0.5964622497558594, grad norm: 0.15988950431346893\n",
      "Epoch 1816, loss: 0.5964480042457581, grad norm: 0.16017958521842957\n",
      "Epoch 1817, loss: 0.5964327454566956, grad norm: 0.16032423079013824\n",
      "Epoch 1818, loss: 0.5964184999465942, grad norm: 0.16078872978687286\n",
      "Epoch 1819, loss: 0.5964012145996094, grad norm: 0.16101695597171783\n",
      "Epoch 1820, loss: 0.5963869690895081, grad norm: 0.1612168252468109\n",
      "Epoch 1821, loss: 0.5963708162307739, grad norm: 0.16145558655261993\n",
      "Epoch 1822, loss: 0.5963544249534607, grad norm: 0.16163387894630432\n",
      "Epoch 1823, loss: 0.5963385105133057, grad norm: 0.1619400680065155\n",
      "Epoch 1824, loss: 0.5963232517242432, grad norm: 0.16215933859348297\n",
      "Epoch 1825, loss: 0.5963073372840881, grad norm: 0.16240738332271576\n",
      "Epoch 1826, loss: 0.5962917804718018, grad norm: 0.16264943778514862\n",
      "Epoch 1827, loss: 0.5962744951248169, grad norm: 0.16281987726688385\n",
      "Epoch 1828, loss: 0.5962587594985962, grad norm: 0.1629847139120102\n",
      "Epoch 1829, loss: 0.5962433815002441, grad norm: 0.16326457262039185\n",
      "Epoch 1830, loss: 0.5962262749671936, grad norm: 0.16348783671855927\n",
      "Epoch 1831, loss: 0.5962090492248535, grad norm: 0.16384081542491913\n",
      "Epoch 1832, loss: 0.5961934328079224, grad norm: 0.16415821015834808\n",
      "Epoch 1833, loss: 0.5961785912513733, grad norm: 0.16428308188915253\n",
      "Epoch 1834, loss: 0.596159815788269, grad norm: 0.16473880410194397\n",
      "Epoch 1835, loss: 0.5961447954177856, grad norm: 0.16482235491275787\n",
      "Epoch 1836, loss: 0.5961275100708008, grad norm: 0.16522616147994995\n",
      "Epoch 1837, loss: 0.5961123704910278, grad norm: 0.16541728377342224\n",
      "Epoch 1838, loss: 0.5960950255393982, grad norm: 0.16556303203105927\n",
      "Epoch 1839, loss: 0.5960770845413208, grad norm: 0.16591008007526398\n",
      "Epoch 1840, loss: 0.5960611701011658, grad norm: 0.16620132327079773\n",
      "Epoch 1841, loss: 0.5960431098937988, grad norm: 0.16635264456272125\n",
      "Epoch 1842, loss: 0.596027135848999, grad norm: 0.16679923236370087\n",
      "Epoch 1843, loss: 0.5960120558738708, grad norm: 0.16690245270729065\n",
      "Epoch 1844, loss: 0.5959932804107666, grad norm: 0.167079895734787\n",
      "Epoch 1845, loss: 0.5959765911102295, grad norm: 0.16745305061340332\n",
      "Epoch 1846, loss: 0.5959598422050476, grad norm: 0.16773538291454315\n",
      "Epoch 1847, loss: 0.5959426164627075, grad norm: 0.1680316925048828\n",
      "Epoch 1848, loss: 0.595924973487854, grad norm: 0.16839398443698883\n",
      "Epoch 1849, loss: 0.5959076881408691, grad norm: 0.1686626672744751\n",
      "Epoch 1850, loss: 0.5958902835845947, grad norm: 0.16893061995506287\n",
      "Epoch 1851, loss: 0.5958741307258606, grad norm: 0.16921718418598175\n",
      "Epoch 1852, loss: 0.595856785774231, grad norm: 0.16936270892620087\n",
      "Epoch 1853, loss: 0.5958375334739685, grad norm: 0.16978169977664948\n",
      "Epoch 1854, loss: 0.5958201289176941, grad norm: 0.16988492012023926\n",
      "Epoch 1855, loss: 0.595801591873169, grad norm: 0.1702061891555786\n",
      "Epoch 1856, loss: 0.5957842469215393, grad norm: 0.17029772698879242\n",
      "Epoch 1857, loss: 0.5957668423652649, grad norm: 0.17060357332229614\n",
      "Epoch 1858, loss: 0.5957481861114502, grad norm: 0.17102688550949097\n",
      "Epoch 1859, loss: 0.595731258392334, grad norm: 0.17112858593463898\n",
      "Epoch 1860, loss: 0.5957112908363342, grad norm: 0.17147403955459595\n",
      "Epoch 1861, loss: 0.5956931114196777, grad norm: 0.1718079298734665\n",
      "Epoch 1862, loss: 0.5956763029098511, grad norm: 0.17212940752506256\n",
      "Epoch 1863, loss: 0.595658540725708, grad norm: 0.17242619395256042\n",
      "Epoch 1864, loss: 0.5956404209136963, grad norm: 0.17287398874759674\n",
      "Epoch 1865, loss: 0.5956231355667114, grad norm: 0.17294900119304657\n",
      "Epoch 1866, loss: 0.5956022143363953, grad norm: 0.17334532737731934\n",
      "Epoch 1867, loss: 0.5955849289894104, grad norm: 0.17368654906749725\n",
      "Epoch 1868, loss: 0.5955672264099121, grad norm: 0.17381857335567474\n",
      "Epoch 1869, loss: 0.5955474972724915, grad norm: 0.17418071627616882\n",
      "Epoch 1870, loss: 0.5955297946929932, grad norm: 0.17436136305332184\n",
      "Epoch 1871, loss: 0.5955091714859009, grad norm: 0.17464284598827362\n",
      "Epoch 1872, loss: 0.5954920053482056, grad norm: 0.17504212260246277\n",
      "Epoch 1873, loss: 0.5954738855361938, grad norm: 0.17531158030033112\n",
      "Epoch 1874, loss: 0.5954549312591553, grad norm: 0.17549465596675873\n",
      "Epoch 1875, loss: 0.5954344272613525, grad norm: 0.17592936754226685\n",
      "Epoch 1876, loss: 0.5954161286354065, grad norm: 0.17613346874713898\n",
      "Epoch 1877, loss: 0.5953971147537231, grad norm: 0.17631599307060242\n",
      "Epoch 1878, loss: 0.5953763723373413, grad norm: 0.17658329010009766\n",
      "Epoch 1879, loss: 0.5953585505485535, grad norm: 0.17701631784439087\n",
      "Epoch 1880, loss: 0.5953407287597656, grad norm: 0.17730307579040527\n",
      "Epoch 1881, loss: 0.5953205823898315, grad norm: 0.17771419882774353\n",
      "Epoch 1882, loss: 0.5953004360198975, grad norm: 0.17784631252288818\n",
      "Epoch 1883, loss: 0.5952803492546082, grad norm: 0.17824038863182068\n",
      "Epoch 1884, loss: 0.5952600240707397, grad norm: 0.1785733997821808\n",
      "Epoch 1885, loss: 0.5952408313751221, grad norm: 0.17886103689670563\n",
      "Epoch 1886, loss: 0.5952205657958984, grad norm: 0.17909689247608185\n",
      "Epoch 1887, loss: 0.595201313495636, grad norm: 0.17933136224746704\n",
      "Epoch 1888, loss: 0.5951805710792542, grad norm: 0.17959851026535034\n",
      "Epoch 1889, loss: 0.5951611399650574, grad norm: 0.1799318641424179\n",
      "Epoch 1890, loss: 0.5951410531997681, grad norm: 0.1802741140127182\n",
      "Epoch 1891, loss: 0.5951215624809265, grad norm: 0.18057598173618317\n",
      "Epoch 1892, loss: 0.595100462436676, grad norm: 0.18069133162498474\n",
      "Epoch 1893, loss: 0.5950777530670166, grad norm: 0.1811734139919281\n",
      "Epoch 1894, loss: 0.5950604677200317, grad norm: 0.18150396645069122\n",
      "Epoch 1895, loss: 0.5950395464897156, grad norm: 0.18175001442432404\n",
      "Epoch 1896, loss: 0.5950196981430054, grad norm: 0.18209415674209595\n",
      "Epoch 1897, loss: 0.5949992537498474, grad norm: 0.1822604387998581\n",
      "Epoch 1898, loss: 0.5949771404266357, grad norm: 0.1825455278158188\n",
      "Epoch 1899, loss: 0.5949555039405823, grad norm: 0.18299314379692078\n",
      "Epoch 1900, loss: 0.5949350595474243, grad norm: 0.18334536254405975\n",
      "Epoch 1901, loss: 0.5949162840843201, grad norm: 0.1836521178483963\n",
      "Epoch 1902, loss: 0.5948944091796875, grad norm: 0.18390095233917236\n",
      "Epoch 1903, loss: 0.594871997833252, grad norm: 0.18420739471912384\n",
      "Epoch 1904, loss: 0.5948532819747925, grad norm: 0.18456695973873138\n",
      "Epoch 1905, loss: 0.5948309898376465, grad norm: 0.18476887047290802\n",
      "Epoch 1906, loss: 0.5948090553283691, grad norm: 0.1850377321243286\n",
      "Epoch 1907, loss: 0.5947872996330261, grad norm: 0.18537938594818115\n",
      "Epoch 1908, loss: 0.5947654247283936, grad norm: 0.18572193384170532\n",
      "Epoch 1909, loss: 0.5947463512420654, grad norm: 0.1859874129295349\n",
      "Epoch 1910, loss: 0.5947239398956299, grad norm: 0.18626998364925385\n",
      "Epoch 1911, loss: 0.5947033762931824, grad norm: 0.1864989548921585\n",
      "Epoch 1912, loss: 0.5946801900863647, grad norm: 0.18686990439891815\n",
      "Epoch 1913, loss: 0.5946579575538635, grad norm: 0.1871674358844757\n",
      "Epoch 1914, loss: 0.5946347713470459, grad norm: 0.18738317489624023\n",
      "Epoch 1915, loss: 0.59461510181427, grad norm: 0.18777969479560852\n",
      "Epoch 1916, loss: 0.5945922136306763, grad norm: 0.1879277527332306\n",
      "Epoch 1917, loss: 0.5945687294006348, grad norm: 0.1883987933397293\n",
      "Epoch 1918, loss: 0.5945470333099365, grad norm: 0.18857291340827942\n",
      "Epoch 1919, loss: 0.5945236682891846, grad norm: 0.1891367882490158\n",
      "Epoch 1920, loss: 0.5945042371749878, grad norm: 0.18940496444702148\n",
      "Epoch 1921, loss: 0.5944811105728149, grad norm: 0.18966609239578247\n",
      "Epoch 1922, loss: 0.5944573283195496, grad norm: 0.18995749950408936\n",
      "Epoch 1923, loss: 0.594435453414917, grad norm: 0.19018840789794922\n",
      "Epoch 1924, loss: 0.59441077709198, grad norm: 0.19056914746761322\n",
      "Epoch 1925, loss: 0.5943896770477295, grad norm: 0.1909729689359665\n",
      "Epoch 1926, loss: 0.5943666696548462, grad norm: 0.19108381867408752\n",
      "Epoch 1927, loss: 0.5943434238433838, grad norm: 0.19144456088542938\n",
      "Epoch 1928, loss: 0.5943203568458557, grad norm: 0.19177451729774475\n",
      "Epoch 1929, loss: 0.594296932220459, grad norm: 0.19211801886558533\n",
      "Epoch 1930, loss: 0.5942735075950623, grad norm: 0.19229283928871155\n",
      "Epoch 1931, loss: 0.5942520499229431, grad norm: 0.1926204413175583\n",
      "Epoch 1932, loss: 0.5942275524139404, grad norm: 0.1929798275232315\n",
      "Epoch 1933, loss: 0.5942059755325317, grad norm: 0.19324514269828796\n",
      "Epoch 1934, loss: 0.59418123960495, grad norm: 0.19346822798252106\n",
      "Epoch 1935, loss: 0.5941573977470398, grad norm: 0.19387125968933105\n",
      "Epoch 1936, loss: 0.5941346287727356, grad norm: 0.19421599805355072\n",
      "Epoch 1937, loss: 0.5941102504730225, grad norm: 0.1943863332271576\n",
      "Epoch 1938, loss: 0.5940849781036377, grad norm: 0.19464313983917236\n",
      "Epoch 1939, loss: 0.5940617322921753, grad norm: 0.19499240815639496\n",
      "Epoch 1940, loss: 0.5940372943878174, grad norm: 0.19537892937660217\n",
      "Epoch 1941, loss: 0.5940138101577759, grad norm: 0.19561004638671875\n",
      "Epoch 1942, loss: 0.593988299369812, grad norm: 0.19585645198822021\n",
      "Epoch 1943, loss: 0.5939648151397705, grad norm: 0.1961980015039444\n",
      "Epoch 1944, loss: 0.593939483165741, grad norm: 0.196389302611351\n",
      "Epoch 1945, loss: 0.5939156413078308, grad norm: 0.19688862562179565\n",
      "Epoch 1946, loss: 0.5938924551010132, grad norm: 0.1971806287765503\n",
      "Epoch 1947, loss: 0.5938665866851807, grad norm: 0.1974440962076187\n",
      "Epoch 1948, loss: 0.5938414335250854, grad norm: 0.1977768987417221\n",
      "Epoch 1949, loss: 0.5938161611557007, grad norm: 0.19807113707065582\n",
      "Epoch 1950, loss: 0.5937927961349487, grad norm: 0.19844576716423035\n",
      "Epoch 1951, loss: 0.5937681794166565, grad norm: 0.19861885905265808\n",
      "Epoch 1952, loss: 0.5937421917915344, grad norm: 0.19895268976688385\n",
      "Epoch 1953, loss: 0.5937176942825317, grad norm: 0.19902662932872772\n",
      "Epoch 1954, loss: 0.593690037727356, grad norm: 0.1993224173784256\n",
      "Epoch 1955, loss: 0.5936651229858398, grad norm: 0.19966235756874084\n",
      "Epoch 1956, loss: 0.5936406850814819, grad norm: 0.19991043210029602\n",
      "Epoch 1957, loss: 0.5936154127120972, grad norm: 0.20020028948783875\n",
      "Epoch 1958, loss: 0.593590497970581, grad norm: 0.20066113770008087\n",
      "Epoch 1959, loss: 0.593565046787262, grad norm: 0.2007237672805786\n",
      "Epoch 1960, loss: 0.5935384035110474, grad norm: 0.201173797249794\n",
      "Epoch 1961, loss: 0.5935139656066895, grad norm: 0.20145881175994873\n",
      "Epoch 1962, loss: 0.5934864282608032, grad norm: 0.20178869366645813\n",
      "Epoch 1963, loss: 0.5934621095657349, grad norm: 0.20207490026950836\n",
      "Epoch 1964, loss: 0.5934367775917053, grad norm: 0.20226705074310303\n",
      "Epoch 1965, loss: 0.5934084057807922, grad norm: 0.20256099104881287\n",
      "Epoch 1966, loss: 0.5933822393417358, grad norm: 0.2028273493051529\n",
      "Epoch 1967, loss: 0.5933564901351929, grad norm: 0.2030905783176422\n",
      "Epoch 1968, loss: 0.593331515789032, grad norm: 0.2033216804265976\n",
      "Epoch 1969, loss: 0.5933039784431458, grad norm: 0.2035672515630722\n",
      "Epoch 1970, loss: 0.5932759046554565, grad norm: 0.20389056205749512\n",
      "Epoch 1971, loss: 0.5932499170303345, grad norm: 0.2041289359331131\n",
      "Epoch 1972, loss: 0.5932234525680542, grad norm: 0.20451727509498596\n",
      "Epoch 1973, loss: 0.5931965112686157, grad norm: 0.20477500557899475\n",
      "Epoch 1974, loss: 0.5931699872016907, grad norm: 0.20504246652126312\n",
      "Epoch 1975, loss: 0.593143105506897, grad norm: 0.205300971865654\n",
      "Epoch 1976, loss: 0.5931161642074585, grad norm: 0.20557697117328644\n",
      "Epoch 1977, loss: 0.5930919051170349, grad norm: 0.20570114254951477\n",
      "Epoch 1978, loss: 0.5930631160736084, grad norm: 0.2059796303510666\n",
      "Epoch 1979, loss: 0.5930345058441162, grad norm: 0.2061993032693863\n",
      "Epoch 1980, loss: 0.5930075645446777, grad norm: 0.20646026730537415\n",
      "Epoch 1981, loss: 0.5929786562919617, grad norm: 0.20675839483737946\n",
      "Epoch 1982, loss: 0.5929521322250366, grad norm: 0.2070227563381195\n",
      "Epoch 1983, loss: 0.5929244756698608, grad norm: 0.20733030140399933\n",
      "Epoch 1984, loss: 0.5928977131843567, grad norm: 0.20758502185344696\n",
      "Epoch 1985, loss: 0.59287029504776, grad norm: 0.2078263759613037\n",
      "Epoch 1986, loss: 0.5928418040275574, grad norm: 0.2081628292798996\n",
      "Epoch 1987, loss: 0.5928146243095398, grad norm: 0.20840398967266083\n",
      "Epoch 1988, loss: 0.5927868485450745, grad norm: 0.20861390233039856\n",
      "Epoch 1989, loss: 0.5927581787109375, grad norm: 0.20885050296783447\n",
      "Epoch 1990, loss: 0.5927311778068542, grad norm: 0.20893460512161255\n",
      "Epoch 1991, loss: 0.5927021503448486, grad norm: 0.20926769077777863\n",
      "Epoch 1992, loss: 0.5926728844642639, grad norm: 0.20935817062854767\n",
      "Epoch 1993, loss: 0.5926448106765747, grad norm: 0.20964322984218597\n",
      "Epoch 1994, loss: 0.5926169753074646, grad norm: 0.20982928574085236\n",
      "Epoch 1995, loss: 0.5925880670547485, grad norm: 0.2100563943386078\n",
      "Epoch 1996, loss: 0.5925585627555847, grad norm: 0.21051475405693054\n",
      "Epoch 1997, loss: 0.5925325751304626, grad norm: 0.21059612929821014\n",
      "Epoch 1998, loss: 0.592502236366272, grad norm: 0.21087437868118286\n",
      "Epoch 1999, loss: 0.592473566532135, grad norm: 0.21122102439403534\n",
      "Epoch 2000, loss: 0.5924456119537354, grad norm: 0.2114301174879074\n",
      "Epoch 2001, loss: 0.5924179553985596, grad norm: 0.21154062449932098\n",
      "Epoch 2002, loss: 0.5923885107040405, grad norm: 0.21181097626686096\n",
      "Epoch 2003, loss: 0.5923584699630737, grad norm: 0.21205058693885803\n",
      "Epoch 2004, loss: 0.5923304557800293, grad norm: 0.21220646798610687\n",
      "Epoch 2005, loss: 0.5922996997833252, grad norm: 0.21237067878246307\n",
      "Epoch 2006, loss: 0.5922707319259644, grad norm: 0.2124917060136795\n",
      "Epoch 2007, loss: 0.5922408699989319, grad norm: 0.2126021683216095\n",
      "Epoch 2008, loss: 0.5922102928161621, grad norm: 0.2129381150007248\n",
      "Epoch 2009, loss: 0.5921811461448669, grad norm: 0.2132372409105301\n",
      "Epoch 2010, loss: 0.5921547412872314, grad norm: 0.213546022772789\n",
      "Epoch 2011, loss: 0.5921239852905273, grad norm: 0.21356238424777985\n",
      "Epoch 2012, loss: 0.5920936465263367, grad norm: 0.21368050575256348\n",
      "Epoch 2013, loss: 0.5920630693435669, grad norm: 0.21405057609081268\n",
      "Epoch 2014, loss: 0.5920356512069702, grad norm: 0.21423135697841644\n",
      "Epoch 2015, loss: 0.5920050740242004, grad norm: 0.21445536613464355\n",
      "Epoch 2016, loss: 0.5919747352600098, grad norm: 0.21449871361255646\n",
      "Epoch 2017, loss: 0.5919449329376221, grad norm: 0.21472184360027313\n",
      "Epoch 2018, loss: 0.5919144153594971, grad norm: 0.21483555436134338\n",
      "Epoch 2019, loss: 0.591883659362793, grad norm: 0.21515193581581116\n",
      "Epoch 2020, loss: 0.5918548107147217, grad norm: 0.2151138186454773\n",
      "Epoch 2021, loss: 0.5918247699737549, grad norm: 0.2153175175189972\n",
      "Epoch 2022, loss: 0.5917950868606567, grad norm: 0.21557292342185974\n",
      "Epoch 2023, loss: 0.5917631387710571, grad norm: 0.2158024162054062\n",
      "Epoch 2024, loss: 0.5917338132858276, grad norm: 0.21607738733291626\n",
      "Epoch 2025, loss: 0.5917037129402161, grad norm: 0.2161291241645813\n",
      "Epoch 2026, loss: 0.5916728377342224, grad norm: 0.2163218855857849\n",
      "Epoch 2027, loss: 0.5916423201560974, grad norm: 0.21646350622177124\n",
      "Epoch 2028, loss: 0.5916112661361694, grad norm: 0.21656619012355804\n",
      "Epoch 2029, loss: 0.591580867767334, grad norm: 0.21669858694076538\n",
      "Epoch 2030, loss: 0.5915507078170776, grad norm: 0.21676239371299744\n",
      "Epoch 2031, loss: 0.5915189385414124, grad norm: 0.21687470376491547\n",
      "Epoch 2032, loss: 0.5914883613586426, grad norm: 0.21715101599693298\n",
      "Epoch 2033, loss: 0.591457724571228, grad norm: 0.21725116670131683\n",
      "Epoch 2034, loss: 0.5914274454116821, grad norm: 0.21729838848114014\n",
      "Epoch 2035, loss: 0.5913958549499512, grad norm: 0.21740438044071198\n",
      "Epoch 2036, loss: 0.59136563539505, grad norm: 0.21749377250671387\n",
      "Epoch 2037, loss: 0.591333270072937, grad norm: 0.21767589449882507\n",
      "Epoch 2038, loss: 0.5913031101226807, grad norm: 0.21783706545829773\n",
      "Epoch 2039, loss: 0.5912724733352661, grad norm: 0.21789489686489105\n",
      "Epoch 2040, loss: 0.5912405848503113, grad norm: 0.21813668310642242\n",
      "Epoch 2041, loss: 0.5912096500396729, grad norm: 0.2182130217552185\n",
      "Epoch 2042, loss: 0.5911784172058105, grad norm: 0.2182704657316208\n",
      "Epoch 2043, loss: 0.5911468267440796, grad norm: 0.2185869812965393\n",
      "Epoch 2044, loss: 0.5911161303520203, grad norm: 0.21861320734024048\n",
      "Epoch 2045, loss: 0.591083824634552, grad norm: 0.21867971122264862\n",
      "Epoch 2046, loss: 0.5910536050796509, grad norm: 0.21877102553844452\n",
      "Epoch 2047, loss: 0.5910229682922363, grad norm: 0.21876437962055206\n",
      "Epoch 2048, loss: 0.5909906029701233, grad norm: 0.21891048550605774\n",
      "Epoch 2049, loss: 0.5909578204154968, grad norm: 0.2191220223903656\n",
      "Epoch 2050, loss: 0.5909271836280823, grad norm: 0.219003364443779\n",
      "Epoch 2051, loss: 0.5908948183059692, grad norm: 0.21918192505836487\n",
      "Epoch 2052, loss: 0.5908644795417786, grad norm: 0.21918296813964844\n",
      "Epoch 2053, loss: 0.5908318758010864, grad norm: 0.21929560601711273\n",
      "Epoch 2054, loss: 0.5907989740371704, grad norm: 0.2194170355796814\n",
      "Epoch 2055, loss: 0.5907697081565857, grad norm: 0.21941472589969635\n",
      "Epoch 2056, loss: 0.590735912322998, grad norm: 0.21939651668071747\n",
      "Epoch 2057, loss: 0.5907042026519775, grad norm: 0.2195865511894226\n",
      "Epoch 2058, loss: 0.5906733870506287, grad norm: 0.2196369469165802\n",
      "Epoch 2059, loss: 0.5906425714492798, grad norm: 0.2195838838815689\n",
      "Epoch 2060, loss: 0.590609073638916, grad norm: 0.21968896687030792\n",
      "Epoch 2061, loss: 0.5905779600143433, grad norm: 0.2197691947221756\n",
      "Epoch 2062, loss: 0.5905466079711914, grad norm: 0.21984925866127014\n",
      "Epoch 2063, loss: 0.5905153155326843, grad norm: 0.21980002522468567\n",
      "Epoch 2064, loss: 0.5904828906059265, grad norm: 0.21989189088344574\n",
      "Epoch 2065, loss: 0.5904513597488403, grad norm: 0.2198803573846817\n",
      "Epoch 2066, loss: 0.5904186964035034, grad norm: 0.21998794376850128\n",
      "Epoch 2067, loss: 0.5903859734535217, grad norm: 0.21997275948524475\n",
      "Epoch 2068, loss: 0.5903531908988953, grad norm: 0.2199467271566391\n",
      "Epoch 2069, loss: 0.5903211832046509, grad norm: 0.2199769914150238\n",
      "Epoch 2070, loss: 0.5902898907661438, grad norm: 0.2200474888086319\n",
      "Epoch 2071, loss: 0.5902597904205322, grad norm: 0.21996745467185974\n",
      "Epoch 2072, loss: 0.5902261137962341, grad norm: 0.21988527476787567\n",
      "Epoch 2073, loss: 0.5901938080787659, grad norm: 0.2200988084077835\n",
      "Epoch 2074, loss: 0.590162992477417, grad norm: 0.21999208629131317\n",
      "Epoch 2075, loss: 0.5901288986206055, grad norm: 0.22003275156021118\n",
      "Epoch 2076, loss: 0.5900974273681641, grad norm: 0.2198750078678131\n",
      "Epoch 2077, loss: 0.5900655388832092, grad norm: 0.21985936164855957\n",
      "Epoch 2078, loss: 0.5900323987007141, grad norm: 0.2198648601770401\n",
      "Epoch 2079, loss: 0.5900006294250488, grad norm: 0.21968786418437958\n",
      "Epoch 2080, loss: 0.5899677276611328, grad norm: 0.21990825235843658\n",
      "Epoch 2081, loss: 0.5899374485015869, grad norm: 0.2197365164756775\n",
      "Epoch 2082, loss: 0.589903712272644, grad norm: 0.21984153985977173\n",
      "Epoch 2083, loss: 0.5898726582527161, grad norm: 0.2197592705488205\n",
      "Epoch 2084, loss: 0.589840292930603, grad norm: 0.21988290548324585\n",
      "Epoch 2085, loss: 0.5898089408874512, grad norm: 0.2197379320859909\n",
      "Epoch 2086, loss: 0.5897765159606934, grad norm: 0.2197209894657135\n",
      "Epoch 2087, loss: 0.5897442102432251, grad norm: 0.2197246104478836\n",
      "Epoch 2088, loss: 0.5897118449211121, grad norm: 0.2196110337972641\n",
      "Epoch 2089, loss: 0.5896793603897095, grad norm: 0.21947596967220306\n",
      "Epoch 2090, loss: 0.5896466970443726, grad norm: 0.21941480040550232\n",
      "Epoch 2091, loss: 0.589616060256958, grad norm: 0.21939030289649963\n",
      "Epoch 2092, loss: 0.5895845890045166, grad norm: 0.2191748321056366\n",
      "Epoch 2093, loss: 0.5895514488220215, grad norm: 0.21919849514961243\n",
      "Epoch 2094, loss: 0.5895187258720398, grad norm: 0.21915796399116516\n",
      "Epoch 2095, loss: 0.5894870758056641, grad norm: 0.2189933806657791\n",
      "Epoch 2096, loss: 0.5894555449485779, grad norm: 0.21879160404205322\n",
      "Epoch 2097, loss: 0.5894230008125305, grad norm: 0.2187783122062683\n",
      "Epoch 2098, loss: 0.5893906354904175, grad norm: 0.218655526638031\n",
      "Epoch 2099, loss: 0.5893588662147522, grad norm: 0.21875882148742676\n",
      "Epoch 2100, loss: 0.5893288254737854, grad norm: 0.2184663861989975\n",
      "Epoch 2101, loss: 0.5892947316169739, grad norm: 0.21848271787166595\n",
      "Epoch 2102, loss: 0.5892630219459534, grad norm: 0.21833448112010956\n",
      "Epoch 2103, loss: 0.5892313718795776, grad norm: 0.21819153428077698\n",
      "Epoch 2104, loss: 0.5891991257667542, grad norm: 0.217976376414299\n",
      "Epoch 2105, loss: 0.5891673564910889, grad norm: 0.21781228482723236\n",
      "Epoch 2106, loss: 0.5891348123550415, grad norm: 0.21773219108581543\n",
      "Epoch 2107, loss: 0.5891048312187195, grad norm: 0.2176884412765503\n",
      "Epoch 2108, loss: 0.5890719294548035, grad norm: 0.21769081056118011\n",
      "Epoch 2109, loss: 0.5890412330627441, grad norm: 0.21735504269599915\n",
      "Epoch 2110, loss: 0.5890071988105774, grad norm: 0.21728545427322388\n",
      "Epoch 2111, loss: 0.5889774560928345, grad norm: 0.21710772812366486\n",
      "Epoch 2112, loss: 0.5889458656311035, grad norm: 0.2169511467218399\n",
      "Epoch 2113, loss: 0.5889136791229248, grad norm: 0.21685171127319336\n",
      "Epoch 2114, loss: 0.5888808965682983, grad norm: 0.21652446687221527\n",
      "Epoch 2115, loss: 0.5888503789901733, grad norm: 0.21655845642089844\n",
      "Epoch 2116, loss: 0.5888186693191528, grad norm: 0.21635085344314575\n",
      "Epoch 2117, loss: 0.5887892842292786, grad norm: 0.21629996597766876\n",
      "Epoch 2118, loss: 0.5887563228607178, grad norm: 0.21600215137004852\n",
      "Epoch 2119, loss: 0.5887243151664734, grad norm: 0.21587254106998444\n",
      "Epoch 2120, loss: 0.5886930823326111, grad norm: 0.2156318873167038\n",
      "Epoch 2121, loss: 0.5886626243591309, grad norm: 0.21545356512069702\n",
      "Epoch 2122, loss: 0.5886318683624268, grad norm: 0.2152353823184967\n",
      "Epoch 2123, loss: 0.588600754737854, grad norm: 0.21503062546253204\n",
      "Epoch 2124, loss: 0.5885693430900574, grad norm: 0.21478527784347534\n",
      "Epoch 2125, loss: 0.5885379314422607, grad norm: 0.21471215784549713\n",
      "Epoch 2126, loss: 0.5885080099105835, grad norm: 0.2144324630498886\n",
      "Epoch 2127, loss: 0.5884756445884705, grad norm: 0.21427570283412933\n",
      "Epoch 2128, loss: 0.5884442329406738, grad norm: 0.21404176950454712\n",
      "Epoch 2129, loss: 0.5884140729904175, grad norm: 0.21378585696220398\n",
      "Epoch 2130, loss: 0.5883825421333313, grad norm: 0.2134673148393631\n",
      "Epoch 2131, loss: 0.5883510112762451, grad norm: 0.2133634239435196\n",
      "Epoch 2132, loss: 0.5883201956748962, grad norm: 0.21328455209732056\n",
      "Epoch 2133, loss: 0.5882909297943115, grad norm: 0.21293745934963226\n",
      "Epoch 2134, loss: 0.5882613658905029, grad norm: 0.21257279813289642\n",
      "Epoch 2135, loss: 0.5882290601730347, grad norm: 0.21232865750789642\n",
      "Epoch 2136, loss: 0.5881994962692261, grad norm: 0.21219268441200256\n",
      "Epoch 2137, loss: 0.5881696939468384, grad norm: 0.21177203953266144\n",
      "Epoch 2138, loss: 0.5881379246711731, grad norm: 0.21166853606700897\n",
      "Epoch 2139, loss: 0.5881074666976929, grad norm: 0.21128466725349426\n",
      "Epoch 2140, loss: 0.5880776643753052, grad norm: 0.2111462503671646\n",
      "Epoch 2141, loss: 0.5880476832389832, grad norm: 0.210863396525383\n",
      "Epoch 2142, loss: 0.5880187749862671, grad norm: 0.21074165403842926\n",
      "Epoch 2143, loss: 0.5879877209663391, grad norm: 0.21049533784389496\n",
      "Epoch 2144, loss: 0.587958037853241, grad norm: 0.21021148562431335\n",
      "Epoch 2145, loss: 0.5879285335540771, grad norm: 0.20994168519973755\n",
      "Epoch 2146, loss: 0.5878986120223999, grad norm: 0.20964683592319489\n",
      "Epoch 2147, loss: 0.5878680944442749, grad norm: 0.20936799049377441\n",
      "Epoch 2148, loss: 0.5878382921218872, grad norm: 0.20895875990390778\n",
      "Epoch 2149, loss: 0.5878074169158936, grad norm: 0.20891760289669037\n",
      "Epoch 2150, loss: 0.5877790451049805, grad norm: 0.20857621729373932\n",
      "Epoch 2151, loss: 0.5877499580383301, grad norm: 0.20805001258850098\n",
      "Epoch 2152, loss: 0.5877202153205872, grad norm: 0.20785705745220184\n",
      "Epoch 2153, loss: 0.5876923203468323, grad norm: 0.207548126578331\n",
      "Epoch 2154, loss: 0.5876622796058655, grad norm: 0.2071262151002884\n",
      "Epoch 2155, loss: 0.5876325368881226, grad norm: 0.20687250792980194\n",
      "Epoch 2156, loss: 0.5876042246818542, grad norm: 0.20655423402786255\n",
      "Epoch 2157, loss: 0.5875746607780457, grad norm: 0.2062223255634308\n",
      "Epoch 2158, loss: 0.5875459909439087, grad norm: 0.2058870494365692\n",
      "Epoch 2159, loss: 0.5875159502029419, grad norm: 0.20571421086788177\n",
      "Epoch 2160, loss: 0.5874888896942139, grad norm: 0.2052013874053955\n",
      "Epoch 2161, loss: 0.5874601602554321, grad norm: 0.20490507781505585\n",
      "Epoch 2162, loss: 0.5874296426773071, grad norm: 0.20472446084022522\n",
      "Epoch 2163, loss: 0.5874044895172119, grad norm: 0.20420345664024353\n",
      "Epoch 2164, loss: 0.5873736143112183, grad norm: 0.20398685336112976\n",
      "Epoch 2165, loss: 0.587346076965332, grad norm: 0.20379427075386047\n",
      "Epoch 2166, loss: 0.587317943572998, grad norm: 0.2033403217792511\n",
      "Epoch 2167, loss: 0.5872898101806641, grad norm: 0.20307022333145142\n",
      "Epoch 2168, loss: 0.5872617959976196, grad norm: 0.2027004212141037\n",
      "Epoch 2169, loss: 0.5872337222099304, grad norm: 0.20230504870414734\n",
      "Epoch 2170, loss: 0.5872046947479248, grad norm: 0.20188280940055847\n",
      "Epoch 2171, loss: 0.5871784687042236, grad norm: 0.20143814384937286\n",
      "Epoch 2172, loss: 0.5871495604515076, grad norm: 0.20116613805294037\n",
      "Epoch 2173, loss: 0.5871235132217407, grad norm: 0.20079359412193298\n",
      "Epoch 2174, loss: 0.5870946645736694, grad norm: 0.2003450095653534\n",
      "Epoch 2175, loss: 0.5870668292045593, grad norm: 0.20005273818969727\n",
      "Epoch 2176, loss: 0.5870398879051208, grad norm: 0.19971515238285065\n",
      "Epoch 2177, loss: 0.587012529373169, grad norm: 0.19942499697208405\n",
      "Epoch 2178, loss: 0.5869846940040588, grad norm: 0.19890406727790833\n",
      "Epoch 2179, loss: 0.5869583487510681, grad norm: 0.19856613874435425\n",
      "Epoch 2180, loss: 0.5869320631027222, grad norm: 0.1982477605342865\n",
      "Epoch 2181, loss: 0.5869059562683105, grad norm: 0.19789600372314453\n",
      "Epoch 2182, loss: 0.5868784785270691, grad norm: 0.19739167392253876\n",
      "Epoch 2183, loss: 0.5868504643440247, grad norm: 0.1970779150724411\n",
      "Epoch 2184, loss: 0.5868244171142578, grad norm: 0.1964883953332901\n",
      "Epoch 2185, loss: 0.5867982506752014, grad norm: 0.19608210027217865\n",
      "Epoch 2186, loss: 0.5867722034454346, grad norm: 0.1957748979330063\n",
      "Epoch 2187, loss: 0.5867459177970886, grad norm: 0.1954110860824585\n",
      "Epoch 2188, loss: 0.5867201089859009, grad norm: 0.19497805833816528\n",
      "Epoch 2189, loss: 0.5866941213607788, grad norm: 0.1944415271282196\n",
      "Epoch 2190, loss: 0.5866669416427612, grad norm: 0.19422727823257446\n",
      "Epoch 2191, loss: 0.5866423845291138, grad norm: 0.19390861690044403\n",
      "Epoch 2192, loss: 0.5866165161132812, grad norm: 0.19357071816921234\n",
      "Epoch 2193, loss: 0.5865910053253174, grad norm: 0.1930566430091858\n",
      "Epoch 2194, loss: 0.586564302444458, grad norm: 0.1926194429397583\n",
      "Epoch 2195, loss: 0.5865396857261658, grad norm: 0.19218996167182922\n",
      "Epoch 2196, loss: 0.5865151286125183, grad norm: 0.19175046682357788\n",
      "Epoch 2197, loss: 0.5864893198013306, grad norm: 0.19123469293117523\n",
      "Epoch 2198, loss: 0.5864638686180115, grad norm: 0.19086094200611115\n",
      "Epoch 2199, loss: 0.5864399671554565, grad norm: 0.1904137134552002\n",
      "Epoch 2200, loss: 0.586414098739624, grad norm: 0.1900404393672943\n",
      "Epoch 2201, loss: 0.5863903760910034, grad norm: 0.18941114842891693\n",
      "Epoch 2202, loss: 0.5863638520240784, grad norm: 0.18897467851638794\n",
      "Epoch 2203, loss: 0.5863394737243652, grad norm: 0.18859337270259857\n",
      "Epoch 2204, loss: 0.5863163471221924, grad norm: 0.18815085291862488\n",
      "Epoch 2205, loss: 0.5862906575202942, grad norm: 0.18774192035198212\n",
      "Epoch 2206, loss: 0.58626788854599, grad norm: 0.18731819093227386\n",
      "Epoch 2207, loss: 0.5862435698509216, grad norm: 0.18684788048267365\n",
      "Epoch 2208, loss: 0.5862189531326294, grad norm: 0.1864272505044937\n",
      "Epoch 2209, loss: 0.5861955881118774, grad norm: 0.18596312403678894\n",
      "Epoch 2210, loss: 0.586171567440033, grad norm: 0.18553301692008972\n",
      "Epoch 2211, loss: 0.5861479043960571, grad norm: 0.1851690113544464\n",
      "Epoch 2212, loss: 0.5861243605613708, grad norm: 0.1846848428249359\n",
      "Epoch 2213, loss: 0.5861005783081055, grad norm: 0.18426287174224854\n",
      "Epoch 2214, loss: 0.5860764980316162, grad norm: 0.1838230937719345\n",
      "Epoch 2215, loss: 0.5860545635223389, grad norm: 0.18330051004886627\n",
      "Epoch 2216, loss: 0.5860313773155212, grad norm: 0.18278546631336212\n",
      "Epoch 2217, loss: 0.5860081315040588, grad norm: 0.18235324323177338\n",
      "Epoch 2218, loss: 0.5859847664833069, grad norm: 0.18188396096229553\n",
      "Epoch 2219, loss: 0.58596271276474, grad norm: 0.18144726753234863\n",
      "Epoch 2220, loss: 0.5859405994415283, grad norm: 0.1809481978416443\n",
      "Epoch 2221, loss: 0.5859166979789734, grad norm: 0.18049544095993042\n",
      "Epoch 2222, loss: 0.585893988609314, grad norm: 0.18004503846168518\n",
      "Epoch 2223, loss: 0.5858718156814575, grad norm: 0.17946985363960266\n",
      "Epoch 2224, loss: 0.585849940776825, grad norm: 0.17882142961025238\n",
      "Epoch 2225, loss: 0.5858263969421387, grad norm: 0.17849101126194\n",
      "Epoch 2226, loss: 0.5858057141304016, grad norm: 0.1779058426618576\n",
      "Epoch 2227, loss: 0.5857827067375183, grad norm: 0.17750732600688934\n",
      "Epoch 2228, loss: 0.5857623219490051, grad norm: 0.17712178826332092\n",
      "Epoch 2229, loss: 0.5857403874397278, grad norm: 0.17659185826778412\n",
      "Epoch 2230, loss: 0.5857188701629639, grad norm: 0.17624975740909576\n",
      "Epoch 2231, loss: 0.585698127746582, grad norm: 0.17573699355125427\n",
      "Epoch 2232, loss: 0.5856766104698181, grad norm: 0.1752326786518097\n",
      "Epoch 2233, loss: 0.5856552124023438, grad norm: 0.17486165463924408\n",
      "Epoch 2234, loss: 0.5856340527534485, grad norm: 0.174301877617836\n",
      "Epoch 2235, loss: 0.5856128931045532, grad norm: 0.1738336980342865\n",
      "Epoch 2236, loss: 0.5855921506881714, grad norm: 0.173354372382164\n",
      "Epoch 2237, loss: 0.5855703353881836, grad norm: 0.17293241620063782\n",
      "Epoch 2238, loss: 0.5855512022972107, grad norm: 0.17227335274219513\n",
      "Epoch 2239, loss: 0.585529625415802, grad norm: 0.17184433341026306\n",
      "Epoch 2240, loss: 0.5855105519294739, grad norm: 0.17118529975414276\n",
      "Epoch 2241, loss: 0.5854882597923279, grad norm: 0.17072781920433044\n",
      "Epoch 2242, loss: 0.5854695439338684, grad norm: 0.17025226354599\n",
      "Epoch 2243, loss: 0.5854493379592896, grad norm: 0.1697039157152176\n",
      "Epoch 2244, loss: 0.5854288935661316, grad norm: 0.16924670338630676\n",
      "Epoch 2245, loss: 0.5854092836380005, grad norm: 0.1686476469039917\n",
      "Epoch 2246, loss: 0.5853891372680664, grad norm: 0.16819603741168976\n",
      "Epoch 2247, loss: 0.585370659828186, grad norm: 0.16774190962314606\n",
      "Epoch 2248, loss: 0.5853496789932251, grad norm: 0.1672828495502472\n",
      "Epoch 2249, loss: 0.5853312611579895, grad norm: 0.16681143641471863\n",
      "Epoch 2250, loss: 0.5853111743927002, grad norm: 0.16624216735363007\n",
      "Epoch 2251, loss: 0.5852923393249512, grad norm: 0.16573689877986908\n",
      "Epoch 2252, loss: 0.585272490978241, grad norm: 0.1653447449207306\n",
      "Epoch 2253, loss: 0.5852542519569397, grad norm: 0.1648244559764862\n",
      "Epoch 2254, loss: 0.5852354764938354, grad norm: 0.16426515579223633\n",
      "Epoch 2255, loss: 0.5852166414260864, grad norm: 0.16386151313781738\n",
      "Epoch 2256, loss: 0.585198163986206, grad norm: 0.1632087677717209\n",
      "Epoch 2257, loss: 0.585179328918457, grad norm: 0.16283512115478516\n",
      "Epoch 2258, loss: 0.585160493850708, grad norm: 0.16225729882717133\n",
      "Epoch 2259, loss: 0.5851423144340515, grad norm: 0.16176429390907288\n",
      "Epoch 2260, loss: 0.5851249098777771, grad norm: 0.16125048696994781\n",
      "Epoch 2261, loss: 0.5851049423217773, grad norm: 0.16070252656936646\n",
      "Epoch 2262, loss: 0.5850886702537537, grad norm: 0.16018269956111908\n",
      "Epoch 2263, loss: 0.5850701928138733, grad norm: 0.15958431363105774\n",
      "Epoch 2264, loss: 0.5850517749786377, grad norm: 0.15911298990249634\n",
      "Epoch 2265, loss: 0.5850350856781006, grad norm: 0.15861113369464874\n",
      "Epoch 2266, loss: 0.5850178003311157, grad norm: 0.15806658565998077\n",
      "Epoch 2267, loss: 0.5849997997283936, grad norm: 0.15786674618721008\n",
      "Epoch 2268, loss: 0.5849834680557251, grad norm: 0.15713800489902496\n",
      "Epoch 2269, loss: 0.5849657654762268, grad norm: 0.15660665929317474\n",
      "Epoch 2270, loss: 0.5849480628967285, grad norm: 0.1560772955417633\n",
      "Epoch 2271, loss: 0.5849314332008362, grad norm: 0.15561328828334808\n",
      "Epoch 2272, loss: 0.5849140882492065, grad norm: 0.15507793426513672\n",
      "Epoch 2273, loss: 0.5848967432975769, grad norm: 0.15458856523036957\n",
      "Epoch 2274, loss: 0.5848816633224487, grad norm: 0.1540394425392151\n",
      "Epoch 2275, loss: 0.5848644375801086, grad norm: 0.1534726470708847\n",
      "Epoch 2276, loss: 0.5848475694656372, grad norm: 0.1530955731868744\n",
      "Epoch 2277, loss: 0.5848314762115479, grad norm: 0.15257731080055237\n",
      "Epoch 2278, loss: 0.5848153233528137, grad norm: 0.15207049250602722\n",
      "Epoch 2279, loss: 0.5847997665405273, grad norm: 0.15151813626289368\n",
      "Epoch 2280, loss: 0.584783673286438, grad norm: 0.15101835131645203\n",
      "Epoch 2281, loss: 0.5847681760787964, grad norm: 0.15054063498973846\n",
      "Epoch 2282, loss: 0.584750771522522, grad norm: 0.15000230073928833\n",
      "Epoch 2283, loss: 0.5847353935241699, grad norm: 0.14948150515556335\n",
      "Epoch 2284, loss: 0.5847192406654358, grad norm: 0.14908543229103088\n",
      "Epoch 2285, loss: 0.5847040414810181, grad norm: 0.14849896728992462\n",
      "Epoch 2286, loss: 0.5846889019012451, grad norm: 0.14801502227783203\n",
      "Epoch 2287, loss: 0.5846736431121826, grad norm: 0.14752309024333954\n",
      "Epoch 2288, loss: 0.5846580862998962, grad norm: 0.14682334661483765\n",
      "Epoch 2289, loss: 0.5846434831619263, grad norm: 0.14645464718341827\n",
      "Epoch 2290, loss: 0.5846282243728638, grad norm: 0.1459040343761444\n",
      "Epoch 2291, loss: 0.5846130847930908, grad norm: 0.14523357152938843\n",
      "Epoch 2292, loss: 0.584598183631897, grad norm: 0.14479191601276398\n",
      "Epoch 2293, loss: 0.5845837593078613, grad norm: 0.14431317150592804\n",
      "Epoch 2294, loss: 0.5845686197280884, grad norm: 0.14374281466007233\n",
      "Epoch 2295, loss: 0.5845548510551453, grad norm: 0.14323870837688446\n",
      "Epoch 2296, loss: 0.584539532661438, grad norm: 0.14281515777111053\n",
      "Epoch 2297, loss: 0.5845259428024292, grad norm: 0.14222149550914764\n",
      "Epoch 2298, loss: 0.5845106840133667, grad norm: 0.1418752819299698\n",
      "Epoch 2299, loss: 0.5844976902008057, grad norm: 0.14130282402038574\n",
      "Epoch 2300, loss: 0.5844836235046387, grad norm: 0.14088110625743866\n",
      "Epoch 2301, loss: 0.5844696164131165, grad norm: 0.1404469758272171\n",
      "Epoch 2302, loss: 0.5844553709030151, grad norm: 0.13985858857631683\n",
      "Epoch 2303, loss: 0.5844416618347168, grad norm: 0.1393316090106964\n",
      "Epoch 2304, loss: 0.5844278335571289, grad norm: 0.13886654376983643\n",
      "Epoch 2305, loss: 0.5844143629074097, grad norm: 0.13826659321784973\n",
      "Epoch 2306, loss: 0.5843999981880188, grad norm: 0.13771304488182068\n",
      "Epoch 2307, loss: 0.584387481212616, grad norm: 0.1371997743844986\n",
      "Epoch 2308, loss: 0.5843734741210938, grad norm: 0.1367749720811844\n",
      "Epoch 2309, loss: 0.5843609571456909, grad norm: 0.13626228272914886\n",
      "Epoch 2310, loss: 0.5843476057052612, grad norm: 0.1356794685125351\n",
      "Epoch 2311, loss: 0.5843347311019897, grad norm: 0.13524159789085388\n",
      "Epoch 2312, loss: 0.5843232274055481, grad norm: 0.13482657074928284\n",
      "Epoch 2313, loss: 0.5843096375465393, grad norm: 0.13429516553878784\n",
      "Epoch 2314, loss: 0.5842970609664917, grad norm: 0.13374216854572296\n",
      "Epoch 2315, loss: 0.584284245967865, grad norm: 0.13319125771522522\n",
      "Epoch 2316, loss: 0.5842714905738831, grad norm: 0.13279949128627777\n",
      "Epoch 2317, loss: 0.5842593908309937, grad norm: 0.13226960599422455\n",
      "Epoch 2318, loss: 0.5842468738555908, grad norm: 0.13178829848766327\n",
      "Epoch 2319, loss: 0.5842345952987671, grad norm: 0.13114187121391296\n",
      "Epoch 2320, loss: 0.5842220783233643, grad norm: 0.13078832626342773\n",
      "Epoch 2321, loss: 0.584210991859436, grad norm: 0.1303701400756836\n",
      "Epoch 2322, loss: 0.584199070930481, grad norm: 0.12975448369979858\n",
      "Epoch 2323, loss: 0.5841864347457886, grad norm: 0.12935447692871094\n",
      "Epoch 2324, loss: 0.584174394607544, grad norm: 0.1288311928510666\n",
      "Epoch 2325, loss: 0.584162712097168, grad norm: 0.12836959958076477\n",
      "Epoch 2326, loss: 0.5841512680053711, grad norm: 0.12780822813510895\n",
      "Epoch 2327, loss: 0.5841391086578369, grad norm: 0.12736846506595612\n",
      "Epoch 2328, loss: 0.5841283798217773, grad norm: 0.12676343321800232\n",
      "Epoch 2329, loss: 0.5841164588928223, grad norm: 0.1263316422700882\n",
      "Epoch 2330, loss: 0.5841048955917358, grad norm: 0.1260206699371338\n",
      "Epoch 2331, loss: 0.5840948820114136, grad norm: 0.12530511617660522\n",
      "Epoch 2332, loss: 0.5840823650360107, grad norm: 0.12493080645799637\n",
      "Epoch 2333, loss: 0.5840720534324646, grad norm: 0.12436493486166\n",
      "Epoch 2334, loss: 0.5840609073638916, grad norm: 0.12385202944278717\n",
      "Epoch 2335, loss: 0.5840500593185425, grad norm: 0.12335191667079926\n",
      "Epoch 2336, loss: 0.5840388536453247, grad norm: 0.12295638769865036\n",
      "Epoch 2337, loss: 0.5840282440185547, grad norm: 0.12243884801864624\n",
      "Epoch 2338, loss: 0.5840173959732056, grad norm: 0.12187648564577103\n",
      "Epoch 2339, loss: 0.5840076804161072, grad norm: 0.12156523764133453\n",
      "Epoch 2340, loss: 0.5839968919754028, grad norm: 0.12108948081731796\n",
      "Epoch 2341, loss: 0.5839864611625671, grad norm: 0.12063942849636078\n",
      "Epoch 2342, loss: 0.5839764475822449, grad norm: 0.12019628286361694\n",
      "Epoch 2343, loss: 0.5839662551879883, grad norm: 0.11959311366081238\n",
      "Epoch 2344, loss: 0.5839563608169556, grad norm: 0.11908946931362152\n",
      "Epoch 2345, loss: 0.5839453339576721, grad norm: 0.1187666654586792\n",
      "Epoch 2346, loss: 0.5839357376098633, grad norm: 0.1182260662317276\n",
      "Epoch 2347, loss: 0.583925724029541, grad norm: 0.11772692203521729\n",
      "Epoch 2348, loss: 0.5839159488677979, grad norm: 0.11737796664237976\n",
      "Epoch 2349, loss: 0.5839062333106995, grad norm: 0.11681728810071945\n",
      "Epoch 2350, loss: 0.5838961601257324, grad norm: 0.11627984046936035\n",
      "Epoch 2351, loss: 0.583886444568634, grad norm: 0.11595984548330307\n",
      "Epoch 2352, loss: 0.5838770866394043, grad norm: 0.11542575061321259\n",
      "Epoch 2353, loss: 0.5838675498962402, grad norm: 0.11486544460058212\n",
      "Epoch 2354, loss: 0.583858072757721, grad norm: 0.1144551932811737\n",
      "Epoch 2355, loss: 0.5838489532470703, grad norm: 0.11398512125015259\n",
      "Epoch 2356, loss: 0.5838392972946167, grad norm: 0.11353393644094467\n",
      "Epoch 2357, loss: 0.5838301181793213, grad norm: 0.11293444782495499\n",
      "Epoch 2358, loss: 0.5838209986686707, grad norm: 0.11261126399040222\n",
      "Epoch 2359, loss: 0.5838131904602051, grad norm: 0.11208915710449219\n",
      "Epoch 2360, loss: 0.5838035345077515, grad norm: 0.11160127073526382\n",
      "Epoch 2361, loss: 0.583794116973877, grad norm: 0.11118851602077484\n",
      "Epoch 2362, loss: 0.5837857723236084, grad norm: 0.11080215126276016\n",
      "Epoch 2363, loss: 0.5837768316268921, grad norm: 0.1103251501917839\n",
      "Epoch 2364, loss: 0.5837680101394653, grad norm: 0.10993392020463943\n",
      "Epoch 2365, loss: 0.5837594270706177, grad norm: 0.10952142626047134\n",
      "Epoch 2366, loss: 0.5837507247924805, grad norm: 0.1089567244052887\n",
      "Epoch 2367, loss: 0.5837416052818298, grad norm: 0.10855025053024292\n",
      "Epoch 2368, loss: 0.5837336778640747, grad norm: 0.10807569324970245\n",
      "Epoch 2369, loss: 0.583725094795227, grad norm: 0.10761123895645142\n",
      "Epoch 2370, loss: 0.5837172269821167, grad norm: 0.10722877085208893\n",
      "Epoch 2371, loss: 0.5837084054946899, grad norm: 0.10676860809326172\n",
      "Epoch 2372, loss: 0.5837010145187378, grad norm: 0.10616131871938705\n",
      "Epoch 2373, loss: 0.583692193031311, grad norm: 0.10570292919874191\n",
      "Epoch 2374, loss: 0.583683967590332, grad norm: 0.10541989654302597\n",
      "Epoch 2375, loss: 0.5836766362190247, grad norm: 0.10487284511327744\n",
      "Epoch 2376, loss: 0.5836687088012695, grad norm: 0.10452983528375626\n",
      "Epoch 2377, loss: 0.5836602449417114, grad norm: 0.10411012172698975\n",
      "Epoch 2378, loss: 0.5836530923843384, grad norm: 0.10369314253330231\n",
      "Epoch 2379, loss: 0.5836452841758728, grad norm: 0.10326936841011047\n",
      "Epoch 2380, loss: 0.5836373567581177, grad norm: 0.10283933579921722\n",
      "Epoch 2381, loss: 0.5836297273635864, grad norm: 0.10240606963634491\n",
      "Epoch 2382, loss: 0.5836225152015686, grad norm: 0.10213462263345718\n",
      "Epoch 2383, loss: 0.5836151838302612, grad norm: 0.10150612145662308\n",
      "Epoch 2384, loss: 0.5836071372032166, grad norm: 0.10102101415395737\n",
      "Epoch 2385, loss: 0.5835993885993958, grad norm: 0.10058553516864777\n",
      "Epoch 2386, loss: 0.5835925340652466, grad norm: 0.10018369555473328\n",
      "Epoch 2387, loss: 0.5835853219032288, grad norm: 0.09971804916858673\n",
      "Epoch 2388, loss: 0.5835784673690796, grad norm: 0.09930707514286041\n",
      "Epoch 2389, loss: 0.583571195602417, grad norm: 0.09888166189193726\n",
      "Epoch 2390, loss: 0.5835638642311096, grad norm: 0.09842848777770996\n",
      "Epoch 2391, loss: 0.5835566520690918, grad norm: 0.09800782799720764\n",
      "Epoch 2392, loss: 0.5835495591163635, grad norm: 0.09755608439445496\n",
      "Epoch 2393, loss: 0.5835429430007935, grad norm: 0.09730978310108185\n",
      "Epoch 2394, loss: 0.5835365056991577, grad norm: 0.09686486423015594\n",
      "Epoch 2395, loss: 0.5835298299789429, grad norm: 0.09651408344507217\n",
      "Epoch 2396, loss: 0.583523154258728, grad norm: 0.09600101411342621\n",
      "Epoch 2397, loss: 0.5835160613059998, grad norm: 0.0956665426492691\n",
      "Epoch 2398, loss: 0.5835096836090088, grad norm: 0.09510932117700577\n",
      "Epoch 2399, loss: 0.5835026502609253, grad norm: 0.09490662068128586\n",
      "Epoch 2400, loss: 0.5834963917732239, grad norm: 0.0943564772605896\n",
      "Epoch 2401, loss: 0.5834894776344299, grad norm: 0.09398552775382996\n",
      "Epoch 2402, loss: 0.5834835171699524, grad norm: 0.093678779900074\n",
      "Epoch 2403, loss: 0.5834771394729614, grad norm: 0.09314122051000595\n",
      "Epoch 2404, loss: 0.5834707021713257, grad norm: 0.09278156608343124\n",
      "Epoch 2405, loss: 0.5834647417068481, grad norm: 0.09227468818426132\n",
      "Epoch 2406, loss: 0.5834580659866333, grad norm: 0.09198343753814697\n",
      "Epoch 2407, loss: 0.583452582359314, grad norm: 0.09157662093639374\n",
      "Epoch 2408, loss: 0.5834461450576782, grad norm: 0.09121306240558624\n",
      "Epoch 2409, loss: 0.5834400057792664, grad norm: 0.09072958678007126\n",
      "Epoch 2410, loss: 0.5834342241287231, grad norm: 0.09038934856653214\n",
      "Epoch 2411, loss: 0.5834283828735352, grad norm: 0.08999525010585785\n",
      "Epoch 2412, loss: 0.5834220051765442, grad norm: 0.0895586833357811\n",
      "Epoch 2413, loss: 0.5834162831306458, grad norm: 0.08922651410102844\n",
      "Epoch 2414, loss: 0.5834106802940369, grad norm: 0.08882783353328705\n",
      "Epoch 2415, loss: 0.583405077457428, grad norm: 0.08835498243570328\n",
      "Epoch 2416, loss: 0.5833988189697266, grad norm: 0.08799900859594345\n",
      "Epoch 2417, loss: 0.5833941698074341, grad norm: 0.0875009149312973\n",
      "Epoch 2418, loss: 0.5833879113197327, grad norm: 0.0872640311717987\n",
      "Epoch 2419, loss: 0.5833824276924133, grad norm: 0.0868266224861145\n",
      "Epoch 2420, loss: 0.5833773016929626, grad norm: 0.08644656836986542\n",
      "Epoch 2421, loss: 0.5833717584609985, grad norm: 0.08605314046144485\n",
      "Epoch 2422, loss: 0.5833658576011658, grad norm: 0.08571410179138184\n",
      "Epoch 2423, loss: 0.5833601951599121, grad norm: 0.08540422469377518\n",
      "Epoch 2424, loss: 0.5833557844161987, grad norm: 0.08498844504356384\n",
      "Epoch 2425, loss: 0.5833502411842346, grad norm: 0.08463066816329956\n",
      "Epoch 2426, loss: 0.5833449363708496, grad norm: 0.08413480222225189\n",
      "Epoch 2427, loss: 0.583340048789978, grad norm: 0.08396853506565094\n",
      "Epoch 2428, loss: 0.5833351612091064, grad norm: 0.08349696546792984\n",
      "Epoch 2429, loss: 0.583329439163208, grad norm: 0.08308782428503036\n",
      "Epoch 2430, loss: 0.5833244919776917, grad norm: 0.08268104493618011\n",
      "Epoch 2431, loss: 0.5833188891410828, grad norm: 0.08225447684526443\n",
      "Epoch 2432, loss: 0.5833140015602112, grad norm: 0.08202188462018967\n",
      "Epoch 2433, loss: 0.5833095908164978, grad norm: 0.08163413405418396\n",
      "Epoch 2434, loss: 0.5833041071891785, grad norm: 0.08130083978176117\n",
      "Epoch 2435, loss: 0.5832998752593994, grad norm: 0.08089695870876312\n",
      "Epoch 2436, loss: 0.5832948684692383, grad norm: 0.08055315166711807\n",
      "Epoch 2437, loss: 0.5832900404930115, grad norm: 0.08016888797283173\n",
      "Epoch 2438, loss: 0.5832855701446533, grad norm: 0.0797809511423111\n",
      "Epoch 2439, loss: 0.5832801461219788, grad norm: 0.07952413707971573\n",
      "Epoch 2440, loss: 0.583276093006134, grad norm: 0.07917222380638123\n",
      "Epoch 2441, loss: 0.5832716822624207, grad norm: 0.07878599315881729\n",
      "Epoch 2442, loss: 0.5832664966583252, grad norm: 0.078301340341568\n",
      "Epoch 2443, loss: 0.5832622051239014, grad norm: 0.07803671807050705\n",
      "Epoch 2444, loss: 0.5832581520080566, grad norm: 0.07776308804750443\n",
      "Epoch 2445, loss: 0.5832537412643433, grad norm: 0.07748347520828247\n",
      "Epoch 2446, loss: 0.5832495093345642, grad norm: 0.07694854587316513\n",
      "Epoch 2447, loss: 0.5832444429397583, grad norm: 0.07663286477327347\n",
      "Epoch 2448, loss: 0.5832402110099792, grad norm: 0.07625950127840042\n",
      "Epoch 2449, loss: 0.5832363367080688, grad norm: 0.0759056806564331\n",
      "Epoch 2450, loss: 0.5832319259643555, grad norm: 0.07561809569597244\n",
      "Epoch 2451, loss: 0.5832272171974182, grad norm: 0.07521089911460876\n",
      "Epoch 2452, loss: 0.5832231044769287, grad norm: 0.07491450011730194\n",
      "Epoch 2453, loss: 0.583219051361084, grad norm: 0.07461998611688614\n",
      "Epoch 2454, loss: 0.5832149982452393, grad norm: 0.07424131035804749\n",
      "Epoch 2455, loss: 0.5832110047340393, grad norm: 0.07388544827699661\n",
      "Epoch 2456, loss: 0.5832070112228394, grad norm: 0.07366620749235153\n",
      "Epoch 2457, loss: 0.5832031965255737, grad norm: 0.07326249033212662\n",
      "Epoch 2458, loss: 0.5831983685493469, grad norm: 0.07291267812252045\n",
      "Epoch 2459, loss: 0.5831947326660156, grad norm: 0.0726286843419075\n",
      "Epoch 2460, loss: 0.5831908583641052, grad norm: 0.07229668647050858\n",
      "Epoch 2461, loss: 0.5831872224807739, grad norm: 0.07186280936002731\n",
      "Epoch 2462, loss: 0.5831830501556396, grad norm: 0.07156088203191757\n",
      "Epoch 2463, loss: 0.5831793546676636, grad norm: 0.0712304413318634\n",
      "Epoch 2464, loss: 0.5831754803657532, grad norm: 0.07087366282939911\n",
      "Epoch 2465, loss: 0.5831711888313293, grad norm: 0.07059347629547119\n",
      "Epoch 2466, loss: 0.5831679701805115, grad norm: 0.07034023106098175\n",
      "Epoch 2467, loss: 0.5831648111343384, grad norm: 0.07007477432489395\n",
      "Epoch 2468, loss: 0.583161473274231, grad norm: 0.06971324980258942\n",
      "Epoch 2469, loss: 0.583157479763031, grad norm: 0.06938763707876205\n",
      "Epoch 2470, loss: 0.583153486251831, grad norm: 0.06894664466381073\n",
      "Epoch 2471, loss: 0.5831506252288818, grad norm: 0.06855403631925583\n",
      "Epoch 2472, loss: 0.5831468105316162, grad norm: 0.06827101111412048\n",
      "Epoch 2473, loss: 0.5831426382064819, grad norm: 0.06799330562353134\n",
      "Epoch 2474, loss: 0.583139181137085, grad norm: 0.06767333298921585\n",
      "Epoch 2475, loss: 0.5831363201141357, grad norm: 0.06745274364948273\n",
      "Epoch 2476, loss: 0.5831329822540283, grad norm: 0.06716574728488922\n",
      "Epoch 2477, loss: 0.5831296443939209, grad norm: 0.06681996583938599\n",
      "Epoch 2478, loss: 0.5831255912780762, grad norm: 0.06660611182451248\n",
      "Epoch 2479, loss: 0.583122730255127, grad norm: 0.06625114381313324\n",
      "Epoch 2480, loss: 0.5831193327903748, grad norm: 0.06589113175868988\n",
      "Epoch 2481, loss: 0.5831159353256226, grad norm: 0.0657033622264862\n",
      "Epoch 2482, loss: 0.5831129550933838, grad norm: 0.0652482733130455\n",
      "Epoch 2483, loss: 0.5831096768379211, grad norm: 0.06499945372343063\n",
      "Epoch 2484, loss: 0.5831068754196167, grad norm: 0.06468386948108673\n",
      "Epoch 2485, loss: 0.5831036567687988, grad norm: 0.06439204514026642\n",
      "Epoch 2486, loss: 0.583100438117981, grad norm: 0.06413190811872482\n",
      "Epoch 2487, loss: 0.5830971598625183, grad norm: 0.06378734856843948\n",
      "Epoch 2488, loss: 0.5830941200256348, grad norm: 0.06351251900196075\n",
      "Epoch 2489, loss: 0.583091676235199, grad norm: 0.06312867999076843\n",
      "Epoch 2490, loss: 0.583087682723999, grad norm: 0.06298389285802841\n",
      "Epoch 2491, loss: 0.583085298538208, grad norm: 0.06253338605165482\n",
      "Epoch 2492, loss: 0.5830824971199036, grad norm: 0.06231844425201416\n",
      "Epoch 2493, loss: 0.58307945728302, grad norm: 0.062096673995256424\n",
      "Epoch 2494, loss: 0.583076536655426, grad norm: 0.061666399240493774\n",
      "Epoch 2495, loss: 0.5830733776092529, grad norm: 0.061540134251117706\n",
      "Epoch 2496, loss: 0.5830703377723694, grad norm: 0.061142049729824066\n",
      "Epoch 2497, loss: 0.5830682516098022, grad norm: 0.06085415557026863\n",
      "Epoch 2498, loss: 0.5830650329589844, grad norm: 0.060586828738451004\n",
      "Epoch 2499, loss: 0.5830624103546143, grad norm: 0.06037132814526558\n"
     ]
    }
   ],
   "source": [
    "epochs = 2500\n",
    "\n",
    "for epoch in trange(epochs):\n",
    "    loss, xor_gate, and_gate, opt_state = make_step(\n",
    "        xor_gate,\n",
    "        and_gate,\n",
    "        X,\n",
    "        y_sum,\n",
    "        y_carry,\n",
    "        optim,\n",
    "        opt_state,  # type: ignore\n",
    "    )\n",
    "    _, grads = compute_sum_loss(xor_gate, X, y_sum)\n",
    "    grad_norm_value = grad_norm(grads)\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"Epoch {epoch}, loss: {loss}, grad norm: {grad_norm_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Trained XOR Gate Parameters:\n",
      "DELTA: 0.4204155206680298, X0: 1.1994107961654663, X_THRESHOLD: -0.2726741135120392\n",
      "\n",
      "Trained AND Gate Parameters:\n",
      "DELTA: 0.42408156394958496, X0: 1.126099944114685, X_THRESHOLD: 1.864433765411377\n",
      "\n",
      "Half-Adder Evaluation:\n",
      "Input: [False False], Predicted Sum: 1, Predicted Carry: 0\n",
      "Input: [False  True], Predicted Sum: 1, Predicted Carry: 0\n",
      "Input: [ True False], Predicted Sum: 1, Predicted Carry: 0\n",
      "Input: [ True  True], Predicted Sum: 0, Predicted Carry: 1\n"
     ]
    }
   ],
   "source": [
    "# Display trained parameters\n",
    "print(\"\\nTrained XOR Gate Parameters:\")\n",
    "print(\n",
    "    f\"DELTA: {xor_gate.DELTA}, X0: {xor_gate.X0}, X_THRESHOLD: {xor_gate.X_THRESHOLD}\"\n",
    ")\n",
    "\n",
    "print(\"\\nTrained AND Gate Parameters:\")\n",
    "print(\n",
    "    f\"DELTA: {and_gate.DELTA}, X0: {and_gate.X0}, X_THRESHOLD: {and_gate.X_THRESHOLD}\"\n",
    ")\n",
    "\n",
    "# Evaluate the trained Half-Adder\n",
    "print(\"\\nHalf-Adder Evaluation:\")\n",
    "for i in range(len(X)):\n",
    "    sum_output = xor_gate(X[i])\n",
    "    carry_output = and_gate(X[i])\n",
    "    print(\n",
    "        f\"Input: {X[i]}, Predicted Sum: {sum_output:.0f}, Predicted Carry: {carry_output:.0f}\"\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
