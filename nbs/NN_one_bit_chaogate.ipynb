{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: JAX_PLATFORM_NAME=cpu\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "\n",
    "%env JAX_PLATFORM_NAME=cpu\n",
    "# %env EQX_ON_ERROR=breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import equinox as eqx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "DELTA = 1 / 4\n",
    "\n",
    "AND_X = 0\n",
    "OR_X = 1 / 8\n",
    "XOR_X = 1 / 4\n",
    "NAND_X = 3 / 8\n",
    "\n",
    "AND_TRUE = 3 / 4\n",
    "OR_TRUE = 11 / 16\n",
    "XOR_TRUE = 3 / 4\n",
    "NAND_TRUE = 11 / 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "An NVIDIA GPU may be present on this machine, but a CUDA-enabled jaxlib is not installed. Falling back to cpu.\n"
     ]
    }
   ],
   "source": [
    "gate_types = {\n",
    "    \"AND\": jnp.array([1, 0, 0, 0]),\n",
    "    \"OR\": jnp.array([0, 1, 0, 0]),\n",
    "    \"NOR\": jnp.array([0, 0, 1, 0]),\n",
    "    \"NAND\": jnp.array([0, 0, 0, 1]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_combinations = [(0, 0), (0, 1), (1, 0), (1, 1)]\n",
    "gate_outputs = {\n",
    "    \"AND\": [0, 0, 0, 1],\n",
    "    \"OR\": [0, 1, 1, 1],\n",
    "    \"NOR\": [1, 0, 0, 0],\n",
    "    \"NAND\": [1, 1, 1, 0],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_map(x: float, a: float = 4):\n",
    "    \"\"\"Logistic map function\"\"\"\n",
    "    return a * x * (1 - x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chao_gate(x: bool, y: bool, DELTA: float, X0: float, X_TRUE: float) -> float:\n",
    "    \"\"\"Chao gate function\n",
    "    Args:\n",
    "        x: input x\n",
    "        y: input y\n",
    "        DELTA:\n",
    "        X0: initial value\n",
    "        X_TRUE\n",
    "    RETURNS:\n",
    "        float: output of the chao gate\n",
    "\n",
    "    \"\"\"\n",
    "    return logistic_map(X0 + x * DELTA + y * DELTA) - X_TRUE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(eqx.Module):\n",
    "    \"\"\"\n",
    "    MLP to learn the parameters of the chao gates\n",
    "    \"\"\"\n",
    "\n",
    "    layer_sizes: list\n",
    "    layers: list\n",
    "    layer_norm: eqx.nn.LayerNorm\n",
    "\n",
    "    def __init__(self, hidden_sizes: list, key):\n",
    "        self.layer_sizes = [4] + hidden_sizes + [3]\n",
    "        self.layers = []\n",
    "        keys = jax.random.split(key, len(self.layer_sizes))\n",
    "\n",
    "        self.layers = [\n",
    "            eqx.nn.Linear(in_features, out_features, key=keys[key_idx])\n",
    "            for key_idx, (in_features, out_features) in enumerate(\n",
    "                zip(self.layer_sizes[:-1], self.layer_sizes[1:])\n",
    "            )\n",
    "        ]\n",
    "\n",
    "        self.layer_norm = eqx.nn.LayerNorm(shape=(self.layer_sizes[1],))\n",
    "\n",
    "    def __call__(self, gate_type: jnp.ndarray) -> jnp.ndarray:\n",
    "        \"\"\"\n",
    "        takes in the gate type and returns the parameters of the chao gate\n",
    "        \"\"\"\n",
    "        x = jax.nn.relu(self.layers[0](gate_type))\n",
    "        x = self.layer_norm(x)\n",
    "        for layer in self.layers[1:-1]:\n",
    "            x = jax.nn.relu(layer(x))\n",
    "\n",
    "        return self.layers[-1](x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([-0.34048057, -0.31616643,  0.02645211], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# | test\n",
    "\n",
    "key = jax.random.PRNGKey(0)\n",
    "mlp = MLP(hidden_sizes=[8, 8], key=key)\n",
    "gate_type = jnp.array([1, 0, 0, 0])\n",
    "params = mlp(gate_type)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(model: eqx.Module, gate_type: jnp.ndarray, data):\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
